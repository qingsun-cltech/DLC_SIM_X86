#ifndef _ERFCINVF_WITHOUT_UNARY_H_
#define _ERFCINVF_WITHOUT_UNARY_H_

inline float8_128 __dlc_erfcinvf_without_unary(float8_128 a)
{
    float8_128 result0;
    asm (
        "{V0@(pr0)  vr10 = mov.u32 %[input0];}"
        "{"
        "pseudo@0	@pseudo imm_0 = 40;"
        "pseudo@0	@pseudo imm_2 = 1004;"
        "pseudo@0	@pseudo imm_3 = 0;"
        "S0@(pr0)	r1 = mov.u32 r32;"
        "S1@(pr0)	[smem:r45] = st r1;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 16384;"
        "pseudo@0	@pseudo imm_1 = 1;"
        "S0@(pr0)	r2 = mov.u32 r44;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 1000;"
        "pseudo@0	@pseudo imm_1 = 0;"
        "pseudo@0	@pseudo imm_2 = 1040;"
        "pseudo@0	@pseudo imm_3 = 0;"
        "S0@(pr0)	r6 = mov.u32 r44;"
        "S1@(pr0)	[smem:r45] = st r2;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 40;"
        "S1@(pr0)	r6 = sub.s32 r6, r32;"
        "}"
        "{"
        "V0@(pr0)	vr31 = xor.u32 vr10, r47;"
        "V1@(pr0)	vr11 = mov.u32 vr10;"
        "}"
        "{"
        "V1@(pr0)	vr31 = add.f32 vr31, r48;"
        "}"
        "{"
        "V0@(pr0)	vr1 = mul.f32 vr31, vr10;"
        "V1@(pr0)	vr2 = add.f32 vr10, vr10;"
        "}"
        "{"
        "V1@(pr0)	vr10 = add.f32 vr1, vr2;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 32640;"
        "V0@(pr0)	vmsk5 = ls.s32 vr10, r36;"
        "V1@(pr0)	vr0 = add.s32 vr10, vr10;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 128;"
        "V0@(pr0)	vmsk2 = ls.s32 vr10, r36;"
        "V1@(pr0)	vr28 = mov.u32 r46;"
        "}"
        "{"
        "V0@(pr0)	vmsk4 = ls.s32 vr10, r46;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 25;"
        "V0@(pr0)	vr29 = sub.s32 vr28, r32;"
        "V1@(pr0)	vr28 = sel vmsk2 vr28, vr29;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 19456;"
        "V0@(pr0)	vr29 = mul.f32 vr10, r36;"
        "V1@(pr0)	vr10 = sel vmsk2 vr10, vr29;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 65535;"
        "pseudo@0	@pseudo imm_1 = 32767;"
        "V0@(pr0)	vr12 = and.u32 vr10, r44;"
        "V1@(pr0)	vmsk7 = eq.s32 vr12, r46;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 23;"
        "V0@(pr0)	vmsk6 = ls.s32 vr10, r46;"
        "V1@(pr0)	vr13 = shr.u32 vr12, r32;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 127;"
        "V1@(pr0)	vr14 = sub.s32 vr13, r32;"
        "}"
        "{"
        "V1@(pr0)	vr13 = add.s32 vr14, r46;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 65535;"
        "pseudo@0	@pseudo imm_1 = 127;"
        "V0@(pr0)	vr12 = and.u32 vr12, r44;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 24420;"
        "pseudo@0	@pseudo imm_1 = 9;"
        "pseudo@0	@pseudo imm_2 = 3;"
        "V0@(pr0)	vr14 = mov.u32 r44;"
        "V1@(pr0)	vr15 = shl.u32 vr14, r34;"
        "}"
        "{"
        "V1@(pr0)	vr14 = add.s32 vr12, vr15;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 128;"
        "pseudo@0	@pseudo imm_1 = 23;"
        "V0@(pr0)	vr1 = and.u32 vr14, r36;"
        "V1@(pr0)	vr14 = shr.u32 vr1, r33;"
        "}"
        "{"
        "V0@(pr0)	vr13 = add.s32 vr13, vr14;"
        "V1@(pr0)	vmsk2 = eq.s32 vr13, r46;"
        "}"
        "{"
        "V0@(pr0)	vr13 = add.s32 vr13, vr28;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 16256;"
        "V0@(pr0)	vr16 = xor.u32 vr1, r36;"
        "V1@(pr0)	vr10 = or.u32 vr12, vr16;"
        "}"
        "{"
        "V0@(pr0)	vr13 = cvtinttof.f32 vr13;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 29056;"
        "pseudo@0	@pseudo imm_1 = 16177;"
        "V0@(pr0)	vr17 = mul.f32 vr13, r44;"
        "V1@(pr0)	vr14 = sub.f32 vr10, r49;"
        "}"
        "{"
        "V1@(pr0)	vr15 = add.f32 vr14, r51;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 65535;"
        "pseudo@0	@pseudo imm_1 = 32767;"
        "pseudo@0	@pseudo imm_2 = 32640;"
        "V0@(pr0)	vr30 = and.u32 vr15, r44;"
        "V1@(pr0)	vmsk3 = eq.s32 vr30, r38;"
        "}"
        "{"
        "V0@(pr0)	vr31 = mul.f32 vr30, r50;"
        "V1@(pr0)	vr2 = mov.u32 vr30;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 23007;"
        "pseudo@0	@pseudo imm_1 = 24375;"
        "V0@(pr0)	vr3 = mov.u32 r44;"
        "V1@(pr0)	vr2 = shr.u32 vr2, r48;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 16320;"
        "V0@(pr0)	vr2 = sub.s32 vr3, vr2;"
        "V1@(pr0)	vr4 = mov.u32 r36;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 32768;"
        "V0@(pr0)	vr3 = mul.f32 vr2, vr2;"
        "V1@(pr0)	vr6 = and.u32 vr15, r36;"
        "}"
        "{"
        "V0@(pr0)	vr5 = mul.f32 vr31, vr3;"
        "V1@(pr0)	vr5 = sub.f32 vr4, vr5;"
        "}"
        "{"
        "V0@(pr0)	vr5 = mul.f32 vr5, vr2;"
        "V1@(pr0)	vr2 = mov.u32 vr5;"
        "}"
        "{"
        "V0@(pr0)	vr3 = mul.f32 vr2, vr2;"
        "V1@(pr0)	vmsk0 = eq.f32 vr15, r46;"
        "}"
        "{"
        "V0@(pr0)	vr5 = mul.f32 vr31, vr3;"
        "V1@(pr0)	vr5 = sub.f32 vr4, vr5;"
        "}"
        "{"
        "V0@(pr0)	vr5 = mul.f32 vr5, vr2;"
        "V1@(pr0)	vr2 = mov.u32 vr5;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 0;"
        "pseudo@0	@pseudo imm_1 = 32640;"
        "V0@(pr0)	vr3 = mul.f32 vr2, vr2;"
        "V1@(pr0)	vr7 = or.u32 vr6, r44;"
        "}"
        "{"
        "V0@(pr0)	vr5 = mul.f32 vr31, vr3;"
        "V1@(pr0)	vr5 = sub.f32 vr4, vr5;"
        "}"
        "{"
        "V0@(pr0)	vr5 = mul.f32 vr5, vr2;"
        "V1@(pr0)	vr2 = or.u32 vr6, r46;"
        "}"
        "{"
        "V0@(pr0)	vr31 = mul.f32 vr5, vr5;"
        "V1@(pr0)	vr31 = or.u32 vr6, vr31;"
        "}"
        "{"
        "V0@(pr0)	vr15 = sel vmsk0 vr31, vr7;"
        "V1@(pr0)	vr15 = sel vmsk3 vr15, vr2;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 5242;"
        "pseudo@0	@pseudo imm_1 = 6;"
        "V0@(pr0)	vr15 = mul.f32 vr14, vr15;"
        "V1@(pr0)	vr16 = mov.u32 r44;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 3;"
        "V1@(pr0)	vr16 = shl.u32 vr16, r32;"
        "}"
        "{"
        "V0@(pr0)	vr7 = mul.f32 vr15, vr15;"
        "V1@(pr0)	vr1 = sub.s32 vr12, vr16;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 47185;"
        "pseudo@0	@pseudo imm_1 = 6;"
        "V0@(pr0)	vr3 = mul.f32 vr7, vr7;"
        "V1@(pr0)	vr16 = mov.u32 r44;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 3;"
        "V1@(pr0)	vr16 = shl.u32 vr16, r32;"
        "}"
        "{"
        "V0@(pr0)	vr4 = sub.s32 vr16, vr12;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 53327;"
        "pseudo@0	@pseudo imm_1 = 15900;"
        "pseudo@0	@pseudo imm_2 = 36393;"
        "pseudo@0	@pseudo imm_3 = 15971;"
        "V0@(pr0)	vr5 = mul.f32 vr3, r44;"
        "V1@(pr0)	vr6 = add.f32 vr5, r45;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 52429;"
        "pseudo@0	@pseudo imm_1 = 16076;"
        "V0@(pr0)	vr5 = mul.f32 vr3, vr6;"
        "V1@(pr0)	vr6 = add.f32 vr5, r44;"
        "}"
        "{"
        "V0@(pr0)	vr5 = mul.f32 vr3, vr6;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 34967;"
        "pseudo@0	@pseudo imm_1 = 15895;"
        "pseudo@0	@pseudo imm_2 = 13093;"
        "pseudo@0	@pseudo imm_3 = 15930;"
        "V0@(pr0)	vr2 = mul.f32 vr3, r44;"
        "V1@(pr0)	vr6 = add.f32 vr2, r45;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 18725;"
        "pseudo@0	@pseudo imm_1 = 16018;"
        "V0@(pr0)	vr2 = mul.f32 vr3, vr6;"
        "V1@(pr0)	vr6 = add.f32 vr2, r44;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 43691;"
        "pseudo@0	@pseudo imm_1 = 16170;"
        "V0@(pr0)	vr2 = mul.f32 vr3, vr6;"
        "V1@(pr0)	vr6 = add.f32 vr2, r44;"
        "}"
        "{"
        "V0@(pr0)	vr2 = mul.f32 vr7, vr6;"
        "V1@(pr0)	vr7 = add.f32 vr2, vr5;"
        "}"
        "{"
        "V0@(pr0)	vr1 = or.u32 vr1, vr4;"
        "V1@(pr0)	vmsk0 = gt.f32 vr1, r46;"
        "}"
        "{"
        "V0@(pr0)	vr2 = mul.f32 vr14, vr14;"
        "}"
        "{"
        "V0@(pr0)	vr4 = mul.f32 vr2, r50;"
        "V1@(pr0)	vr1 = add.f32 vr4, vr7;"
        "}"
        "{"
        "V0@(pr0)	vr2 = mul.f32 vr15, vr1;"
        "V1@(pr0)	vr5 = sub.f32 vr4, vr2;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 63441;"
        "pseudo@0	@pseudo imm_1 = 14103;"
        "V0@(pr0)	vr16 = mul.f32 vr13, r44;"
        "V1@(pr0)	vr6 = sub.f32 vr14, vr5;"
        "}"
        "{"
        "V1@(pr0)	vr3 = add.f32 vr2, vr16;"
        "}"
        "{"
        "V1@(pr0)	vr1 = sub.f32 vr4, vr3;"
        "}"
        "{"
        "V1@(pr0)	vr1 = sub.f32 vr1, vr14;"
        "}"
        "{"
        "V1@(pr0)	vr1 = sub.f32 vr17, vr1;"
        "}"
        "{"
        "V1@(pr0)	vr2 = sub.f32 vr14, vr7;"
        "}"
        "{"
        "V0@(pr0)	vr4 = mul.f32 vr15, vr2;"
        "V1@(pr0)	vr2 = sub.f32 vr14, vr4;"
        "}"
        "{"
        "V1@(pr0)	vr5 = sub.f32 vr4, vr16;"
        "}"
        "{"
        "V1@(pr0)	vr7 = sub.f32 vr5, vr14;"
        "}"
        "{"
        "V1@(pr0)	vr5 = sub.f32 vr17, vr7;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 43690;"
        "pseudo@0	@pseudo imm_1 = 16042;"
        "V0@(pr0)	vr4 = mul.f32 vr14, r44;"
        "}"
        "{"
        "V0@(pr0)	vr15 = mov.u32 r50;"
        "V1@(pr0)	vr7 = sub.f32 vr15, vr4;"
        "}"
        "{"
        "V0@(pr0)	vr4 = mul.f32 vr14, vr14;"
        "}"
        "{"
        "V0@(pr0)	vr7 = mul.f32 vr4, vr7;"
        "}"
        "{"
        "V1@(pr0)	vr15 = sub.f32 vr14, vr7;"
        "}"
        "{"
        "V0@(pr0)	vmsk1 = eq.f32 vr14, r46;"
        "V1@(pr0)	vr4 = sub.f32 vr7, vr16;"
        "}"
        "{"
        "V1@(pr0)	vr7 = sub.f32 vr4, vr14;"
        "}"
        "{"
        "V1@(pr0)	vr4 = sub.f32 vr17, vr7;"
        "}"
        "{"
        "V1@(pr0)	vr3 = add.f32 vr16, vr17;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 15;"
        "V1@(pr0)	vr7 = add.s32 vr12, r32;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 65535;"
        "pseudo@0	@pseudo imm_1 = 127;"
        "V0@(pr0)	vr16 = and.u32 vr7, r44;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 16;"
        "V0@(pr0)	vmsk3 = ls.s32 vr16, r32;"
        "}"
        "{"
        "V0@(pr0)	vr13 = sel vmsk2 vr1, vr6;"
        "V1@(pr0)	vr14 = sel vmsk2 vr5, vr2;"
        "}"
        "{"
        "V0@(pr0)	vr16 = sel vmsk2 vr3, r46;"
        "V1@(pr0)	vr17 = sel vmsk2 vr4, vr15;"
        "}"
        "{"
        "V0@(pr0)	vr1 = sel vmsk0 vr14, vr13;"
        "V1@(pr0)	vr2 = sel vmsk1 vr17, vr16;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 65408;"
        "V0@(pr0)	vr10 = sel vmsk3 vr1, vr2;"
        "V1@(pr0)	vr10 = sel vmsk7 vr10, r36;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 65528;"
        "V0@(pr0)	vr10 = sel vmsk6 vr10, r36;"
        "V1@(pr0)	vr10 = sel vmsk5 vr0, vr10;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 32704;"
        "V0@(pr0)	vr10 = sel vmsk4 vr10, r36;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 57344;"
        "pseudo@0	@pseudo imm_1 = 12730;"
        "V0@(pr0)	vr0 = mul.f32 vr10, r44;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 55852;"
        "pseudo@0	@pseudo imm_1 = 13337;"
        "V1@(pr0)	vr0 = add.f32 vr0, r44;"
        "}"
        "{"
        "V0@(pr0)	vr0 = mul.f32 vr10, vr0;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 51534;"
        "pseudo@0	@pseudo imm_1 = 13732;"
        "V1@(pr0)	vr0 = add.f32 vr0, r44;"
        "}"
        "{"
        "V0@(pr0)	vr0 = mul.f32 vr10, vr0;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 38365;"
        "pseudo@0	@pseudo imm_1 = 13298;"
        "V1@(pr0)	vr0 = add.f32 vr0, r44;"
        "}"
        "{"
        "V0@(pr0)	vr0 = mul.f32 vr10, vr0;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 34313;"
        "pseudo@0	@pseudo imm_1 = 47211;"
        "V1@(pr0)	vr0 = add.f32 vr0, r44;"
        "}"
        "{"
        "V0@(pr0)	vr0 = mul.f32 vr10, vr0;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 57165;"
        "pseudo@0	@pseudo imm_1 = 47386;"
        "V1@(pr0)	vr0 = add.f32 vr0, r44;"
        "}"
        "{"
        "V0@(pr0)	vr0 = mul.f32 vr10, vr0;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 45569;"
        "pseudo@0	@pseudo imm_1 = 15127;"
        "V1@(pr0)	vr0 = add.f32 vr0, r44;"
        "}"
        "{"
        "V0@(pr0)	vr0 = mul.f32 vr10, vr0;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 3878;"
        "pseudo@0	@pseudo imm_1 = 15421;"
        "V1@(pr0)	vr0 = add.f32 vr0, r44;"
        "}"
        "{"
        "V0@(pr0)	vr0 = mul.f32 vr10, vr0;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 38263;"
        "pseudo@0	@pseudo imm_1 = 48749;"
        "V1@(pr0)	vr0 = add.f32 vr0, r44;"
        "}"
        "{"
        "V0@(pr0)	vr1 = mul.f32 vr10, vr0;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 57284;"
        "pseudo@0	@pseudo imm_1 = 16226;"
        "V1@(pr0)	vr10 = add.f32 vr1, r44;"
        "}"
        "{"
        "V0@(pr0)	vr31 = xor.u32 vr11, r47;"
        "}"
        "{"
        "V1@(pr0)	vr31 = add.f32 vr31, r48;"
        "}"
        "{"
        "V0@(pr0)	vr1 = mul.f32 vr10, vr31;"
        "}"
        "{"
        "V1@(pr0)	vr0 = add.f32 vr1, vr10;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 4;"
        "S0@(pr0)	r3 = add.s32 r9, r32;"
        "S1@(pr0)	r3 = ld [smem:r3];"
        "}"
        "{"
        "S0@(pr0)	r3 = add.s32 r3, r9;"
        "S1@(pr0)	r0 = ld [smem:r3];"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 2048;"
        "pseudo@0	@pseudo imm_1 = 0;"
        "S1@(pr0)	r0 = sub.s32 r0, r44;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 0;"
        "pseudo@0	@pseudo imm_2 = 1;"
        "pseudo@0	@pseudo imm_4 = 0;"
        "pseudo@0	@pseudo vs_imm0 = 1;"
        "S0@(pr0)	r1 = add.s32 r0, r32;"
        "VS@(pr0)	[vmem:1+2,4,0] = st vr0;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 1024;"
        "pseudo@0	@pseudo imm_2 = 1;"
        "pseudo@0	@pseudo imm_4 = 0;"
        "pseudo@0	@pseudo vs_imm0 = 1;"
        "S0@(pr0)	r1 = add.s32 r0, r32;"
        "VS@(pr0)	[vmem:1+2,4,0] = st vr11;"
        "}"
        "{"
        "S1@(pr0)	[smem:r3] = st r0;"
        "}"
        "{"
        "V0@(pr0)	vmsk0 = gt.f32 vr11, r49;"
        "V1@(pr0)	vr1 = mov.u32 r51;"
        "}"
        "{"
        "V1@(pr0)	vr1 = sub.f32 vr1, vr11;"
        "}"
        "{"
        "V0@(pr0)	vr10 = sel vmsk0 vr11, vr1;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 32640;"
        "V0@(pr0)	vmsk5 = ls.s32 vr10, r36;"
        "V1@(pr0)	vr0 = add.s32 vr10, vr10;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 128;"
        "V0@(pr0)	vmsk2 = ls.s32 vr10, r36;"
        "V1@(pr0)	vr28 = mov.u32 r46;"
        "}"
        "{"
        "V0@(pr0)	vmsk4 = ls.s32 vr10, r46;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 25;"
        "V0@(pr0)	vr29 = sub.s32 vr28, r32;"
        "V1@(pr0)	vr28 = sel vmsk2 vr28, vr29;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 19456;"
        "V0@(pr0)	vr29 = mul.f32 vr10, r36;"
        "V1@(pr0)	vr10 = sel vmsk2 vr10, vr29;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 65535;"
        "pseudo@0	@pseudo imm_1 = 32767;"
        "V0@(pr0)	vr12 = and.u32 vr10, r44;"
        "V1@(pr0)	vmsk7 = eq.s32 vr12, r46;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 23;"
        "V0@(pr0)	vmsk6 = ls.s32 vr10, r46;"
        "V1@(pr0)	vr13 = shr.u32 vr12, r32;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 127;"
        "V1@(pr0)	vr14 = sub.s32 vr13, r32;"
        "}"
        "{"
        "V1@(pr0)	vr13 = add.s32 vr14, r46;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 65535;"
        "pseudo@0	@pseudo imm_1 = 127;"
        "V0@(pr0)	vr12 = and.u32 vr12, r44;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 24420;"
        "pseudo@0	@pseudo imm_1 = 9;"
        "pseudo@0	@pseudo imm_2 = 3;"
        "V0@(pr0)	vr14 = mov.u32 r44;"
        "V1@(pr0)	vr15 = shl.u32 vr14, r34;"
        "}"
        "{"
        "V1@(pr0)	vr14 = add.s32 vr12, vr15;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 128;"
        "pseudo@0	@pseudo imm_1 = 23;"
        "V0@(pr0)	vr1 = and.u32 vr14, r36;"
        "V1@(pr0)	vr14 = shr.u32 vr1, r33;"
        "}"
        "{"
        "V0@(pr0)	vr13 = add.s32 vr13, vr14;"
        "V1@(pr0)	vmsk2 = eq.s32 vr13, r46;"
        "}"
        "{"
        "V0@(pr0)	vr13 = add.s32 vr13, vr28;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 16256;"
        "V0@(pr0)	vr16 = xor.u32 vr1, r36;"
        "V1@(pr0)	vr10 = or.u32 vr12, vr16;"
        "}"
        "{"
        "V0@(pr0)	vr13 = cvtinttof.f32 vr13;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 29056;"
        "pseudo@0	@pseudo imm_1 = 16177;"
        "V0@(pr0)	vr17 = mul.f32 vr13, r44;"
        "V1@(pr0)	vr14 = sub.f32 vr10, r49;"
        "}"
        "{"
        "V1@(pr0)	vr15 = add.f32 vr14, r51;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 65535;"
        "pseudo@0	@pseudo imm_1 = 32767;"
        "pseudo@0	@pseudo imm_2 = 0;"
        "pseudo@0	@pseudo imm_3 = 32640;"
        "V0@(pr0)	vr30 = and.u32 vr15, r44;"
        "V1@(pr0)	vmsk3 = eq.s32 vr30, r45;"
        "}"
        "{"
        "V0@(pr0)	vr31 = mul.f32 vr30, r50;"
        "V1@(pr0)	vr2 = mov.u32 vr30;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 23007;"
        "pseudo@0	@pseudo imm_1 = 24375;"
        "V0@(pr0)	vr3 = mov.u32 r44;"
        "V1@(pr0)	vr2 = shr.u32 vr2, r48;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 16320;"
        "V0@(pr0)	vr2 = sub.s32 vr3, vr2;"
        "V1@(pr0)	vr4 = mov.u32 r36;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 32768;"
        "V0@(pr0)	vr3 = mul.f32 vr2, vr2;"
        "V1@(pr0)	vr6 = and.u32 vr15, r36;"
        "}"
        "{"
        "V0@(pr0)	vr5 = mul.f32 vr31, vr3;"
        "V1@(pr0)	vr5 = sub.f32 vr4, vr5;"
        "}"
        "{"
        "V0@(pr0)	vr5 = mul.f32 vr5, vr2;"
        "V1@(pr0)	vr2 = mov.u32 vr5;"
        "}"
        "{"
        "V0@(pr0)	vr3 = mul.f32 vr2, vr2;"
        "V1@(pr0)	vmsk0 = eq.f32 vr15, r46;"
        "}"
        "{"
        "V0@(pr0)	vr5 = mul.f32 vr31, vr3;"
        "V1@(pr0)	vr5 = sub.f32 vr4, vr5;"
        "}"
        "{"
        "V0@(pr0)	vr5 = mul.f32 vr5, vr2;"
        "V1@(pr0)	vr2 = mov.u32 vr5;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 0;"
        "pseudo@0	@pseudo imm_1 = 32640;"
        "V0@(pr0)	vr3 = mul.f32 vr2, vr2;"
        "V1@(pr0)	vr7 = or.u32 vr6, r44;"
        "}"
        "{"
        "V0@(pr0)	vr5 = mul.f32 vr31, vr3;"
        "V1@(pr0)	vr5 = sub.f32 vr4, vr5;"
        "}"
        "{"
        "V0@(pr0)	vr5 = mul.f32 vr5, vr2;"
        "V1@(pr0)	vr2 = or.u32 vr6, r46;"
        "}"
        "{"
        "V0@(pr0)	vr31 = mul.f32 vr5, vr5;"
        "V1@(pr0)	vr31 = or.u32 vr6, vr31;"
        "}"
        "{"
        "V0@(pr0)	vr15 = sel vmsk0 vr31, vr7;"
        "V1@(pr0)	vr15 = sel vmsk3 vr15, vr2;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 5242;"
        "pseudo@0	@pseudo imm_1 = 6;"
        "V0@(pr0)	vr15 = mul.f32 vr14, vr15;"
        "V1@(pr0)	vr16 = mov.u32 r44;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 3;"
        "V1@(pr0)	vr16 = shl.u32 vr16, r32;"
        "}"
        "{"
        "V0@(pr0)	vr7 = mul.f32 vr15, vr15;"
        "V1@(pr0)	vr1 = sub.s32 vr12, vr16;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 47185;"
        "pseudo@0	@pseudo imm_1 = 6;"
        "V0@(pr0)	vr3 = mul.f32 vr7, vr7;"
        "V1@(pr0)	vr16 = mov.u32 r44;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 3;"
        "V1@(pr0)	vr16 = shl.u32 vr16, r32;"
        "}"
        "{"
        "V0@(pr0)	vr4 = sub.s32 vr16, vr12;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 53327;"
        "pseudo@0	@pseudo imm_1 = 15900;"
        "pseudo@0	@pseudo imm_2 = 36393;"
        "pseudo@0	@pseudo imm_3 = 15971;"
        "V0@(pr0)	vr5 = mul.f32 vr3, r44;"
        "V1@(pr0)	vr6 = add.f32 vr5, r45;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 52429;"
        "pseudo@0	@pseudo imm_1 = 16076;"
        "V0@(pr0)	vr5 = mul.f32 vr3, vr6;"
        "V1@(pr0)	vr6 = add.f32 vr5, r44;"
        "}"
        "{"
        "V0@(pr0)	vr5 = mul.f32 vr3, vr6;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 34967;"
        "pseudo@0	@pseudo imm_1 = 15895;"
        "pseudo@0	@pseudo imm_2 = 13093;"
        "pseudo@0	@pseudo imm_3 = 15930;"
        "V0@(pr0)	vr2 = mul.f32 vr3, r44;"
        "V1@(pr0)	vr6 = add.f32 vr2, r45;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 18725;"
        "pseudo@0	@pseudo imm_1 = 16018;"
        "V0@(pr0)	vr2 = mul.f32 vr3, vr6;"
        "V1@(pr0)	vr6 = add.f32 vr2, r44;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 43691;"
        "pseudo@0	@pseudo imm_1 = 16170;"
        "V0@(pr0)	vr2 = mul.f32 vr3, vr6;"
        "V1@(pr0)	vr6 = add.f32 vr2, r44;"
        "}"
        "{"
        "V0@(pr0)	vr2 = mul.f32 vr7, vr6;"
        "V1@(pr0)	vr7 = add.f32 vr2, vr5;"
        "}"
        "{"
        "V0@(pr0)	vr1 = or.u32 vr1, vr4;"
        "V1@(pr0)	vmsk0 = gt.f32 vr1, r46;"
        "}"
        "{"
        "V0@(pr0)	vr2 = mul.f32 vr14, vr14;"
        "}"
        "{"
        "V0@(pr0)	vr4 = mul.f32 vr2, r50;"
        "V1@(pr0)	vr1 = add.f32 vr4, vr7;"
        "}"
        "{"
        "V0@(pr0)	vr2 = mul.f32 vr15, vr1;"
        "V1@(pr0)	vr5 = sub.f32 vr4, vr2;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 63441;"
        "pseudo@0	@pseudo imm_1 = 14103;"
        "V0@(pr0)	vr16 = mul.f32 vr13, r44;"
        "V1@(pr0)	vr6 = sub.f32 vr14, vr5;"
        "}"
        "{"
        "V1@(pr0)	vr3 = add.f32 vr2, vr16;"
        "}"
        "{"
        "V1@(pr0)	vr1 = sub.f32 vr4, vr3;"
        "}"
        "{"
        "V1@(pr0)	vr1 = sub.f32 vr1, vr14;"
        "}"
        "{"
        "V1@(pr0)	vr1 = sub.f32 vr17, vr1;"
        "}"
        "{"
        "V1@(pr0)	vr2 = sub.f32 vr14, vr7;"
        "}"
        "{"
        "V0@(pr0)	vr4 = mul.f32 vr15, vr2;"
        "V1@(pr0)	vr2 = sub.f32 vr14, vr4;"
        "}"
        "{"
        "V1@(pr0)	vr5 = sub.f32 vr4, vr16;"
        "}"
        "{"
        "V1@(pr0)	vr7 = sub.f32 vr5, vr14;"
        "}"
        "{"
        "V1@(pr0)	vr5 = sub.f32 vr17, vr7;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 43690;"
        "pseudo@0	@pseudo imm_1 = 16042;"
        "V0@(pr0)	vr4 = mul.f32 vr14, r44;"
        "}"
        "{"
        "V0@(pr0)	vr15 = mov.u32 r50;"
        "V1@(pr0)	vr7 = sub.f32 vr15, vr4;"
        "}"
        "{"
        "V0@(pr0)	vr4 = mul.f32 vr14, vr14;"
        "}"
        "{"
        "V0@(pr0)	vr7 = mul.f32 vr4, vr7;"
        "}"
        "{"
        "V1@(pr0)	vr15 = sub.f32 vr14, vr7;"
        "}"
        "{"
        "V0@(pr0)	vmsk1 = eq.f32 vr14, r46;"
        "V1@(pr0)	vr4 = sub.f32 vr7, vr16;"
        "}"
        "{"
        "V1@(pr0)	vr7 = sub.f32 vr4, vr14;"
        "}"
        "{"
        "V1@(pr0)	vr4 = sub.f32 vr17, vr7;"
        "}"
        "{"
        "V1@(pr0)	vr3 = add.f32 vr16, vr17;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 15;"
        "V1@(pr0)	vr7 = add.s32 vr12, r32;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 65535;"
        "pseudo@0	@pseudo imm_1 = 127;"
        "V0@(pr0)	vr16 = and.u32 vr7, r44;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 16;"
        "V0@(pr0)	vmsk3 = ls.s32 vr16, r32;"
        "}"
        "{"
        "V0@(pr0)	vr13 = sel vmsk2 vr1, vr6;"
        "V1@(pr0)	vr14 = sel vmsk2 vr5, vr2;"
        "}"
        "{"
        "V0@(pr0)	vr16 = sel vmsk2 vr3, r46;"
        "V1@(pr0)	vr17 = sel vmsk2 vr4, vr15;"
        "}"
        "{"
        "V0@(pr0)	vr1 = sel vmsk0 vr14, vr13;"
        "V1@(pr0)	vr2 = sel vmsk1 vr17, vr16;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 65408;"
        "V0@(pr0)	vr10 = sel vmsk3 vr1, vr2;"
        "V1@(pr0)	vr10 = sel vmsk7 vr10, r36;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 65528;"
        "V0@(pr0)	vr10 = sel vmsk6 vr10, r36;"
        "V1@(pr0)	vr10 = sel vmsk5 vr0, vr10;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 32704;"
        "V0@(pr0)	vr10 = sel vmsk4 vr10, r36;"
        "}"
        "{"
        "V1@(pr0)	vr0 = mov.u32 r46;"
        "}"
        "{"
        "V1@(pr0)	vr10 = sub.f32 vr0, vr10;"
        "}"
        "{"
        "V0@(pr0)	vr1 = mul.f32 vr10, r50;"
        "V1@(pr0)	vr2 = mov.u32 vr10;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 23007;"
        "pseudo@0	@pseudo imm_1 = 24375;"
        "V0@(pr0)	vr3 = mov.u32 r44;"
        "V1@(pr0)	vr2 = shr.u32 vr2, r48;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 16320;"
        "V0@(pr0)	vr2 = sub.s32 vr3, vr2;"
        "V1@(pr0)	vr4 = mov.u32 r36;"
        "}"
        "{"
        "V0@(pr0)	vr3 = mul.f32 vr2, vr2;"
        "V1@(pr0)	vmsk0 = lseq.f32 vr10, r46;"
        "}"
        "{"
        "V0@(pr0)	vr5 = mul.f32 vr1, vr3;"
        "V1@(pr0)	vr5 = sub.f32 vr4, vr5;"
        "}"
        "{"
        "V0@(pr0)	vr5 = mul.f32 vr5, vr2;"
        "V1@(pr0)	vr2 = mov.u32 vr5;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 32640;"
        "V0@(pr0)	vr3 = mul.f32 vr2, vr2;"
        "V1@(pr0)	vmsk1 = eq.s32 vr10, r36;"
        "}"
        "{"
        "V0@(pr0)	vr5 = mul.f32 vr1, vr3;"
        "V1@(pr0)	vr5 = sub.f32 vr4, vr5;"
        "}"
        "{"
        "V0@(pr0)	vr5 = mul.f32 vr5, vr2;"
        "V1@(pr0)	vr2 = mov.u32 vr5;"
        "}"
        "{"
        "V0@(pr0)	vr3 = mul.f32 vr2, vr2;"
        "V1@(pr0)	vmsk2 = eq.f32 vr10, r46;"
        "}"
        "{"
        "V0@(pr0)	vr5 = mul.f32 vr1, vr3;"
        "V1@(pr0)	vr5 = sub.f32 vr4, vr5;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 32640;"
        "V0@(pr0)	vr1 = and.u32 vr10, r47;"
        "V1@(pr0)	vr3 = or.u32 vr1, r36;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 32704;"
        "V0@(pr0)	vr10 = mul.f32 vr5, vr2;"
        "V1@(pr0)	vr10 = sel vmsk0 vr10, r36;"
        "}"
        "{"
        "V0@(pr0)	vr10 = sel vmsk1 vr10, r46;"
        "V1@(pr0)	vr10 = sel vmsk2 vr10, vr3;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 31499;"
        "pseudo@0	@pseudo imm_1 = 16818;"
        "V0@(pr0)	vr0 = mul.f32 vr10, r44;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 13331;"
        "pseudo@0	@pseudo imm_1 = 49745;"
        "V1@(pr0)	vr0 = add.f32 vr0, r44;"
        "}"
        "{"
        "V0@(pr0)	vr0 = mul.f32 vr10, vr0;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 50062;"
        "pseudo@0	@pseudo imm_1 = 16985;"
        "V1@(pr0)	vr0 = add.f32 vr0, r44;"
        "}"
        "{"
        "V0@(pr0)	vr0 = mul.f32 vr10, vr0;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 797;"
        "pseudo@0	@pseudo imm_1 = 49670;"
        "V1@(pr0)	vr0 = add.f32 vr0, r44;"
        "}"
        "{"
        "V0@(pr0)	vr0 = mul.f32 vr10, vr0;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 47713;"
        "pseudo@0	@pseudo imm_1 = 16733;"
        "V1@(pr0)	vr0 = add.f32 vr0, r44;"
        "}"
        "{"
        "V0@(pr0)	vr0 = mul.f32 vr10, vr0;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 60865;"
        "pseudo@0	@pseudo imm_1 = 49291;"
        "V1@(pr0)	vr0 = add.f32 vr0, r44;"
        "}"
        "{"
        "V0@(pr0)	vr0 = mul.f32 vr10, vr0;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 61411;"
        "pseudo@0	@pseudo imm_1 = 16323;"
        "V1@(pr0)	vr0 = add.f32 vr0, r44;"
        "}"
        "{"
        "V0@(pr0)	vr0 = mul.f32 vr10, vr0;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 7611;"
        "pseudo@0	@pseudo imm_1 = 15604;"
        "V1@(pr0)	vr0 = add.f32 vr0, r44;"
        "}"
        "{"
        "V0@(pr0)	vr0 = mul.f32 vr10, vr0;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 2214;"
        "pseudo@0	@pseudo imm_1 = 47555;"
        "V1@(pr0)	vr0 = add.f32 vr0, r44;"
        "}"
        "{"
        "V0@(pr0)	vr0 = mul.f32 vr10, vr0;"
        "}"
        "{"
        "V1@(pr0)	vr10 = add.f32 vr0, vr10;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 65535;"
        "pseudo@0	@pseudo imm_1 = 32767;"
        "pseudo@0	@pseudo imm_2 = 32640;"
        "V0@(pr0)	vr0 = and.u32 vr10, r44;"
        "V1@(pr0)	vmsk1 = eq.s32 vr0, r38;"
        "}"
        "{"
        "V0@(pr0)	vr1 = mul.f32 vr0, r50;"
        "V1@(pr0)	vr2 = mov.u32 vr0;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 23007;"
        "pseudo@0	@pseudo imm_1 = 24375;"
        "V0@(pr0)	vr3 = mov.u32 r44;"
        "V1@(pr0)	vr2 = shr.u32 vr2, r48;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 16320;"
        "V0@(pr0)	vr2 = sub.s32 vr3, vr2;"
        "V1@(pr0)	vr4 = mov.u32 r36;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 32768;"
        "V0@(pr0)	vr3 = mul.f32 vr2, vr2;"
        "V1@(pr0)	vr6 = and.u32 vr10, r36;"
        "}"
        "{"
        "V0@(pr0)	vr5 = mul.f32 vr1, vr3;"
        "V1@(pr0)	vr5 = sub.f32 vr4, vr5;"
        "}"
        "{"
        "V0@(pr0)	vr5 = mul.f32 vr5, vr2;"
        "V1@(pr0)	vr2 = mov.u32 vr5;"
        "}"
        "{"
        "V0@(pr0)	vr3 = mul.f32 vr2, vr2;"
        "V1@(pr0)	vmsk0 = eq.f32 vr10, r46;"
        "}"
        "{"
        "V0@(pr0)	vr5 = mul.f32 vr1, vr3;"
        "V1@(pr0)	vr5 = sub.f32 vr4, vr5;"
        "}"
        "{"
        "V0@(pr0)	vr5 = mul.f32 vr5, vr2;"
        "V1@(pr0)	vr2 = mov.u32 vr5;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 32640;"
        "V0@(pr0)	vr3 = mul.f32 vr2, vr2;"
        "V1@(pr0)	vr7 = or.u32 vr6, r36;"
        "}"
        "{"
        "V0@(pr0)	vr5 = mul.f32 vr1, vr3;"
        "V1@(pr0)	vr5 = sub.f32 vr4, vr5;"
        "}"
        "{"
        "V0@(pr0)	vr5 = mul.f32 vr5, vr2;"
        "V1@(pr0)	vr2 = or.u32 vr6, r46;"
        "}"
        "{"
        "V0@(pr0)	vr1 = mul.f32 vr5, vr5;"
        "V1@(pr0)	vr1 = or.u32 vr6, vr1;"
        "}"
        "{"
        "V0@(pr0)	vr10 = sel vmsk0 vr1, vr7;"
        "V1@(pr0)	vr10 = sel vmsk1 vr10, vr2;"
        "}"
        "{"
        "V0@(pr0)	vr0 = mov.u32 r46;"
        "V1@(pr0)	vmsk0 = gteq.f32 vr11, r49;"
        "}"
        "{"
        "V1@(pr0)	vr11 = sub.f32 vr0, vr10;"
        "}"
        "{"
        "V0@(pr0)	vr10 = sel vmsk0 vr10, vr11;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 4;"
        "S0@(pr0)	r3 = add.s32 r9, r32;"
        "S1@(pr0)	r3 = ld [smem:r3];"
        "}"
        "{"
        "S0@(pr0)	r3 = add.s32 r3, r9;"
        "S1@(pr0)	r0 = ld [smem:r3];"
        "}"
        "{"
        "S1@(pr0)	r0 = ld [smem:r3];"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 0;"
        "pseudo@0	@pseudo imm_2 = 1;"
        "pseudo@0	@pseudo imm_4 = 0;"
        "pseudo@0	@pseudo vs_imm0 = 1;"
        "S0@(pr0)	r1 = add.s32 r0, r32;"
        "VL@(pr0)	vr0 = ld [vmem:1+2,4,0];"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 1024;"
        "pseudo@0	@pseudo imm_2 = 1;"
        "pseudo@0	@pseudo imm_4 = 0;"
        "pseudo@0	@pseudo vs_imm0 = 1;"
        "S0@(pr0)	r1 = add.s32 r0, r32;"
        "VL@(pr0)	vr11 = ld [vmem:1+2,4,0];"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 2048;"
        "pseudo@0	@pseudo imm_1 = 0;"
        "S0@(pr0)	r0 = add.s32 r0, r44;"
        "S1@(pr0)	[smem:r3] = st r0;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 23593;"
        "pseudo@0	@pseudo imm_1 = 15119;"
        "pseudo@0	@pseudo imm_2 = 49807;"
        "pseudo@0	@pseudo imm_3 = 16383;"
        "V0@(pr0)	vmsk0 = gteq.f32 vr11, r44;"
        "V1@(pr0)	vmsk1 = lseq.f32 vr11, r45;"
        "}"
        "{"
        "V1@(pr0)	vr1 = sel vmsk0 vr10, vr0;"
        "}"
        "{"
        "V1@(pr0)	vr1 = sel vmsk1 vr10, vr1;"
        "}"
        "{"
        "V0@(pr0)	vmsk0 = eq.f32 vr11, r46;"
        "V1@(pr0)	vmsk1 = eq.f32 vr11, r51;"
        "}"
        "{"
        "V1@(pr0)	vr10 = mov.u32 vr1;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_1 = 32640;"
        "V1@(pr0)	vr10 = sel vmsk0 vr10, r37;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_1 = 65408;"
        "V1@(pr0)	%[res0] = sel vmsk1 vr10, r37;"
        "}"
        : [res0] "=x" (result0)
        : [input0] "x" (a)
        :"vr4", "vr30", "vr10", "vr6", "vr12", "vr7", "vr15", "vr31", "vr1", "vr5", "vr0", "vr28", "vr13", "vr29", "vr2", "vr17", "vr16", "vr11", "vr14", "vr3", "r0", "r9", "r1", "r3", "r6", "r2", "vmsk3", "vmsk0", "vmsk5", "vmsk4", "vmsk7", "vmsk1", "vmsk2", "vmsk6"
        );
    return result0;
}

#endif // _ERFCINVF_WITHOUT_UNARY_H_
