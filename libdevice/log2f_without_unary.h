#ifndef _LOG2F_WITHOUT_UNARY_H_
#define _LOG2F_WITHOUT_UNARY_H_

inline float8_128 __dlc_log2f_without_unary(float8_128 a)
{
    float8_128 result0;
    asm (
        "{V0@(pr0)  vr10 = mov.u32 %[input0];}"
        "{"
        "pseudo@0       @pseudo imm_0 = 65535;"
        "pseudo@0       @pseudo imm_1 = 32767;"
        "V0@(pr0)       vr12 = and.u32 vr10, r44;"
        "V1@(pr0)       vmsk7 = eq.s32 vr12, r46;"
        "}"
        "{"
        "pseudo@0       @pseudo imm_0 = 32640;"
        "V0@(pr0)       vmsk5 = ls.s32 vr10, r36;"
        "V1@(pr0)       vr0 = add.f32 vr10, vr10;"
        "}"
        "{"
        "pseudo@0       @pseudo imm_0 = 128;"
        "V0@(pr0)       vmsk2 = ls.s32 vr10, r36;"
        "V1@(pr0)       vr28 = mov.u32 r46;"
        "}"
        "{"
        "V0@(pr0)       vmsk4 = ls.s32 vr10, r46;"
        "}"
        "{"
        "pseudo@0       @pseudo imm_0 = 25;"
        "V0@(pr0)       vr29 = sub.s32 vr28, r32;"
        "V1@(pr0)       vr28 = sel vmsk2 vr28, vr29;"
        "}"
        "{"
        "pseudo@0       @pseudo imm_0 = 19456;"
        "V0@(pr0)       vr29 = mul.f32 vr10, r36;"
        "V1@(pr0)       vr10 = sel vmsk2 vr10, vr29;"
        "}"
        "{"
        "pseudo@0       @pseudo imm_0 = 23;"
        "V0@(pr0)       vmsk6 = ls.s32 vr10, r46;"
        "V1@(pr0)       vr13 = shr.u32 vr12, r32;"
        "}"
        "{"
        "pseudo@0       @pseudo imm_0 = 127;"
        "V1@(pr0)       vr14 = sub.s32 vr13, r32;"
        "}"
        "{"
        "V1@(pr0)       vr13 = add.s32 vr14, r46;"
        "}"
        "{"
        "pseudo@0       @pseudo imm_0 = 65535;"
        "pseudo@0       @pseudo imm_1 = 127;"
        "V0@(pr0)       vr12 = and.u32 vr12, r44;"
        "}"
        "{"
        "pseudo@0       @pseudo imm_0 = 24420;"
        "pseudo@0       @pseudo imm_1 = 9;"
        "pseudo@0       @pseudo imm_2 = 3;"
        "V0@(pr0)       vr14 = mov.u32 r44;"
        "V1@(pr0)       vr15 = shl.u32 vr14, r34;"
        "}"
        "{"
        "V1@(pr0)       vr14 = add.s32 vr12, vr15;"
        "}"
        "{"
        "pseudo@0       @pseudo imm_0 = 128;"
        "pseudo@0       @pseudo imm_1 = 23;"
        "V0@(pr0)       vr1 = and.u32 vr14, r36;"
        "V1@(pr0)       vr14 = shr.u32 vr1, r33;"
        "}"
        "{"
        "V0@(pr0)       vr13 = add.s32 vr13, vr14;"
        "V1@(pr0)       vmsk2 = eq.s32 vr13, r46;"
        "}"
        "{"
        "V0@(pr0)       vr13 = add.s32 vr13, vr28;"
        "}"
        "{"
        "pseudo@0       @pseudo imm_0 = 16256;"
        "V0@(pr0)       vr16 = xor.u32 vr1, r36;"
        "V1@(pr0)       vr10 = or.u32 vr12, vr16;"
        "}"
        "{"
        "V0@(pr0)       vr13 = cvtinttof.f32 vr13;"
        "}"
        "{"
        "pseudo@0       @pseudo imm_0 = 29056;"
        "pseudo@0       @pseudo imm_1 = 16177;"
        "V0@(pr0)       vr17 = mul.f32 vr13, r44;"
        "V1@(pr0)       vr14 = sub.f32 vr10, r49;"
        "}"
        "{"
        "V1@(pr0)       vr15 = add.f32 vr14, r51;"
        "}"
        "{"
        "pseudo@0       @pseudo imm_0 = 65535;"
        "pseudo@0       @pseudo imm_1 = 32767;"
        "pseudo@0       @pseudo imm_2 = 0;"
        "pseudo@0       @pseudo imm_3 = 32640;"
        "V0@(pr0)       vr30 = and.u32 vr15, r44;"
        "V1@(pr0)       vmsk3 = eq.s32 vr30, r45;"
        "}"
        "{"
        "V0@(pr0)       vr31 = mul.f32 vr30, r50;"
        "V1@(pr0)       vr2 = mov.u32 vr30;"
        "}"
        "{"
        "pseudo@0       @pseudo imm_0 = 23007;"
        "pseudo@0       @pseudo imm_1 = 24375;"
        "V0@(pr0)       vr3 = mov.u32 r44;"
        "V1@(pr0)       vr2 = shr.u32 vr2, r48;"
        "}"
        "{"
        "pseudo@0       @pseudo imm_0 = 16320;"
        "V0@(pr0)       vr2 = sub.s32 vr3, vr2;"
        "V1@(pr0)       vr4 = mov.u32 r36;"
        "}"
        "{"
        "pseudo@0       @pseudo imm_0 = 32768;"
        "V0@(pr0)       vr3 = mul.f32 vr2, vr2;"
        "V1@(pr0)       vr6 = and.u32 vr15, r36;"
        "}"
        "{"
        "V0@(pr0)       vr5 = mul.f32 vr31, vr3;"
        "V1@(pr0)       vr5 = sub.f32 vr4, vr5;"
        "}"
        "{"
        "V0@(pr0)       vr5 = mul.f32 vr5, vr2;"
        "V1@(pr0)       vr2 = mov.u32 vr5;"
        "}"
        "{"
        "V0@(pr0)       vr3 = mul.f32 vr2, vr2;"
        "V1@(pr0)       vmsk0 = eq.f32 vr15, r46;"
        "}"
        "{"
        "V0@(pr0)       vr5 = mul.f32 vr31, vr3;"
        "V1@(pr0)       vr5 = sub.f32 vr4, vr5;"
        "}"
        "{"
        "V0@(pr0)       vr5 = mul.f32 vr5, vr2;"
        "V1@(pr0)       vr2 = mov.u32 vr5;"
        "}"
        "{"
        "pseudo@0       @pseudo imm_0 = 0;"
        "pseudo@0       @pseudo imm_1 = 32640;"
        "V0@(pr0)       vr3 = mul.f32 vr2, vr2;"
        "V1@(pr0)       vr7 = or.u32 vr6, r44;"
        "}"
        "{"
        "V0@(pr0)       vr5 = mul.f32 vr31, vr3;"
        "V1@(pr0)       vr5 = sub.f32 vr4, vr5;"
        "}"
        "{"
        "V0@(pr0)       vr5 = mul.f32 vr5, vr2;"
        "V1@(pr0)       vr2 = or.u32 vr6, r46;"
        "}"
        "{"
        "V0@(pr0)       vr31 = mul.f32 vr5, vr5;"
        "V1@(pr0)       vr31 = or.u32 vr6, vr31;"
        "}"
        "{"
        "V0@(pr0)       vr15 = sel vmsk0 vr31, vr7;"
        "V1@(pr0)       vr15 = sel vmsk3 vr15, vr2;"
        "}"
        "{"
        "pseudo@0       @pseudo imm_0 = 5242;"
        "pseudo@0       @pseudo imm_1 = 6;"
        "V0@(pr0)       vr15 = mul.f32 vr14, vr15;"
        "V1@(pr0)       vr16 = mov.u32 r44;"
        "}"
        "{"
        "pseudo@0       @pseudo imm_0 = 3;"
        "V1@(pr0)       vr16 = shl.u32 vr16, r32;"
        "}"
        "{"
        "V0@(pr0)       vr7 = mul.f32 vr15, vr15;"
        "V1@(pr0)       vr1 = sub.s32 vr12, vr16;"
        "}"
        "{"
        "pseudo@0       @pseudo imm_0 = 47185;"
        "pseudo@0       @pseudo imm_1 = 6;"
        "V0@(pr0)       vr3 = mul.f32 vr7, vr7;"
        "V1@(pr0)       vr16 = mov.u32 r44;"
        "}"
        "{"
        "pseudo@0       @pseudo imm_0 = 3;"
        "V1@(pr0)       vr16 = shl.u32 vr16, r32;"
        "}"
        "{"
        "V1@(pr0)       vr4 = sub.s32 vr16, vr12;"
        "}"
        "{"
        "pseudo@0       @pseudo imm_0 = 53327;"
        "pseudo@0       @pseudo imm_1 = 15900;"
        "pseudo@0       @pseudo imm_2 = 36393;"
        "pseudo@0       @pseudo imm_3 = 15971;"
        "V0@(pr0)       vr5 = mul.f32 vr3, r44;"
        "V1@(pr0)       vr6 = add.f32 vr5, r45;"
        "}"
        "{"
        "pseudo@0       @pseudo imm_0 = 52429;"
        "pseudo@0       @pseudo imm_1 = 16076;"
        "V0@(pr0)       vr5 = mul.f32 vr3, vr6;"
        "V1@(pr0)       vr6 = add.f32 vr5, r44;"
        "}"
        "{"
        "V0@(pr0)       vr5 = mul.f32 vr3, vr6;"
        "}"
        "{"
        "pseudo@0       @pseudo imm_0 = 34967;"
        "pseudo@0       @pseudo imm_1 = 15895;"
        "pseudo@0       @pseudo imm_2 = 13093;"
        "pseudo@0       @pseudo imm_3 = 15930;"
        "V0@(pr0)       vr2 = mul.f32 vr3, r44;"
        "V1@(pr0)       vr6 = add.f32 vr2, r45;"
        "}"
        "{"
        "pseudo@0       @pseudo imm_0 = 18725;"
        "pseudo@0       @pseudo imm_1 = 16018;"
        "V0@(pr0)       vr2 = mul.f32 vr3, vr6;"
        "V1@(pr0)       vr6 = add.f32 vr2, r44;"
        "}"
        "{"
        "pseudo@0       @pseudo imm_0 = 43691;"
        "pseudo@0       @pseudo imm_1 = 16170;"
        "V0@(pr0)       vr2 = mul.f32 vr3, vr6;"
        "V1@(pr0)       vr6 = add.f32 vr2, r44;"
        "}"
        "{"
        "V0@(pr0)       vr2 = mul.f32 vr7, vr6;"
        "V1@(pr0)       vr7 = add.f32 vr2, vr5;"
        "}"
        "{"
        "V0@(pr0)       vr1 = or.u32 vr1, vr4;"
        "V1@(pr0)       vmsk0 = gt.f32 vr1, r46;"
        "}"
        "{"
        "V0@(pr0)       vr2 = mul.f32 vr14, vr14;"
        "}"
        "{"
        "V0@(pr0)       vr4 = mul.f32 vr2, r50;"
        "V1@(pr0)       vr1 = add.f32 vr4, vr7;"
        "}"
        "{"
        "V0@(pr0)       vr2 = mul.f32 vr15, vr1;"
        "V1@(pr0)       vr5 = sub.f32 vr4, vr2;"
        "}"
        "{"
        "pseudo@0       @pseudo imm_0 = 63441;"
        "pseudo@0       @pseudo imm_1 = 14103;"
        "V0@(pr0)       vr16 = mul.f32 vr13, r44;"
        "V1@(pr0)       vr6 = sub.f32 vr14, vr5;"
        "}"
        "{"
        "V1@(pr0)       vr3 = add.f32 vr2, vr16;"
        "}"
        "{"
        "V1@(pr0)       vr1 = sub.f32 vr4, vr3;"
        "}"
        "{"
        "V1@(pr0)       vr1 = sub.f32 vr1, vr14;"
        "}"
        "{"
        "V1@(pr0)       vr1 = sub.f32 vr17, vr1;"
        "}"
        "{"
        "V1@(pr0)       vr2 = sub.f32 vr14, vr7;"
        "}"
        "{"
        "V0@(pr0)       vr4 = mul.f32 vr15, vr2;"
        "V1@(pr0)       vr2 = sub.f32 vr14, vr4;"
        "}"
        "{"
        "V1@(pr0)       vr5 = sub.f32 vr4, vr16;"
        "}"
        "{"
        "V1@(pr0)       vr7 = sub.f32 vr5, vr14;"
        "}"
        "{"
        "V1@(pr0)       vr5 = sub.f32 vr17, vr7;"
        "}"
        "{"
        "pseudo@0       @pseudo imm_0 = 43690;"
        "pseudo@0       @pseudo imm_1 = 16042;"
        "V0@(pr0)       vr4 = mul.f32 vr14, r44;"
        "}"
        "{"
        "V0@(pr0)       vr15 = mov.u32 r50;"
        "V1@(pr0)       vr7 = sub.f32 vr15, vr4;"
        "}"
        "{"
        "V0@(pr0)       vr4 = mul.f32 vr14, vr14;"
        "}"
        "{"
        "V0@(pr0)       vr7 = mul.f32 vr4, vr7;"
        "}"
        "{"
        "V1@(pr0)       vr15 = sub.f32 vr14, vr7;"
        "}"
        "{"
        "V0@(pr0)       vmsk1 = eq.f32 vr14, r46;"
        "V1@(pr0)       vr4 = sub.f32 vr7, vr16;"
        "}"
        "{"
        "V1@(pr0)       vr7 = sub.f32 vr4, vr14;"
        "}"
        "{"
        "V1@(pr0)       vr4 = sub.f32 vr17, vr7;"
        "}"
        "{"
        "V1@(pr0)       vr3 = add.f32 vr16, vr17;"
        "}"
        "{"
        "pseudo@0       @pseudo imm_0 = 15;"
        "V1@(pr0)       vr7 = add.s32 vr12, r32;"
        "}"
        "{"
        "pseudo@0       @pseudo imm_0 = 65535;"
        "pseudo@0       @pseudo imm_1 = 127;"
        "V0@(pr0)       vr16 = and.u32 vr7, r44;"
        "}"
        "{"
        "pseudo@0       @pseudo imm_0 = 16;"
        "V0@(pr0)       vmsk3 = ls.s32 vr16, r32;"
        "}"
        "{"
        "V0@(pr0)       vr13 = sel vmsk2 vr1, vr6;"
        "V1@(pr0)       vr14 = sel vmsk2 vr5, vr2;"
        "}"
        "{"
        "V0@(pr0)       vr16 = sel vmsk2 vr3, r46;"
        "V1@(pr0)       vr17 = sel vmsk2 vr4, vr15;"
        "}"
        "{"
        "V0@(pr0)       vr1 = sel vmsk0 vr14, vr13;"
        "V1@(pr0)       vr2 = sel vmsk1 vr17, vr16;"
        "}"
        "{"
        "V0@(pr0)       vr10 = sel vmsk3 vr1, vr2;"
        "}"
        "{"
        "pseudo@0       @pseudo imm_0 = 65528;"
        "V0@(pr0)       vr10 = sel vmsk6 vr10, r36;"
        "V1@(pr0)       vr10 = sel vmsk5 vr0, vr10;"
        "}"
        "{"
        "pseudo@0       @pseudo imm_0 = 32704;"
        "V0@(pr0)       vr10 = sel vmsk4 vr10, r36;"
        "}"
        "{"
        "pseudo@0       @pseudo imm_0 = 65408;"
        "V0@(pr0)       vr10 = sel vmsk7 vr10, r36;"
        "}"
        "{"
        "pseudo@0       @pseudo imm_0 = 43579;"
        "pseudo@0       @pseudo imm_1 = 16312;"
        "V0@(pr0)       vr12 = mov.u32 r44;"
        "}"
        "{"
        "V0@(pr0)       %[res0] = mul.f32 vr10, vr12;"
        "}"
        : [res0] "=x" (result0)
        : [input0] "x" (a)
        :"vr4", "vr30", "vr10", "vr6", "vr12", "vr7", "vr15", "vr31", "vr1", "vr5", "vr0", "vr28", "vr13", "vr29", "vr2", "vr17", "vr16", "vr3", "vr14", "vmsk3", "vmsk0", "vmsk5", "vmsk4", "vmsk7", "vmsk1", "vmsk2", "vmsk6"
        );
    return result0;
}

#endif // _LOG2F_WITHOUT_UNARY_H_
