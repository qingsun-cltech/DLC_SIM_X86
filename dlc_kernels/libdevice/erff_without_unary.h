#pragma once
#include "../../dlc-intrinsics.h"
#include "../../typehint.h"

inline float8_128 __dlc_erff_without_unary(float8_128 a)
{
    float8_128 result0;
    asm (
        "{V0@(pr0)  vr10 = mov.u32 %[input0];}"
        "{"
        "pseudo@0	@pseudo imm_0 = 65535;"
        "pseudo@0	@pseudo imm_1 = 32767;"
        "V0@(pr0)	vr0 = mov.u32 r44;"
        "}"
        "{"
        "V0@(pr0)	vr1 = and.u32 vr10, vr0;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 16576;"
        "V0@(pr0)	vr4 = mov.u32 r36;"
        "}"
        "{"
        "V0@(pr0)	vmsk1 = ls.s32 vr1, vr4;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 16992;"
        "pseudo@0	@pseudo imm_1 = 3490;"
        "V0@(pr0)	vr4 = mov.u32 r44;"
        "}"
        "{"
        "V1@(pr0)	vr5 = sub.f32 vr3, vr4;"
        "}"
        "{"
        "V1@(pr0)	vr6 = sub.f32 vr4, vr3;"
        "}"
        "{"
        "V0@(pr0)	vr30 = sel vmsk1 vr6, r46;"
        "}"
        "{"
        "V0@(pr0)	vr30 = sel vmsk0 vr30, vr6;"
        "}"
        "{"
        "V0@(pr0)	vr0 = mul.f32 vr1, vr1;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 65535;"
        "pseudo@0	@pseudo imm_1 = 32767;"
        "pseudo@0	@pseudo imm_2 = 32640;"
        "V0@(pr0)	vr28 = and.u32 vr0, r44;"
        "V1@(pr0)	vmsk7 = eq.s32 vr28, r38;"
        "}"
        "{"
        "V0@(pr0)	vr11 = mul.f32 vr28, r50;"
        "V1@(pr0)	vr12 = mov.u32 vr28;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 23007;"
        "pseudo@0	@pseudo imm_1 = 24375;"
        "V0@(pr0)	vr13 = mov.u32 r44;"
        "V1@(pr0)	vr12 = shr.u32 vr12, r48;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 16320;"
        "V0@(pr0)	vr12 = sub.s32 vr13, vr12;"
        "V1@(pr0)	vr14 = mov.u32 r36;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 32768;"
        "V0@(pr0)	vr13 = mul.f32 vr12, vr12;"
        "V1@(pr0)	vr16 = and.u32 vr0, r36;"
        "}"
        "{"
        "V0@(pr0)	vr15 = mul.f32 vr11, vr13;"
        "V1@(pr0)	vr15 = sub.f32 vr14, vr15;"
        "}"
        "{"
        "V0@(pr0)	vr15 = mul.f32 vr15, vr12;"
        "V1@(pr0)	vr12 = mov.u32 vr15;"
        "}"
        "{"
        "V0@(pr0)	vr13 = mul.f32 vr12, vr12;"
        "V1@(pr0)	vmsk6 = eq.f32 vr0, r46;"
        "}"
        "{"
        "V0@(pr0)	vr15 = mul.f32 vr11, vr13;"
        "V1@(pr0)	vr15 = sub.f32 vr14, vr15;"
        "}"
        "{"
        "V0@(pr0)	vr15 = mul.f32 vr15, vr12;"
        "V1@(pr0)	vr12 = mov.u32 vr15;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 32640;"
        "V0@(pr0)	vr13 = mul.f32 vr12, vr12;"
        "V1@(pr0)	vr17 = or.u32 vr16, r36;"
        "}"
        "{"
        "V0@(pr0)	vr15 = mul.f32 vr11, vr13;"
        "V1@(pr0)	vr15 = sub.f32 vr14, vr15;"
        "}"
        "{"
        "V0@(pr0)	vr15 = mul.f32 vr15, vr12;"
        "V1@(pr0)	vr12 = or.u32 vr16, r46;"
        "}"
        "{"
        "V0@(pr0)	vr11 = mul.f32 vr15, vr15;"
        "V1@(pr0)	vr11 = or.u32 vr16, vr11;"
        "}"
        "{"
        "V0@(pr0)	vr0 = sel vmsk6 vr11, vr17;"
        "V1@(pr0)	vr0 = sel vmsk7 vr0, vr12;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 16256;"
        "V0@(pr0)	vr3 = mov.u32 r36;"
        "}"
        "{"
        "V0@(pr0)	vr0 = mul.f32 vr0, vr3;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 56174;"
        "pseudo@0	@pseudo imm_1 = 16438;"
        "V0@(pr0)	vr4 = mov.u32 r44;"
        "}"
        "{"
        "V0@(pr0)	vmsk0 = gteq.s32 vr1, vr4;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 49781;"
        "pseudo@0	@pseudo imm_1 = 50161;"
        "V0@(pr0)	vr4 = mov.u32 r44;"
        "}"
        "{"
        "V0@(pr0)	vr4 = mul.f32 vr4, vr0;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 8971;"
        "pseudo@0	@pseudo imm_1 = 50304;"
        "V0@(pr0)	vr5 = mov.u32 r44;"
        "}"
        "{"
        "V1@(pr0)	vr4 = add.f32 vr4, vr5;"
        "}"
        "{"
        "V0@(pr0)	vr4 = mul.f32 vr4, vr0;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 25665;"
        "pseudo@0	@pseudo imm_1 = 50207;"
        "V0@(pr0)	vr5 = mov.u32 r44;"
        "}"
        "{"
        "V1@(pr0)	vr4 = add.f32 vr4, vr5;"
        "}"
        "{"
        "V0@(pr0)	vr4 = mul.f32 vr4, vr0;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 41706;"
        "pseudo@0	@pseudo imm_1 = 49952;"
        "V0@(pr0)	vr5 = mov.u32 r44;"
        "}"
        "{"
        "V1@(pr0)	vr4 = add.f32 vr4, vr5;"
        "}"
        "{"
        "V0@(pr0)	vr4 = mul.f32 vr4, vr0;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 4171;"
        "pseudo@0	@pseudo imm_1 = 49550;"
        "V0@(pr0)	vr5 = mov.u32 r44;"
        "}"
        "{"
        "V1@(pr0)	vr4 = add.f32 vr4, vr5;"
        "}"
        "{"
        "V0@(pr0)	vr4 = mul.f32 vr4, vr0;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 40404;"
        "pseudo@0	@pseudo imm_1 = 48972;"
        "V0@(pr0)	vr5 = mov.u32 r44;"
        "}"
        "{"
        "V1@(pr0)	vr4 = add.f32 vr4, vr5;"
        "}"
        "{"
        "V0@(pr0)	vr4 = mul.f32 vr4, vr0;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 41106;"
        "pseudo@0	@pseudo imm_1 = 48161;"
        "V0@(pr0)	vr5 = mov.u32 r44;"
        "}"
        "{"
        "V1@(pr0)	vr4 = add.f32 vr4, vr5;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 34578;"
        "pseudo@0	@pseudo imm_1 = 49587;"
        "V0@(pr0)	vr5 = mov.u32 r44;"
        "}"
        "{"
        "V0@(pr0)	vr5 = mul.f32 vr5, vr0;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 17319;"
        "pseudo@0	@pseudo imm_1 = 17389;"
        "V0@(pr0)	vr6 = mov.u32 r44;"
        "}"
        "{"
        "V1@(pr0)	vr5 = add.f32 vr5, vr6;"
        "}"
        "{"
        "V0@(pr0)	vr5 = mul.f32 vr5, vr0;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 37070;"
        "pseudo@0	@pseudo imm_1 = 17695;"
        "V0@(pr0)	vr6 = mov.u32 r44;"
        "}"
        "{"
        "V1@(pr0)	vr5 = add.f32 vr5, vr6;"
        "}"
        "{"
        "V0@(pr0)	vr5 = mul.f32 vr5, vr0;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 64955;"
        "pseudo@0	@pseudo imm_1 = 17735;"
        "V0@(pr0)	vr6 = mov.u32 r44;"
        "}"
        "{"
        "V1@(pr0)	vr5 = add.f32 vr5, vr6;"
        "}"
        "{"
        "V0@(pr0)	vr5 = mul.f32 vr5, vr0;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 5977;"
        "pseudo@0	@pseudo imm_1 = 17600;"
        "V0@(pr0)	vr6 = mov.u32 r44;"
        "}"
        "{"
        "V1@(pr0)	vr5 = add.f32 vr5, vr6;"
        "}"
        "{"
        "V0@(pr0)	vr5 = mul.f32 vr5, vr0;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 58737;"
        "pseudo@0	@pseudo imm_1 = 17314;"
        "V0@(pr0)	vr6 = mov.u32 r44;"
        "}"
        "{"
        "V1@(pr0)	vr5 = add.f32 vr5, vr6;"
        "}"
        "{"
        "V0@(pr0)	vr5 = mul.f32 vr5, vr0;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 46169;"
        "pseudo@0	@pseudo imm_1 = 16882;"
        "V0@(pr0)	vr6 = mov.u32 r44;"
        "}"
        "{"
        "V1@(pr0)	vr5 = add.f32 vr5, vr6;"
        "}"
        "{"
        "V0@(pr0)	vr5 = mul.f32 vr5, vr0;"
        "}"
        "{"
        "V1@(pr0)	vr5 = add.f32 vr5, vr3;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 1918;"
        "pseudo@0	@pseudo imm_1 = 49437;"
        "V0@(pr0)	vr14 = mov.u32 r44;"
        "}"
        "{"
        "V0@(pr0)	vr14 = mul.f32 vr14, vr0;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 37675;"
        "pseudo@0	@pseudo imm_1 = 49826;"
        "V0@(pr0)	vr15 = mov.u32 r44;"
        "}"
        "{"
        "V1@(pr0)	vr14 = add.f32 vr14, vr15;"
        "}"
        "{"
        "V0@(pr0)	vr14 = mul.f32 vr14, vr0;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 39655;"
        "pseudo@0	@pseudo imm_1 = 49976;"
        "V0@(pr0)	vr15 = mov.u32 r44;"
        "}"
        "{"
        "V1@(pr0)	vr14 = add.f32 vr14, vr15;"
        "}"
        "{"
        "V0@(pr0)	vr14 = mul.f32 vr14, vr0;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 25996;"
        "pseudo@0	@pseudo imm_1 = 49954;"
        "V0@(pr0)	vr15 = mov.u32 r44;"
        "}"
        "{"
        "V1@(pr0)	vr14 = add.f32 vr14, vr15;"
        "}"
        "{"
        "V0@(pr0)	vr14 = mul.f32 vr14, vr0;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 32855;"
        "pseudo@0	@pseudo imm_1 = 49785;"
        "V0@(pr0)	vr15 = mov.u32 r44;"
        "}"
        "{"
        "V1@(pr0)	vr14 = add.f32 vr14, vr15;"
        "}"
        "{"
        "V0@(pr0)	vr14 = mul.f32 vr14, vr0;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 61474;"
        "pseudo@0	@pseudo imm_1 = 49448;"
        "V0@(pr0)	vr15 = mov.u32 r44;"
        "}"
        "{"
        "V1@(pr0)	vr14 = add.f32 vr14, vr15;"
        "}"
        "{"
        "V0@(pr0)	vr14 = mul.f32 vr14, vr0;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 41143;"
        "pseudo@0	@pseudo imm_1 = 48945;"
        "V0@(pr0)	vr15 = mov.u32 r44;"
        "}"
        "{"
        "V1@(pr0)	vr14 = add.f32 vr14, vr15;"
        "}"
        "{"
        "V0@(pr0)	vr14 = mul.f32 vr14, vr0;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 41107;"
        "pseudo@0	@pseudo imm_1 = 48161;"
        "V0@(pr0)	vr15 = mov.u32 r44;"
        "}"
        "{"
        "V1@(pr0)	vr14 = add.f32 vr14, vr15;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 32663;"
        "pseudo@0	@pseudo imm_1 = 48503;"
        "V0@(pr0)	vr15 = mov.u32 r44;"
        "}"
        "{"
        "V0@(pr0)	vr15 = mul.f32 vr15, vr0;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 16252;"
        "pseudo@0	@pseudo imm_1 = 16594;"
        "V0@(pr0)	vr16 = mov.u32 r44;"
        "}"
        "{"
        "V1@(pr0)	vr15 = add.f32 vr15, vr16;"
        "}"
        "{"
        "V0@(pr0)	vr15 = mul.f32 vr15, vr0;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 17695;"
        "pseudo@0	@pseudo imm_1 = 17113;"
        "V0@(pr0)	vr16 = mov.u32 r44;"
        "}"
        "{"
        "V1@(pr0)	vr15 = add.f32 vr15, vr16;"
        "}"
        "{"
        "V0@(pr0)	vr15 = mul.f32 vr15, vr0;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 33035;"
        "pseudo@0	@pseudo imm_1 = 17366;"
        "V0@(pr0)	vr16 = mov.u32 r44;"
        "}"
        "{"
        "V1@(pr0)	vr15 = add.f32 vr15, vr16;"
        "}"
        "{"
        "V0@(pr0)	vr15 = mul.f32 vr15, vr0;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 22729;"
        "pseudo@0	@pseudo imm_1 = 17441;"
        "V0@(pr0)	vr16 = mov.u32 r44;"
        "}"
        "{"
        "V1@(pr0)	vr15 = add.f32 vr15, vr16;"
        "}"
        "{"
        "V0@(pr0)	vr15 = mul.f32 vr15, vr0;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 18543;"
        "pseudo@0	@pseudo imm_1 = 17369;"
        "V0@(pr0)	vr16 = mov.u32 r44;"
        "}"
        "{"
        "V1@(pr0)	vr15 = add.f32 vr15, vr16;"
        "}"
        "{"
        "V0@(pr0)	vr15 = mul.f32 vr15, vr0;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 43107;"
        "pseudo@0	@pseudo imm_1 = 17161;"
        "V0@(pr0)	vr16 = mov.u32 r44;"
        "}"
        "{"
        "V1@(pr0)	vr15 = add.f32 vr15, vr16;"
        "}"
        "{"
        "V0@(pr0)	vr15 = mul.f32 vr15, vr0;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 13774;"
        "pseudo@0	@pseudo imm_1 = 16797;"
        "V0@(pr0)	vr16 = mov.u32 r44;"
        "}"
        "{"
        "V1@(pr0)	vr15 = add.f32 vr15, vr16;"
        "}"
        "{"
        "V0@(pr0)	vr15 = mul.f32 vr15, vr0;"
        "}"
        "{"
        "V1@(pr0)	vr15 = add.f32 vr15, vr3;"
        "}"
        "{"
        "V0@(pr0)	vr4 = sel vmsk0 vr14, vr4;"
        "}"
        "{"
        "V1@(pr0)	vr5 = sel vmsk0 vr15, vr5;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 61440;"
        "V0@(pr0)	vr6 = mov.u32 r40;"
        "}"
        "{"
        "V0@(pr0)	vr6 = and.u32 vr1, vr6;"
        "}"
        "{"
        "V0@(pr0)	vr7 = mul.f32 vr6, vr6;"
        "}"
        "{"
        "V0@(pr0)	vr7 = mul.f32 vr7, r57;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 16144;"
        "V0@(pr0)	vr12 = mov.u32 r36;"
        "}"
        "{"
        "V1@(pr0)	vr7 = sub.f32 vr7, vr12;"
        "}"
        "{"
        "V1@(pr0)	vmsk5 = ls.f32 vr7, r46;"
        "}"
        "{"
        "V0@(pr0)	vr12 = mov.u32 vr30;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 4;"
        "S0@(pr0)	r3 = add.s32 r9, r32;"
        "S1@(pr0)	r3 = ld [smem:r3];"
        "}"
        "{"
        "S0@(pr0)	r3 = add.s32 r3, r9;"
        "S1@(pr0)	r0 = ld [smem:r3];"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 8192;"
        "pseudo@0	@pseudo imm_1 = 0;"
        "S1@(pr0)	r0 = sub.s32 r0, r44;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 0;"
        "pseudo@0	@pseudo imm_2 = 1;"
        "pseudo@0	@pseudo imm_4 = 0;"
        "pseudo@0	@pseudo vs_imm0 = 1;"
        "S0@(pr0)	r1 = add.s32 r0, r32;"
        "VS@(pr0)	[vmem:1+2,4,0] = st vr1;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 1024;"
        "pseudo@0	@pseudo imm_2 = 1;"
        "pseudo@0	@pseudo imm_4 = 0;"
        "pseudo@0	@pseudo vs_imm0 = 1;"
        "S0@(pr0)	r1 = add.s32 r0, r32;"
        "VS@(pr0)	[vmem:1+2,4,0] = st vr0;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 2048;"
        "pseudo@0	@pseudo imm_2 = 1;"
        "pseudo@0	@pseudo imm_4 = 0;"
        "pseudo@0	@pseudo vs_imm0 = 1;"
        "S0@(pr0)	r1 = add.s32 r0, r32;"
        "VS@(pr0)	[vmem:1+2,4,0] = st vr3;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 3072;"
        "pseudo@0	@pseudo imm_2 = 1;"
        "pseudo@0	@pseudo imm_4 = 0;"
        "pseudo@0	@pseudo vs_imm0 = 1;"
        "S0@(pr0)	r1 = add.s32 r0, r32;"
        "VS@(pr0)	[vmem:1+2,4,0] = st vr4;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 4096;"
        "pseudo@0	@pseudo imm_2 = 1;"
        "pseudo@0	@pseudo imm_4 = 0;"
        "pseudo@0	@pseudo vs_imm0 = 1;"
        "S0@(pr0)	r1 = add.s32 r0, r32;"
        "VS@(pr0)	[vmem:1+2,4,0] = st vr5;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 5120;"
        "pseudo@0	@pseudo imm_2 = 1;"
        "pseudo@0	@pseudo imm_4 = 0;"
        "pseudo@0	@pseudo vs_imm0 = 1;"
        "S0@(pr0)	r1 = add.s32 r0, r32;"
        "VS@(pr0)	[vmem:1+2,4,0] = st vr6;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 6144;"
        "pseudo@0	@pseudo imm_2 = 1;"
        "pseudo@0	@pseudo imm_4 = 0;"
        "pseudo@0	@pseudo vs_imm0 = 1;"
        "S0@(pr0)	r1 = add.s32 r0, r32;"
        "VS@(pr0)	[vmem:1+2,4,0] = st vr12;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 7168;"
        "pseudo@0	@pseudo imm_2 = 1;"
        "pseudo@0	@pseudo imm_4 = 0;"
        "pseudo@0	@pseudo vs_imm0 = 1;"
        "S0@(pr0)	r1 = add.s32 r0, r32;"
        "VS@(pr0)	[vmem:1+2,4,0] = st vr10;"
        "}"
        "{"
        "S1@(pr0)	[smem:r3] = st r0;"
        "}"
        "{"
        "V0@(pr0)	vr10 = mov.u32 vr7;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 65535;"
        "pseudo@0	@pseudo imm_1 = 32767;"
        "V0@(pr0)	vr10 = and.u32 vr10, r44;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 65535;"
        "pseudo@0	@pseudo imm_1 = 32767;"
        "V0@(pr0)	vr0 = and.u32 vr10, r44;"
        "V1@(pr0)	vr1 = mov.u32 r46;"
        "}"
        "{"
        "V0@(pr0)	vr2 = mov.u32 r46;"
        "V1@(pr0)	vr3 = mov.u32 r46;"
        "}"
        "{"
        "V0@(pr0)	vr4 = and.u32 vr10, r47;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 29056;"
        "pseudo@0	@pseudo imm_1 = 16177;"
        "V0@(pr0)	vmsk0 = eq.s32 vr4, r47;"
        "V1@(pr0)	vr5 = mov.u32 r44;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 29056;"
        "pseudo@0	@pseudo imm_1 = 48945;"
        "pseudo@0	@pseudo imm_2 = 63441;"
        "pseudo@0	@pseudo imm_3 = 14103;"
        "V0@(pr0)	vr5 = sel vmsk0 vr5, r44;"
        "V1@(pr0)	vr6 = mov.u32 r45;"
        "}"
        "{"
        "V1@(pr0)	vr5 = sub.f32 vr10, vr5;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 63441;"
        "pseudo@0	@pseudo imm_1 = 46871;"
        "V0@(pr0)	vr6 = sel vmsk0 vr6, r44;"
        "V1@(pr0)	vr7 = mov.u32 r48;"
        "}"
        "{"
        "V0@(pr0)	vr7 = sel vmsk0 vr7, r56;"
        "V1@(pr0)	vr14 = mov.u32 r50;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 43579;"
        "pseudo@0	@pseudo imm_1 = 16312;"
        "V0@(pr0)	vr13 = mul.f32 vr10, r44;"
        "V1@(pr0)	vr14 = sel vmsk0 vr14, r58;"
        "}"
        "{"
        "V1@(pr0)	vr13 = add.f32 vr13, vr14;"
        "}"
        "{"
        "V0@(pr0)	vr14 = cvtftoint.s32 vr13, r56;"
        "V1@(pr0)	vr13 = cvtinttof.f32 vr14;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 29056;"
        "pseudo@0	@pseudo imm_1 = 16177;"
        "V0@(pr0)	vr15 = mul.f32 vr13, r44;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 63441;"
        "pseudo@0	@pseudo imm_1 = 14103;"
        "V0@(pr0)	vr16 = mul.f32 vr13, r44;"
        "V1@(pr0)	vr15 = sub.f32 vr10, vr15;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 29208;"
        "pseudo@0	@pseudo imm_1 = 16049;"
        "pseudo@0	@pseudo imm_2 = 5522;"
        "pseudo@0	@pseudo imm_3 = 16261;"
        "V0@(pr0)	vmsk0 = gt.s32 vr0, r44;"
        "V1@(pr0)	vmsk1 = ls.s32 vr0, r45;"
        "}"
        "{"
        "V0@(pr0)	vr5 = sel vmsk1 vr15, vr5;"
        "V1@(pr0)	vr6 = sel vmsk1 vr16, vr6;"
        "}"
        "{"
        "V0@(pr0)	vr7 = sel vmsk1 vr14, vr7;"
        "}"
        "{"
        "V0@(pr0)	vr1 = sel vmsk0 vr1, vr5;"
        "V1@(pr0)	vr2 = sel vmsk0 vr2, vr6;"
        "}"
        "{"
        "V0@(pr0)	vr3 = sel vmsk0 vr3, vr7;"
        "V1@(pr0)	vr5 = sub.f32 vr1, vr2;"
        "}"
        "{"
        "V0@(pr0)	vr5 = sel vmsk0 vr10, vr5;"
        "}"
        "{"
        "V0@(pr0)	vr6 = mul.f32 vr5, vr5;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 47948;"
        "pseudo@0	@pseudo imm_1 = 13105;"
        "pseudo@0	@pseudo imm_2 = 59918;"
        "pseudo@0	@pseudo imm_3 = 46557;"
        "V0@(pr0)	vr13 = mul.f32 vr6, r44;"
        "V1@(pr0)	vr13 = add.f32 vr13, r45;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 45909;"
        "pseudo@0	@pseudo imm_1 = 14474;"
        "V0@(pr0)	vr13 = mul.f32 vr6, vr13;"
        "V1@(pr0)	vr13 = add.f32 vr13, r44;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 2913;"
        "pseudo@0	@pseudo imm_1 = 47926;"
        "V0@(pr0)	vr13 = mul.f32 vr6, vr13;"
        "V1@(pr0)	vr13 = add.f32 vr13, r44;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 43691;"
        "pseudo@0	@pseudo imm_1 = 15914;"
        "V0@(pr0)	vr13 = mul.f32 vr6, vr13;"
        "V1@(pr0)	vr13 = add.f32 vr13, r44;"
        "}"
        "{"
        "V0@(pr0)	vr13 = mul.f32 vr6, vr13;"
        "V1@(pr0)	vr7 = sub.f32 vr5, vr13;"
        "}"
        "{"
        "V0@(pr0)	vr15 = mul.f32 vr5, vr7;"
        "V1@(pr0)	vr16 = sub.f32 vr7, r51;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 65535;"
        "pseudo@0	@pseudo imm_1 = 32767;"
        "pseudo@0	@pseudo imm_2 = 32640;"
        "V0@(pr0)	vr11 = and.u32 vr16, r44;"
        "V1@(pr0)	vmsk1 = eq.s32 vr11, r38;"
        "}"
        "{"
        "V0@(pr0)	vr12 = mul.f32 vr11, r50;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 23007;"
        "pseudo@0	@pseudo imm_1 = 24375;"
        "V0@(pr0)	vr13 = mov.u32 r44;"
        "V1@(pr0)	vr11 = shr.u32 vr11, r48;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 16320;"
        "V0@(pr0)	vr11 = sub.s32 vr13, vr11;"
        "V1@(pr0)	vr28 = mov.u32 r36;"
        "}"
        "{"
        "V0@(pr0)	vr13 = mul.f32 vr11, vr11;"
        "V1@(pr0)	vr30 = and.u32 vr16, r47;"
        "}"
        "{"
        "V0@(pr0)	vr29 = mul.f32 vr12, vr13;"
        "V1@(pr0)	vr29 = sub.f32 vr28, vr29;"
        "}"
        "{"
        "V0@(pr0)	vr29 = mul.f32 vr29, vr11;"
        "V1@(pr0)	vr11 = mov.u32 vr29;"
        "}"
        "{"
        "V0@(pr0)	vr13 = mul.f32 vr11, vr11;"
        "V1@(pr0)	vmsk0 = eq.f32 vr16, r46;"
        "}"
        "{"
        "V0@(pr0)	vr29 = mul.f32 vr12, vr13;"
        "V1@(pr0)	vr29 = sub.f32 vr28, vr29;"
        "}"
        "{"
        "V0@(pr0)	vr29 = mul.f32 vr29, vr11;"
        "V1@(pr0)	vr11 = mov.u32 vr29;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 32640;"
        "V0@(pr0)	vr13 = mul.f32 vr11, vr11;"
        "V1@(pr0)	vr31 = or.u32 vr30, r36;"
        "}"
        "{"
        "V0@(pr0)	vr29 = mul.f32 vr12, vr13;"
        "V1@(pr0)	vr29 = sub.f32 vr28, vr29;"
        "}"
        "{"
        "V0@(pr0)	vr29 = mul.f32 vr29, vr11;"
        "V1@(pr0)	vr11 = or.u32 vr30, r46;"
        "}"
        "{"
        "V0@(pr0)	vr12 = mul.f32 vr29, vr29;"
        "V1@(pr0)	vr12 = or.u32 vr30, vr12;"
        "}"
        "{"
        "V0@(pr0)	vr16 = sel vmsk0 vr12, vr31;"
        "V1@(pr0)	vr16 = sel vmsk1 vr16, vr11;"
        "}"
        "{"
        "V0@(pr0)	vr14 = mul.f32 vr15, vr16;"
        "}"
        "{"
        "V0@(pr0)	vmsk0 = eq.s32 vr3, r46;"
        "V1@(pr0)	vr15 = add.f32 vr2, vr14;"
        "}"
        "{"
        "V0@(pr0)	vr16 = mov.u32 r49;"
        "V1@(pr0)	vr15 = sub.f32 vr15, vr1;"
        "}"
        "{"
        "V1@(pr0)	vr16 = sub.f32 vr16, vr15;"
        "}"
        "{"
        "V0@(pr0)	vr13 = sel vmsk0 vr16, r46;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 65411;"
        "pseudo@0	@pseudo imm_2 = 23;"
        "V0@(pr0)	vmsk0 = gteq.s32 vr3, r40;"
        "V1@(pr0)	vr17 = shl.u32 vr3, r34;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 100;"
        "V0@(pr0)	vr15 = add.s32 vr13, vr17;"
        "V1@(pr0)	vr16 = add.s32 vr3, r32;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 23;"
        "V1@(pr0)	vr16 = shl.u32 vr16, r32;"
        "}"
        "{"
        "V0@(pr0)	vr16 = add.s32 vr13, vr16;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 3456;"
        "V0@(pr0)	vr16 = mul.f32 vr16, r36;"
        "}"
        "{"
        "V0@(pr0)	vr13 = sel vmsk0 vr16, vr15;"
        "}"
        "{"
        "V0@(pr0)	vmsk0 = eq.s32 vr3, r46;"
        "V1@(pr0)	vr15 = sub.f32 vr14, vr10;"
        "}"
        "{"
        "V0@(pr0)	vr16 = mov.u32 r49;"
        "}"
        "{"
        "V1@(pr0)	vr15 = sub.f32 vr16, vr15;"
        "}"
        "{"
        "V0@(pr0)	vr13 = sel vmsk0 vr13, vr15;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 13312;"
        "V0@(pr0)	vmsk0 = ls.s32 vr0, r36;"
        "V1@(pr0)	vr6 = add.f32 vr10, r49;"
        "}"
        "{"
        "V0@(pr0)	vr13 = sel vmsk0 vr13, vr6;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_2 = 29207;"
        "pseudo@0	@pseudo imm_3 = 17073;"
        "V0@(pr0)	vmsk3 = ls.s32 vr10, r46;"
        "V1@(pr0)	vmsk2 = gt.s32 vr10, r45;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 61877;"
        "pseudo@0	@pseudo imm_1 = 17103;"
        "V0@(pr0)	vr12 = sel vmsk3 vr13, r46;"
        "V1@(pr0)	vmsk1 = gt.s32 vr0, r44;"
        "}"
        "{"
        "V0@(pr0)	vr13 = sel vmsk1 vr13, vr12;"
        "V1@(pr0)	vmsk0 = infnan.f32 vr10;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 32640;"
        "pseudo@0	@pseudo imm_1 = 65408;"
        "V0@(pr0)	vr13 = sel vmsk2 vr13, r36;"
        "V1@(pr0)	vmsk1 = eq.s32 vr10, r37;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 32704;"
        "V0@(pr0)	vr6 = sel vmsk0 vr6, r36;"
        "V1@(pr0)	vr7 = and.u32 vr10, r47;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 32640;"
        "V0@(pr0)	vr7 = or.u32 vr6, vr7;"
        "V1@(pr0)	vmsk2 = eq.s32 vr10, r36;"
        "}"
        "{"
        "V0@(pr0)	vr13 = sel vmsk0 vr13, vr7;"
        "}"
        "{"
        "V0@(pr0)	vr13 = sel vmsk1 vr13, r46;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 32640;"
        "V0@(pr0)	vr10 = sel vmsk2 vr13, r36;"
        "}"
        "{"
        "V0@(pr0)	vr7 = mov.u32 vr10;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 4;"
        "S0@(pr0)	r3 = add.s32 r9, r32;"
        "S1@(pr0)	r3 = ld [smem:r3];"
        "}"
        "{"
        "S0@(pr0)	r3 = add.s32 r3, r9;"
        "S1@(pr0)	r0 = ld [smem:r3];"
        "}"
        "{"
        "S1@(pr0)	r0 = ld [smem:r3];"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 0;"
        "pseudo@0	@pseudo imm_2 = 1;"
        "pseudo@0	@pseudo imm_4 = 0;"
        "pseudo@0	@pseudo vs_imm0 = 1;"
        "S0@(pr0)	r1 = add.s32 r0, r32;"
        "VL@(pr0)	vr1 = ld [vmem:1+2,4,0];"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 1024;"
        "pseudo@0	@pseudo imm_2 = 1;"
        "pseudo@0	@pseudo imm_4 = 0;"
        "pseudo@0	@pseudo vs_imm0 = 1;"
        "S0@(pr0)	r1 = add.s32 r0, r32;"
        "VL@(pr0)	vr0 = ld [vmem:1+2,4,0];"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 2048;"
        "pseudo@0	@pseudo imm_2 = 1;"
        "pseudo@0	@pseudo imm_4 = 0;"
        "pseudo@0	@pseudo vs_imm0 = 1;"
        "S0@(pr0)	r1 = add.s32 r0, r32;"
        "VL@(pr0)	vr3 = ld [vmem:1+2,4,0];"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 3072;"
        "pseudo@0	@pseudo imm_2 = 1;"
        "pseudo@0	@pseudo imm_4 = 0;"
        "pseudo@0	@pseudo vs_imm0 = 1;"
        "S0@(pr0)	r1 = add.s32 r0, r32;"
        "VL@(pr0)	vr4 = ld [vmem:1+2,4,0];"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 4096;"
        "pseudo@0	@pseudo imm_2 = 1;"
        "pseudo@0	@pseudo imm_4 = 0;"
        "pseudo@0	@pseudo vs_imm0 = 1;"
        "S0@(pr0)	r1 = add.s32 r0, r32;"
        "VL@(pr0)	vr5 = ld [vmem:1+2,4,0];"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 5120;"
        "pseudo@0	@pseudo imm_2 = 1;"
        "pseudo@0	@pseudo imm_4 = 0;"
        "pseudo@0	@pseudo vs_imm0 = 1;"
        "S0@(pr0)	r1 = add.s32 r0, r32;"
        "VL@(pr0)	vr6 = ld [vmem:1+2,4,0];"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 6144;"
        "pseudo@0	@pseudo imm_2 = 1;"
        "pseudo@0	@pseudo imm_4 = 0;"
        "pseudo@0	@pseudo vs_imm0 = 1;"
        "S0@(pr0)	r1 = add.s32 r0, r32;"
        "VL@(pr0)	vr12 = ld [vmem:1+2,4,0];"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 7168;"
        "pseudo@0	@pseudo imm_2 = 1;"
        "pseudo@0	@pseudo imm_4 = 0;"
        "pseudo@0	@pseudo vs_imm0 = 1;"
        "S0@(pr0)	r1 = add.s32 r0, r32;"
        "VL@(pr0)	vr10 = ld [vmem:1+2,4,0];"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 8192;"
        "pseudo@0	@pseudo imm_1 = 0;"
        "S0@(pr0)	r0 = add.s32 r0, r44;"
        "S1@(pr0)	[smem:r3] = st r0;"
        "}"
        "{"
        "V0@(pr0)	vr30 = mov.u32 vr12;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 65535;"
        "pseudo@0	@pseudo imm_1 = 32767;"
        "pseudo@0	@pseudo imm_2 = 32640;"
        "V0@(pr0)	vr28 = and.u32 vr7, r44;"
        "V1@(pr0)	vmsk7 = eq.s32 vr28, r38;"
        "}"
        "{"
        "V0@(pr0)	vr11 = mul.f32 vr28, r50;"
        "V1@(pr0)	vr12 = mov.u32 vr28;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 23007;"
        "pseudo@0	@pseudo imm_1 = 24375;"
        "V0@(pr0)	vr13 = mov.u32 r44;"
        "V1@(pr0)	vr12 = shr.u32 vr12, r48;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 16320;"
        "V0@(pr0)	vr12 = sub.s32 vr13, vr12;"
        "V1@(pr0)	vr29 = mov.u32 r36;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 32768;"
        "V0@(pr0)	vr13 = mul.f32 vr12, vr12;"
        "V1@(pr0)	vr16 = and.u32 vr7, r36;"
        "}"
        "{"
        "V0@(pr0)	vr31 = mul.f32 vr11, vr13;"
        "V1@(pr0)	vr31 = sub.f32 vr29, vr31;"
        "}"
        "{"
        "V0@(pr0)	vr31 = mul.f32 vr31, vr12;"
        "V1@(pr0)	vr12 = mov.u32 vr31;"
        "}"
        "{"
        "V0@(pr0)	vr13 = mul.f32 vr12, vr12;"
        "V1@(pr0)	vmsk6 = eq.f32 vr7, r46;"
        "}"
        "{"
        "V0@(pr0)	vr31 = mul.f32 vr11, vr13;"
        "V1@(pr0)	vr31 = sub.f32 vr29, vr31;"
        "}"
        "{"
        "V0@(pr0)	vr31 = mul.f32 vr31, vr12;"
        "V1@(pr0)	vr12 = mov.u32 vr31;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 32640;"
        "V0@(pr0)	vr13 = mul.f32 vr12, vr12;"
        "V1@(pr0)	vr17 = or.u32 vr16, r36;"
        "}"
        "{"
        "V0@(pr0)	vr31 = mul.f32 vr11, vr13;"
        "V1@(pr0)	vr31 = sub.f32 vr29, vr31;"
        "}"
        "{"
        "V0@(pr0)	vr31 = mul.f32 vr31, vr12;"
        "V1@(pr0)	vr12 = or.u32 vr16, r46;"
        "}"
        "{"
        "V0@(pr0)	vr11 = mul.f32 vr31, vr31;"
        "V1@(pr0)	vr11 = or.u32 vr16, vr11;"
        "}"
        "{"
        "V0@(pr0)	vr31 = mov.u32 vr7;"
        "}"
        "{"
        "V0@(pr0)	vr7 = sel vmsk6 vr11, vr17;"
        "V1@(pr0)	vr7 = sel vmsk7 vr7, vr12;"
        "}"
        "{"
        "V0@(pr0)	vr12 = mov.u32 vr7;"
        "}"
        "{"
        "V0@(pr0)	vr7 = mov.u32 vr31;"
        "}"
        "{"
        "V0@(pr0)	vr7 = sel vmsk5 vr7, vr12;"
        "}"
        "{"
        "V1@(pr0)	vr12 = sub.f32 vr6, vr1;"
        "}"
        "{"
        "V1@(pr0)	vr13 = add.f32 vr6, vr1;"
        "}"
        "{"
        "V0@(pr0)	vr12 = mul.f32 vr12, vr13;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 65535;"
        "pseudo@0	@pseudo imm_1 = 32767;"
        "pseudo@0	@pseudo imm_2 = 32640;"
        "V0@(pr0)	vr28 = and.u32 vr5, r44;"
        "V1@(pr0)	vmsk7 = eq.s32 vr28, r38;"
        "}"
        "{"
        "V0@(pr0)	vr11 = mul.f32 vr28, r50;"
        "V1@(pr0)	vr29 = mov.u32 vr28;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 23007;"
        "pseudo@0	@pseudo imm_1 = 24375;"
        "V0@(pr0)	vr13 = mov.u32 r44;"
        "V1@(pr0)	vr29 = shr.u32 vr29, r48;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 16320;"
        "V0@(pr0)	vr29 = sub.s32 vr13, vr29;"
        "V1@(pr0)	vr14 = mov.u32 r36;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 32768;"
        "V0@(pr0)	vr13 = mul.f32 vr29, vr29;"
        "V1@(pr0)	vr16 = and.u32 vr5, r36;"
        "}"
        "{"
        "V0@(pr0)	vr15 = mul.f32 vr11, vr13;"
        "V1@(pr0)	vr15 = sub.f32 vr14, vr15;"
        "}"
        "{"
        "V0@(pr0)	vr15 = mul.f32 vr15, vr29;"
        "V1@(pr0)	vr29 = mov.u32 vr15;"
        "}"
        "{"
        "V0@(pr0)	vr13 = mul.f32 vr29, vr29;"
        "V1@(pr0)	vmsk6 = eq.f32 vr5, r46;"
        "}"
        "{"
        "V0@(pr0)	vr15 = mul.f32 vr11, vr13;"
        "V1@(pr0)	vr15 = sub.f32 vr14, vr15;"
        "}"
        "{"
        "V0@(pr0)	vr15 = mul.f32 vr15, vr29;"
        "V1@(pr0)	vr29 = mov.u32 vr15;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 32640;"
        "V0@(pr0)	vr13 = mul.f32 vr29, vr29;"
        "V1@(pr0)	vr17 = or.u32 vr16, r36;"
        "}"
        "{"
        "V0@(pr0)	vr15 = mul.f32 vr11, vr13;"
        "V1@(pr0)	vr15 = sub.f32 vr14, vr15;"
        "}"
        "{"
        "V0@(pr0)	vr15 = mul.f32 vr15, vr29;"
        "V1@(pr0)	vr29 = or.u32 vr16, r46;"
        "}"
        "{"
        "V0@(pr0)	vr11 = mul.f32 vr15, vr15;"
        "V1@(pr0)	vr11 = or.u32 vr16, vr11;"
        "}"
        "{"
        "V0@(pr0)	vr5 = sel vmsk6 vr11, vr17;"
        "V1@(pr0)	vr5 = sel vmsk7 vr5, vr29;"
        "}"
        "{"
        "V0@(pr0)	vr6 = mul.f32 vr5, vr4;"
        "}"
        "{"
        "V1@(pr0)	vr6 = add.f32 vr12, vr6;"
        "}"
        "{"
        "V1@(pr0)	vmsk5 = ls.f32 vr6, r46;"
        "}"
        "{"
        "V0@(pr0)	vr12 = mov.u32 vr30;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 4;"
        "S0@(pr0)	r3 = add.s32 r9, r32;"
        "S1@(pr0)	r3 = ld [smem:r3];"
        "}"
        "{"
        "S0@(pr0)	r3 = add.s32 r3, r9;"
        "S1@(pr0)	r0 = ld [smem:r3];"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 8192;"
        "pseudo@0	@pseudo imm_1 = 0;"
        "S1@(pr0)	r0 = sub.s32 r0, r44;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 0;"
        "pseudo@0	@pseudo imm_2 = 1;"
        "pseudo@0	@pseudo imm_4 = 0;"
        "pseudo@0	@pseudo vs_imm0 = 1;"
        "S0@(pr0)	r1 = add.s32 r0, r32;"
        "VS@(pr0)	[vmem:1+2,4,0] = st vr1;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 1024;"
        "pseudo@0	@pseudo imm_2 = 1;"
        "pseudo@0	@pseudo imm_4 = 0;"
        "pseudo@0	@pseudo vs_imm0 = 1;"
        "S0@(pr0)	r1 = add.s32 r0, r32;"
        "VS@(pr0)	[vmem:1+2,4,0] = st vr0;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 2048;"
        "pseudo@0	@pseudo imm_2 = 1;"
        "pseudo@0	@pseudo imm_4 = 0;"
        "pseudo@0	@pseudo vs_imm0 = 1;"
        "S0@(pr0)	r1 = add.s32 r0, r32;"
        "VS@(pr0)	[vmem:1+2,4,0] = st vr3;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 3072;"
        "pseudo@0	@pseudo imm_2 = 1;"
        "pseudo@0	@pseudo imm_4 = 0;"
        "pseudo@0	@pseudo vs_imm0 = 1;"
        "S0@(pr0)	r1 = add.s32 r0, r32;"
        "VS@(pr0)	[vmem:1+2,4,0] = st vr4;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 4096;"
        "pseudo@0	@pseudo imm_2 = 1;"
        "pseudo@0	@pseudo imm_4 = 0;"
        "pseudo@0	@pseudo vs_imm0 = 1;"
        "S0@(pr0)	r1 = add.s32 r0, r32;"
        "VS@(pr0)	[vmem:1+2,4,0] = st vr5;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 5120;"
        "pseudo@0	@pseudo imm_2 = 1;"
        "pseudo@0	@pseudo imm_4 = 0;"
        "pseudo@0	@pseudo vs_imm0 = 1;"
        "S0@(pr0)	r1 = add.s32 r0, r32;"
        "VS@(pr0)	[vmem:1+2,4,0] = st vr7;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 6144;"
        "pseudo@0	@pseudo imm_2 = 1;"
        "pseudo@0	@pseudo imm_4 = 0;"
        "pseudo@0	@pseudo vs_imm0 = 1;"
        "S0@(pr0)	r1 = add.s32 r0, r32;"
        "VS@(pr0)	[vmem:1+2,4,0] = st vr12;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 7168;"
        "pseudo@0	@pseudo imm_2 = 1;"
        "pseudo@0	@pseudo imm_4 = 0;"
        "pseudo@0	@pseudo vs_imm0 = 1;"
        "S0@(pr0)	r1 = add.s32 r0, r32;"
        "VS@(pr0)	[vmem:1+2,4,0] = st vr10;"
        "}"
        "{"
        "S1@(pr0)	[smem:r3] = st r0;"
        "}"
        "{"
        "V0@(pr0)	vr10 = mov.u32 vr6;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 65535;"
        "pseudo@0	@pseudo imm_1 = 32767;"
        "V0@(pr0)	vr10 = and.u32 vr10, r44;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 65535;"
        "pseudo@0	@pseudo imm_1 = 32767;"
        "V0@(pr0)	vr0 = and.u32 vr10, r44;"
        "V1@(pr0)	vr1 = mov.u32 r46;"
        "}"
        "{"
        "V0@(pr0)	vr2 = mov.u32 r46;"
        "V1@(pr0)	vr3 = mov.u32 r46;"
        "}"
        "{"
        "V0@(pr0)	vr4 = and.u32 vr10, r47;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 29056;"
        "pseudo@0	@pseudo imm_1 = 16177;"
        "V0@(pr0)	vmsk0 = eq.s32 vr4, r47;"
        "V1@(pr0)	vr5 = mov.u32 r44;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 29056;"
        "pseudo@0	@pseudo imm_1 = 48945;"
        "pseudo@0	@pseudo imm_2 = 63441;"
        "pseudo@0	@pseudo imm_3 = 14103;"
        "V0@(pr0)	vr5 = sel vmsk0 vr5, r44;"
        "V1@(pr0)	vr6 = mov.u32 r45;"
        "}"
        "{"
        "V1@(pr0)	vr5 = sub.f32 vr10, vr5;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 63441;"
        "pseudo@0	@pseudo imm_1 = 46871;"
        "V0@(pr0)	vr6 = sel vmsk0 vr6, r44;"
        "V1@(pr0)	vr7 = mov.u32 r48;"
        "}"
        "{"
        "V0@(pr0)	vr7 = sel vmsk0 vr7, r56;"
        "V1@(pr0)	vr14 = mov.u32 r50;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 43579;"
        "pseudo@0	@pseudo imm_1 = 16312;"
        "V0@(pr0)	vr13 = mul.f32 vr10, r44;"
        "V1@(pr0)	vr14 = sel vmsk0 vr14, r58;"
        "}"
        "{"
        "V1@(pr0)	vr13 = add.f32 vr13, vr14;"
        "}"
        "{"
        "V0@(pr0)	vr14 = cvtftoint.s32 vr13, r56;"
        "V1@(pr0)	vr13 = cvtinttof.f32 vr14;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 29056;"
        "pseudo@0	@pseudo imm_1 = 16177;"
        "V0@(pr0)	vr15 = mul.f32 vr13, r44;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 63441;"
        "pseudo@0	@pseudo imm_1 = 14103;"
        "V0@(pr0)	vr16 = mul.f32 vr13, r44;"
        "V1@(pr0)	vr15 = sub.f32 vr10, vr15;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 29208;"
        "pseudo@0	@pseudo imm_1 = 16049;"
        "pseudo@0	@pseudo imm_2 = 5522;"
        "pseudo@0	@pseudo imm_3 = 16261;"
        "V0@(pr0)	vmsk0 = gt.s32 vr0, r44;"
        "V1@(pr0)	vmsk1 = ls.s32 vr0, r45;"
        "}"
        "{"
        "V0@(pr0)	vr5 = sel vmsk1 vr15, vr5;"
        "V1@(pr0)	vr6 = sel vmsk1 vr16, vr6;"
        "}"
        "{"
        "V0@(pr0)	vr7 = sel vmsk1 vr14, vr7;"
        "}"
        "{"
        "V0@(pr0)	vr1 = sel vmsk0 vr1, vr5;"
        "V1@(pr0)	vr2 = sel vmsk0 vr2, vr6;"
        "}"
        "{"
        "V0@(pr0)	vr3 = sel vmsk0 vr3, vr7;"
        "V1@(pr0)	vr5 = sub.f32 vr1, vr2;"
        "}"
        "{"
        "V0@(pr0)	vr5 = sel vmsk0 vr10, vr5;"
        "}"
        "{"
        "V0@(pr0)	vr6 = mul.f32 vr5, vr5;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 47948;"
        "pseudo@0	@pseudo imm_1 = 13105;"
        "pseudo@0	@pseudo imm_2 = 59918;"
        "pseudo@0	@pseudo imm_3 = 46557;"
        "V0@(pr0)	vr13 = mul.f32 vr6, r44;"
        "V1@(pr0)	vr13 = add.f32 vr13, r45;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 45909;"
        "pseudo@0	@pseudo imm_1 = 14474;"
        "V0@(pr0)	vr13 = mul.f32 vr6, vr13;"
        "V1@(pr0)	vr13 = add.f32 vr13, r44;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 2913;"
        "pseudo@0	@pseudo imm_1 = 47926;"
        "V0@(pr0)	vr13 = mul.f32 vr6, vr13;"
        "V1@(pr0)	vr13 = add.f32 vr13, r44;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 43691;"
        "pseudo@0	@pseudo imm_1 = 15914;"
        "V0@(pr0)	vr13 = mul.f32 vr6, vr13;"
        "V1@(pr0)	vr13 = add.f32 vr13, r44;"
        "}"
        "{"
        "V0@(pr0)	vr13 = mul.f32 vr6, vr13;"
        "V1@(pr0)	vr7 = sub.f32 vr5, vr13;"
        "}"
        "{"
        "V0@(pr0)	vr15 = mul.f32 vr5, vr7;"
        "V1@(pr0)	vr16 = sub.f32 vr7, r51;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 65535;"
        "pseudo@0	@pseudo imm_1 = 32767;"
        "pseudo@0	@pseudo imm_2 = 32640;"
        "V0@(pr0)	vr11 = and.u32 vr16, r44;"
        "V1@(pr0)	vmsk1 = eq.s32 vr11, r38;"
        "}"
        "{"
        "V0@(pr0)	vr12 = mul.f32 vr11, r50;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 23007;"
        "pseudo@0	@pseudo imm_1 = 24375;"
        "V0@(pr0)	vr13 = mov.u32 r44;"
        "V1@(pr0)	vr11 = shr.u32 vr11, r48;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 16320;"
        "V0@(pr0)	vr11 = sub.s32 vr13, vr11;"
        "V1@(pr0)	vr28 = mov.u32 r36;"
        "}"
        "{"
        "V0@(pr0)	vr13 = mul.f32 vr11, vr11;"
        "V1@(pr0)	vr30 = and.u32 vr16, r47;"
        "}"
        "{"
        "V0@(pr0)	vr29 = mul.f32 vr12, vr13;"
        "V1@(pr0)	vr29 = sub.f32 vr28, vr29;"
        "}"
        "{"
        "V0@(pr0)	vr29 = mul.f32 vr29, vr11;"
        "V1@(pr0)	vr11 = mov.u32 vr29;"
        "}"
        "{"
        "V0@(pr0)	vr13 = mul.f32 vr11, vr11;"
        "V1@(pr0)	vmsk0 = eq.f32 vr16, r46;"
        "}"
        "{"
        "V0@(pr0)	vr29 = mul.f32 vr12, vr13;"
        "V1@(pr0)	vr29 = sub.f32 vr28, vr29;"
        "}"
        "{"
        "V0@(pr0)	vr29 = mul.f32 vr29, vr11;"
        "V1@(pr0)	vr11 = mov.u32 vr29;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 32640;"
        "V0@(pr0)	vr13 = mul.f32 vr11, vr11;"
        "V1@(pr0)	vr31 = or.u32 vr30, r36;"
        "}"
        "{"
        "V0@(pr0)	vr29 = mul.f32 vr12, vr13;"
        "V1@(pr0)	vr29 = sub.f32 vr28, vr29;"
        "}"
        "{"
        "V0@(pr0)	vr29 = mul.f32 vr29, vr11;"
        "V1@(pr0)	vr11 = or.u32 vr30, r46;"
        "}"
        "{"
        "V0@(pr0)	vr12 = mul.f32 vr29, vr29;"
        "V1@(pr0)	vr12 = or.u32 vr30, vr12;"
        "}"
        "{"
        "V0@(pr0)	vr16 = sel vmsk0 vr12, vr31;"
        "V1@(pr0)	vr16 = sel vmsk1 vr16, vr11;"
        "}"
        "{"
        "V0@(pr0)	vr14 = mul.f32 vr15, vr16;"
        "}"
        "{"
        "V0@(pr0)	vmsk0 = eq.s32 vr3, r46;"
        "V1@(pr0)	vr15 = add.f32 vr2, vr14;"
        "}"
        "{"
        "V0@(pr0)	vr16 = mov.u32 r49;"
        "V1@(pr0)	vr15 = sub.f32 vr15, vr1;"
        "}"
        "{"
        "V1@(pr0)	vr16 = sub.f32 vr16, vr15;"
        "}"
        "{"
        "V0@(pr0)	vr13 = sel vmsk0 vr16, r46;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 65411;"
        "pseudo@0	@pseudo imm_2 = 23;"
        "V0@(pr0)	vmsk0 = gteq.s32 vr3, r40;"
        "V1@(pr0)	vr17 = shl.u32 vr3, r34;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 100;"
        "V0@(pr0)	vr15 = add.s32 vr13, vr17;"
        "V1@(pr0)	vr16 = add.s32 vr3, r32;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 23;"
        "V1@(pr0)	vr16 = shl.u32 vr16, r32;"
        "}"
        "{"
        "V0@(pr0)	vr16 = add.s32 vr13, vr16;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 3456;"
        "V0@(pr0)	vr16 = mul.f32 vr16, r36;"
        "}"
        "{"
        "V0@(pr0)	vr13 = sel vmsk0 vr16, vr15;"
        "}"
        "{"
        "V0@(pr0)	vmsk0 = eq.s32 vr3, r46;"
        "V1@(pr0)	vr15 = sub.f32 vr14, vr10;"
        "}"
        "{"
        "V0@(pr0)	vr16 = mov.u32 r49;"
        "}"
        "{"
        "V1@(pr0)	vr15 = sub.f32 vr16, vr15;"
        "}"
        "{"
        "V0@(pr0)	vr13 = sel vmsk0 vr13, vr15;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 13312;"
        "V0@(pr0)	vmsk0 = ls.s32 vr0, r36;"
        "V1@(pr0)	vr6 = add.f32 vr10, r49;"
        "}"
        "{"
        "V0@(pr0)	vr13 = sel vmsk0 vr13, vr6;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_2 = 29207;"
        "pseudo@0	@pseudo imm_3 = 17073;"
        "V0@(pr0)	vmsk3 = ls.s32 vr10, r46;"
        "V1@(pr0)	vmsk2 = gt.s32 vr10, r45;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 61877;"
        "pseudo@0	@pseudo imm_1 = 17103;"
        "V0@(pr0)	vr12 = sel vmsk3 vr13, r46;"
        "V1@(pr0)	vmsk1 = gt.s32 vr0, r44;"
        "}"
        "{"
        "V0@(pr0)	vr13 = sel vmsk1 vr13, vr12;"
        "V1@(pr0)	vmsk0 = infnan.f32 vr10;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 32640;"
        "pseudo@0	@pseudo imm_1 = 65408;"
        "V0@(pr0)	vr13 = sel vmsk2 vr13, r36;"
        "V1@(pr0)	vmsk1 = eq.s32 vr10, r37;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 32704;"
        "V0@(pr0)	vr6 = sel vmsk0 vr6, r36;"
        "V1@(pr0)	vr7 = and.u32 vr10, r47;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 32640;"
        "V0@(pr0)	vr7 = or.u32 vr6, vr7;"
        "V1@(pr0)	vmsk2 = eq.s32 vr10, r36;"
        "}"
        "{"
        "V0@(pr0)	vr13 = sel vmsk0 vr13, vr7;"
        "}"
        "{"
        "V0@(pr0)	vr13 = sel vmsk1 vr13, r46;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 32640;"
        "V0@(pr0)	vr10 = sel vmsk2 vr13, r36;"
        "}"
        "{"
        "V0@(pr0)	vr6 = mov.u32 vr10;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 4;"
        "S0@(pr0)	r3 = add.s32 r9, r32;"
        "S1@(pr0)	r3 = ld [smem:r3];"
        "}"
        "{"
        "S0@(pr0)	r3 = add.s32 r3, r9;"
        "S1@(pr0)	r0 = ld [smem:r3];"
        "}"
        "{"
        "S1@(pr0)	r0 = ld [smem:r3];"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 0;"
        "pseudo@0	@pseudo imm_2 = 1;"
        "pseudo@0	@pseudo imm_4 = 0;"
        "pseudo@0	@pseudo vs_imm0 = 1;"
        "S0@(pr0)	r1 = add.s32 r0, r32;"
        "VL@(pr0)	vr1 = ld [vmem:1+2,4,0];"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 1024;"
        "pseudo@0	@pseudo imm_2 = 1;"
        "pseudo@0	@pseudo imm_4 = 0;"
        "pseudo@0	@pseudo vs_imm0 = 1;"
        "S0@(pr0)	r1 = add.s32 r0, r32;"
        "VL@(pr0)	vr0 = ld [vmem:1+2,4,0];"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 2048;"
        "pseudo@0	@pseudo imm_2 = 1;"
        "pseudo@0	@pseudo imm_4 = 0;"
        "pseudo@0	@pseudo vs_imm0 = 1;"
        "S0@(pr0)	r1 = add.s32 r0, r32;"
        "VL@(pr0)	vr3 = ld [vmem:1+2,4,0];"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 3072;"
        "pseudo@0	@pseudo imm_2 = 1;"
        "pseudo@0	@pseudo imm_4 = 0;"
        "pseudo@0	@pseudo vs_imm0 = 1;"
        "S0@(pr0)	r1 = add.s32 r0, r32;"
        "VL@(pr0)	vr4 = ld [vmem:1+2,4,0];"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 4096;"
        "pseudo@0	@pseudo imm_2 = 1;"
        "pseudo@0	@pseudo imm_4 = 0;"
        "pseudo@0	@pseudo vs_imm0 = 1;"
        "S0@(pr0)	r1 = add.s32 r0, r32;"
        "VL@(pr0)	vr5 = ld [vmem:1+2,4,0];"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 5120;"
        "pseudo@0	@pseudo imm_2 = 1;"
        "pseudo@0	@pseudo imm_4 = 0;"
        "pseudo@0	@pseudo vs_imm0 = 1;"
        "S0@(pr0)	r1 = add.s32 r0, r32;"
        "VL@(pr0)	vr7 = ld [vmem:1+2,4,0];"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 6144;"
        "pseudo@0	@pseudo imm_2 = 1;"
        "pseudo@0	@pseudo imm_4 = 0;"
        "pseudo@0	@pseudo vs_imm0 = 1;"
        "S0@(pr0)	r1 = add.s32 r0, r32;"
        "VL@(pr0)	vr12 = ld [vmem:1+2,4,0];"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 7168;"
        "pseudo@0	@pseudo imm_2 = 1;"
        "pseudo@0	@pseudo imm_4 = 0;"
        "pseudo@0	@pseudo vs_imm0 = 1;"
        "S0@(pr0)	r1 = add.s32 r0, r32;"
        "VL@(pr0)	vr10 = ld [vmem:1+2,4,0];"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 8192;"
        "pseudo@0	@pseudo imm_1 = 0;"
        "S0@(pr0)	r0 = add.s32 r0, r44;"
        "S1@(pr0)	[smem:r3] = st r0;"
        "}"
        "{"
        "V0@(pr0)	vr30 = mov.u32 vr12;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 65535;"
        "pseudo@0	@pseudo imm_1 = 32767;"
        "pseudo@0	@pseudo imm_2 = 32640;"
        "V0@(pr0)	vr28 = and.u32 vr6, r44;"
        "V1@(pr0)	vmsk7 = eq.s32 vr28, r38;"
        "}"
        "{"
        "V0@(pr0)	vr11 = mul.f32 vr28, r50;"
        "V1@(pr0)	vr29 = mov.u32 vr28;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 23007;"
        "pseudo@0	@pseudo imm_1 = 24375;"
        "V0@(pr0)	vr13 = mov.u32 r44;"
        "V1@(pr0)	vr29 = shr.u32 vr29, r48;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 16320;"
        "V0@(pr0)	vr29 = sub.s32 vr13, vr29;"
        "V1@(pr0)	vr14 = mov.u32 r36;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 32768;"
        "V0@(pr0)	vr13 = mul.f32 vr29, vr29;"
        "V1@(pr0)	vr16 = and.u32 vr6, r36;"
        "}"
        "{"
        "V0@(pr0)	vr15 = mul.f32 vr11, vr13;"
        "V1@(pr0)	vr15 = sub.f32 vr14, vr15;"
        "}"
        "{"
        "V0@(pr0)	vr15 = mul.f32 vr15, vr29;"
        "V1@(pr0)	vr29 = mov.u32 vr15;"
        "}"
        "{"
        "V0@(pr0)	vr13 = mul.f32 vr29, vr29;"
        "V1@(pr0)	vmsk6 = eq.f32 vr6, r46;"
        "}"
        "{"
        "V0@(pr0)	vr15 = mul.f32 vr11, vr13;"
        "V1@(pr0)	vr15 = sub.f32 vr14, vr15;"
        "}"
        "{"
        "V0@(pr0)	vr15 = mul.f32 vr15, vr29;"
        "V1@(pr0)	vr29 = mov.u32 vr15;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 32640;"
        "V0@(pr0)	vr13 = mul.f32 vr29, vr29;"
        "V1@(pr0)	vr17 = or.u32 vr16, r36;"
        "}"
        "{"
        "V0@(pr0)	vr15 = mul.f32 vr11, vr13;"
        "V1@(pr0)	vr15 = sub.f32 vr14, vr15;"
        "}"
        "{"
        "V0@(pr0)	vr15 = mul.f32 vr15, vr29;"
        "V1@(pr0)	vr29 = or.u32 vr16, r46;"
        "}"
        "{"
        "V0@(pr0)	vr11 = mul.f32 vr15, vr15;"
        "V1@(pr0)	vr11 = or.u32 vr16, vr11;"
        "}"
        "{"
        "V0@(pr0)	vr12 = mov.u32 vr6;"
        "}"
        "{"
        "V0@(pr0)	vr6 = sel vmsk6 vr11, vr17;"
        "V1@(pr0)	vr6 = sel vmsk7 vr6, vr29;"
        "}"
        "{"
        "V0@(pr0)	vr6 = sel vmsk5 vr12, vr6;"
        "}"
        "{"
        "V0@(pr0)	vr6 = mul.f32 vr6, vr7;"
        "}"
        "{"
        "V0@(pr0)	vr7 = mov.u32 vr1;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 65535;"
        "pseudo@0	@pseudo imm_1 = 32767;"
        "pseudo@0	@pseudo imm_2 = 32640;"
        "V0@(pr0)	vr28 = and.u32 vr7, r44;"
        "V1@(pr0)	vmsk7 = eq.s32 vr28, r38;"
        "}"
        "{"
        "V0@(pr0)	vr11 = mul.f32 vr28, r50;"
        "V1@(pr0)	vr29 = mov.u32 vr28;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 23007;"
        "pseudo@0	@pseudo imm_1 = 24375;"
        "V0@(pr0)	vr13 = mov.u32 r44;"
        "V1@(pr0)	vr29 = shr.u32 vr29, r48;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 16320;"
        "V0@(pr0)	vr29 = sub.s32 vr13, vr29;"
        "V1@(pr0)	vr14 = mov.u32 r36;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 32768;"
        "V0@(pr0)	vr13 = mul.f32 vr29, vr29;"
        "V1@(pr0)	vr16 = and.u32 vr7, r36;"
        "}"
        "{"
        "V0@(pr0)	vr15 = mul.f32 vr11, vr13;"
        "V1@(pr0)	vr15 = sub.f32 vr14, vr15;"
        "}"
        "{"
        "V0@(pr0)	vr15 = mul.f32 vr15, vr29;"
        "V1@(pr0)	vr29 = mov.u32 vr15;"
        "}"
        "{"
        "V0@(pr0)	vr13 = mul.f32 vr29, vr29;"
        "V1@(pr0)	vmsk6 = eq.f32 vr7, r46;"
        "}"
        "{"
        "V0@(pr0)	vr15 = mul.f32 vr11, vr13;"
        "V1@(pr0)	vr15 = sub.f32 vr14, vr15;"
        "}"
        "{"
        "V0@(pr0)	vr15 = mul.f32 vr15, vr29;"
        "V1@(pr0)	vr29 = mov.u32 vr15;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 32640;"
        "V0@(pr0)	vr13 = mul.f32 vr29, vr29;"
        "V1@(pr0)	vr17 = or.u32 vr16, r36;"
        "}"
        "{"
        "V0@(pr0)	vr15 = mul.f32 vr11, vr13;"
        "V1@(pr0)	vr15 = sub.f32 vr14, vr15;"
        "}"
        "{"
        "V0@(pr0)	vr15 = mul.f32 vr15, vr29;"
        "V1@(pr0)	vr29 = or.u32 vr16, r46;"
        "}"
        "{"
        "V0@(pr0)	vr11 = mul.f32 vr15, vr15;"
        "V1@(pr0)	vr11 = or.u32 vr16, vr11;"
        "}"
        "{"
        "V0@(pr0)	vr7 = sel vmsk6 vr11, vr17;"
        "V1@(pr0)	vr7 = sel vmsk7 vr7, vr29;"
        "}"
        "{"
        "V0@(pr0)	vr6 = mul.f32 vr6, vr7;"
        "}"
        "{"
        "V0@(pr0)	vr7 = mov.u32 r46;"
        "}"
        "{"
        "V0@(pr0)	vmsk0 = gteq.s32 vr10, vr7;"
        "}"
        "{"
        "V1@(pr0)	vr7 = sub.f32 vr3, vr6;"
        "}"
        "{"
        "V1@(pr0)	vr12 = sub.f32 vr6, vr3;"
        "}"
        "{"
        "V0@(pr0)	vr30 = sel vmsk0 vr12, vr7;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 16288;"
        "V0@(pr0)	vr2 = mov.u32 r36;"
        "}"
        "{"
        "V0@(pr0)	vmsk0 = ls.s32 vr1, vr2;"
        "}"
        "{"
        "V1@(pr0)	vr0 = sub.f32 vr1, vr3;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 63936;"
        "pseudo@0	@pseudo imm_1 = 47885;"
        "V0@(pr0)	vr5 = mov.u32 r44;"
        "}"
        "{"
        "V0@(pr0)	vr5 = mul.f32 vr5, vr0;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 20915;"
        "pseudo@0	@pseudo imm_1 = 15633;"
        "V0@(pr0)	vr6 = mov.u32 r44;"
        "}"
        "{"
        "V1@(pr0)	vr5 = add.f32 vr5, vr6;"
        "}"
        "{"
        "V0@(pr0)	vr5 = mul.f32 vr5, vr0;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 7362;"
        "pseudo@0	@pseudo imm_1 = 48611;"
        "V0@(pr0)	vr6 = mov.u32 r44;"
        "}"
        "{"
        "V1@(pr0)	vr5 = add.f32 vr5, vr6;"
        "}"
        "{"
        "V0@(pr0)	vr5 = mul.f32 vr5, vr0;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 65108;"
        "pseudo@0	@pseudo imm_1 = 16034;"
        "V0@(pr0)	vr6 = mov.u32 r44;"
        "}"
        "{"
        "V1@(pr0)	vr5 = add.f32 vr5, vr6;"
        "}"
        "{"
        "V0@(pr0)	vr5 = mul.f32 vr5, vr0;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 37384;"
        "pseudo@0	@pseudo imm_1 = 48830;"
        "V0@(pr0)	vr6 = mov.u32 r44;"
        "}"
        "{"
        "V1@(pr0)	vr5 = add.f32 vr5, vr6;"
        "}"
        "{"
        "V0@(pr0)	vr5 = mul.f32 vr5, vr0;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 26629;"
        "pseudo@0	@pseudo imm_1 = 16084;"
        "V0@(pr0)	vr6 = mov.u32 r44;"
        "}"
        "{"
        "V1@(pr0)	vr5 = add.f32 vr5, vr6;"
        "}"
        "{"
        "V0@(pr0)	vr5 = mul.f32 vr5, vr0;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 52678;"
        "pseudo@0	@pseudo imm_1 = 47898;"
        "V0@(pr0)	vr6 = mov.u32 r44;"
        "}"
        "{"
        "V1@(pr0)	vr5 = add.f32 vr5, vr6;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 23203;"
        "pseudo@0	@pseudo imm_1 = 15428;"
        "V0@(pr0)	vr6 = mov.u32 r44;"
        "}"
        "{"
        "V0@(pr0)	vr6 = mul.f32 vr6, vr0;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 28179;"
        "pseudo@0	@pseudo imm_1 = 15455;"
        "V0@(pr0)	vr4 = mov.u32 r44;"
        "}"
        "{"
        "V1@(pr0)	vr6 = add.f32 vr6, vr4;"
        "}"
        "{"
        "V0@(pr0)	vr6 = mul.f32 vr6, vr0;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 13063;"
        "pseudo@0	@pseudo imm_1 = 15873;"
        "V0@(pr0)	vr4 = mov.u32 r44;"
        "}"
        "{"
        "V1@(pr0)	vr6 = add.f32 vr6, vr4;"
        "}"
        "{"
        "V0@(pr0)	vr6 = mul.f32 vr6, vr0;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 6887;"
        "pseudo@0	@pseudo imm_1 = 15763;"
        "V0@(pr0)	vr4 = mov.u32 r44;"
        "}"
        "{"
        "V1@(pr0)	vr6 = add.f32 vr6, vr4;"
        "}"
        "{"
        "V0@(pr0)	vr6 = mul.f32 vr6, vr0;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 22405;"
        "pseudo@0	@pseudo imm_1 = 16138;"
        "V0@(pr0)	vr4 = mov.u32 r44;"
        "}"
        "{"
        "V1@(pr0)	vr6 = add.f32 vr6, vr4;"
        "}"
        "{"
        "V0@(pr0)	vr6 = mul.f32 vr6, vr0;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 62257;"
        "pseudo@0	@pseudo imm_1 = 15833;"
        "V0@(pr0)	vr4 = mov.u32 r44;"
        "}"
        "{"
        "V1@(pr0)	vr6 = add.f32 vr6, vr4;"
        "}"
        "{"
        "V0@(pr0)	vr6 = mul.f32 vr6, vr0;"
        "}"
        "{"
        "V1@(pr0)	vr6 = add.f32 vr6, vr3;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 65535;"
        "pseudo@0	@pseudo imm_1 = 32767;"
        "pseudo@0	@pseudo imm_2 = 32640;"
        "V0@(pr0)	vr28 = and.u32 vr6, r44;"
        "V1@(pr0)	vmsk7 = eq.s32 vr28, r38;"
        "}"
        "{"
        "V0@(pr0)	vr11 = mul.f32 vr28, r50;"
        "V1@(pr0)	vr29 = mov.u32 vr28;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 23007;"
        "pseudo@0	@pseudo imm_1 = 24375;"
        "V0@(pr0)	vr13 = mov.u32 r44;"
        "V1@(pr0)	vr29 = shr.u32 vr29, r48;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 16320;"
        "V0@(pr0)	vr29 = sub.s32 vr13, vr29;"
        "V1@(pr0)	vr14 = mov.u32 r36;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 32768;"
        "V0@(pr0)	vr13 = mul.f32 vr29, vr29;"
        "V1@(pr0)	vr16 = and.u32 vr6, r36;"
        "}"
        "{"
        "V0@(pr0)	vr15 = mul.f32 vr11, vr13;"
        "V1@(pr0)	vr15 = sub.f32 vr14, vr15;"
        "}"
        "{"
        "V0@(pr0)	vr15 = mul.f32 vr15, vr29;"
        "V1@(pr0)	vr29 = mov.u32 vr15;"
        "}"
        "{"
        "V0@(pr0)	vr13 = mul.f32 vr29, vr29;"
        "V1@(pr0)	vmsk6 = eq.f32 vr6, r46;"
        "}"
        "{"
        "V0@(pr0)	vr15 = mul.f32 vr11, vr13;"
        "V1@(pr0)	vr15 = sub.f32 vr14, vr15;"
        "}"
        "{"
        "V0@(pr0)	vr15 = mul.f32 vr15, vr29;"
        "V1@(pr0)	vr29 = mov.u32 vr15;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 32640;"
        "V0@(pr0)	vr13 = mul.f32 vr29, vr29;"
        "V1@(pr0)	vr17 = or.u32 vr16, r36;"
        "}"
        "{"
        "V0@(pr0)	vr15 = mul.f32 vr11, vr13;"
        "V1@(pr0)	vr15 = sub.f32 vr14, vr15;"
        "}"
        "{"
        "V0@(pr0)	vr15 = mul.f32 vr15, vr29;"
        "V1@(pr0)	vr29 = or.u32 vr16, r46;"
        "}"
        "{"
        "V0@(pr0)	vr11 = mul.f32 vr15, vr15;"
        "V1@(pr0)	vr11 = or.u32 vr16, vr11;"
        "}"
        "{"
        "V0@(pr0)	vr6 = sel vmsk6 vr11, vr17;"
        "V1@(pr0)	vr6 = sel vmsk7 vr6, vr29;"
        "}"
        "{"
        "V0@(pr0)	vr5 = mul.f32 vr5, vr6;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 22027;"
        "pseudo@0	@pseudo imm_1 = 16216;"
        "V0@(pr0)	vr2 = mov.u32 r44;"
        "}"
        "{"
        "V1@(pr0)	vr6 = add.f32 vr2, vr5;"
        "}"
        "{"
        "V0@(pr0)	vmsk1 = gteq.s32 vr10, r46;"
        "}"
        "{"
        "V0@(pr0)	vr2 = mul.f32 vr2, r57;"
        "}"
        "{"
        "V1@(pr0)	vr7 = sub.f32 vr2, vr5;"
        "}"
        "{"
        "V0@(pr0)	vr7 = sel vmsk1 vr7, vr6;"
        "}"
        "{"
        "V0@(pr0)	vr30 = sel vmsk0 vr30, vr7;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 16216;"
        "V0@(pr0)	vr2 = mov.u32 r36;"
        "}"
        "{"
        "V0@(pr0)	vmsk0 = ls.s32 vr1, vr2;"
        "}"
        "{"
        "V0@(pr0)	vr0 = mul.f32 vr10, vr10;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 22193;"
        "pseudo@0	@pseudo imm_1 = 47047;"
        "V0@(pr0)	vr5 = mov.u32 r44;"
        "}"
        "{"
        "V0@(pr0)	vr5 = mul.f32 vr5, vr0;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 5257;"
        "pseudo@0	@pseudo imm_1 = 48061;"
        "V0@(pr0)	vr4 = mov.u32 r44;"
        "}"
        "{"
        "V1@(pr0)	vr5 = add.f32 vr5, vr4;"
        "}"
        "{"
        "V0@(pr0)	vr5 = mul.f32 vr5, vr0;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 21135;"
        "pseudo@0	@pseudo imm_1 = 48361;"
        "V0@(pr0)	vr4 = mov.u32 r44;"
        "}"
        "{"
        "V1@(pr0)	vr5 = add.f32 vr5, vr4;"
        "}"
        "{"
        "V0@(pr0)	vr5 = mul.f32 vr5, vr0;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 27627;"
        "pseudo@0	@pseudo imm_1 = 48806;"
        "V0@(pr0)	vr4 = mov.u32 r44;"
        "}"
        "{"
        "V1@(pr0)	vr5 = add.f32 vr5, vr4;"
        "}"
        "{"
        "V0@(pr0)	vr5 = mul.f32 vr5, vr0;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 30164;"
        "pseudo@0	@pseudo imm_1 = 15875;"
        "V0@(pr0)	vr4 = mov.u32 r44;"
        "}"
        "{"
        "V1@(pr0)	vr5 = add.f32 vr5, vr4;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 57882;"
        "pseudo@0	@pseudo imm_1 = 46724;"
        "V0@(pr0)	vr6 = mov.u32 r44;"
        "}"
        "{"
        "V0@(pr0)	vr6 = mul.f32 vr6, vr0;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 61001;"
        "pseudo@0	@pseudo imm_1 = 14602;"
        "V0@(pr0)	vr4 = mov.u32 r44;"
        "}"
        "{"
        "V1@(pr0)	vr6 = add.f32 vr6, vr4;"
        "}"
        "{"
        "V0@(pr0)	vr6 = mul.f32 vr6, vr0;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 33046;"
        "pseudo@0	@pseudo imm_1 = 15270;"
        "V0@(pr0)	vr4 = mov.u32 r44;"
        "}"
        "{"
        "V1@(pr0)	vr6 = add.f32 vr6, vr4;"
        "}"
        "{"
        "V0@(pr0)	vr6 = mul.f32 vr6, vr0;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 10851;"
        "pseudo@0	@pseudo imm_1 = 15749;"
        "V0@(pr0)	vr4 = mov.u32 r44;"
        "}"
        "{"
        "V1@(pr0)	vr6 = add.f32 vr6, vr4;"
        "}"
        "{"
        "V0@(pr0)	vr6 = mul.f32 vr6, vr0;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 48078;"
        "pseudo@0	@pseudo imm_1 = 16075;"
        "V0@(pr0)	vr4 = mov.u32 r44;"
        "}"
        "{"
        "V1@(pr0)	vr6 = add.f32 vr6, vr4;"
        "}"
        "{"
        "V0@(pr0)	vr6 = mul.f32 vr6, vr0;"
        "}"
        "{"
        "V1@(pr0)	vr6 = add.f32 vr6, vr3;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 65535;"
        "pseudo@0	@pseudo imm_1 = 32767;"
        "pseudo@0	@pseudo imm_2 = 32640;"
        "V0@(pr0)	vr28 = and.u32 vr6, r44;"
        "V1@(pr0)	vmsk7 = eq.s32 vr28, r38;"
        "}"
        "{"
        "V0@(pr0)	vr11 = mul.f32 vr28, r50;"
        "V1@(pr0)	vr29 = mov.u32 vr28;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 23007;"
        "pseudo@0	@pseudo imm_1 = 24375;"
        "V0@(pr0)	vr13 = mov.u32 r44;"
        "V1@(pr0)	vr29 = shr.u32 vr29, r48;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 16320;"
        "V0@(pr0)	vr29 = sub.s32 vr13, vr29;"
        "V1@(pr0)	vr14 = mov.u32 r36;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 32768;"
        "V0@(pr0)	vr13 = mul.f32 vr29, vr29;"
        "V1@(pr0)	vr16 = and.u32 vr6, r36;"
        "}"
        "{"
        "V0@(pr0)	vr15 = mul.f32 vr11, vr13;"
        "V1@(pr0)	vr15 = sub.f32 vr14, vr15;"
        "}"
        "{"
        "V0@(pr0)	vr15 = mul.f32 vr15, vr29;"
        "V1@(pr0)	vr29 = mov.u32 vr15;"
        "}"
        "{"
        "V0@(pr0)	vr13 = mul.f32 vr29, vr29;"
        "V1@(pr0)	vmsk6 = eq.f32 vr6, r46;"
        "}"
        "{"
        "V0@(pr0)	vr15 = mul.f32 vr11, vr13;"
        "V1@(pr0)	vr15 = sub.f32 vr14, vr15;"
        "}"
        "{"
        "V0@(pr0)	vr15 = mul.f32 vr15, vr29;"
        "V1@(pr0)	vr29 = mov.u32 vr15;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 32640;"
        "V0@(pr0)	vr13 = mul.f32 vr29, vr29;"
        "V1@(pr0)	vr17 = or.u32 vr16, r36;"
        "}"
        "{"
        "V0@(pr0)	vr15 = mul.f32 vr11, vr13;"
        "V1@(pr0)	vr15 = sub.f32 vr14, vr15;"
        "}"
        "{"
        "V0@(pr0)	vr15 = mul.f32 vr15, vr29;"
        "V1@(pr0)	vr29 = or.u32 vr16, r46;"
        "}"
        "{"
        "V0@(pr0)	vr11 = mul.f32 vr15, vr15;"
        "V1@(pr0)	vr11 = or.u32 vr16, vr11;"
        "}"
        "{"
        "V0@(pr0)	vr6 = sel vmsk6 vr11, vr17;"
        "V1@(pr0)	vr6 = sel vmsk7 vr6, vr29;"
        "}"
        "{"
        "V0@(pr0)	vr5 = mul.f32 vr5, vr6;"
        "}"
        "{"
        "V0@(pr0)	vr5 = mul.f32 vr10, vr5;"
        "}"
        "{"
        "V1@(pr0)	vr5 = add.f32 vr10, vr5;"
        "}"
        "{"
        "V0@(pr0)	vr30 = sel vmsk0 vr30, vr5;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 12672;"
        "V0@(pr0)	vr2 = mov.u32 r36;"
        "}"
        "{"
        "V0@(pr0)	vmsk0 = ls.s32 vr1, vr2;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 30164;"
        "pseudo@0	@pseudo imm_1 = 15875;"
        "V0@(pr0)	vr2 = mov.u32 r44;"
        "}"
        "{"
        "V0@(pr0)	vr2 = mul.f32 vr2, vr10;"
        "}"
        "{"
        "V1@(pr0)	vr2 = add.f32 vr2, vr10;"
        "}"
        "{"
        "V0@(pr0)	vr30 = sel vmsk0 vr30, vr2;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 30164;"
        "pseudo@0	@pseudo imm_1 = 16259;"
        "V0@(pr0)	vr2 = mov.u32 r44;"
        "}"
        "{"
        "V0@(pr0)	vr2 = mul.f32 vr2, vr10;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 16640;"
        "V0@(pr0)	vr4 = mov.u32 r36;"
        "}"
        "{"
        "V0@(pr0)	vr4 = mul.f32 vr10, vr4;"
        "}"
        "{"
        "V1@(pr0)	vr2 = add.f32 vr2, vr4;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 15872;"
        "V0@(pr0)	vr4 = mov.u32 r36;"
        "}"
        "{"
        "V0@(pr0)	vr2 = mul.f32 vr2, vr4;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 1024;"
        "V0@(pr0)	vr4 = mov.u32 r36;"
        "}"
        "{"
        "V0@(pr0)	vmsk0 = ls.s32 vr1, vr4;"
        "}"
        "{"
        "V0@(pr0)	vr30 = sel vmsk0 vr30, vr2;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 0;"
        "pseudo@0	@pseudo imm_1 = 32640;"
        "V0@(pr0)	vr2 = mov.u32 r44;"
        "}"
        "{"
        "V0@(pr0)	vmsk0 = gteq.s32 vr1, vr2;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 31;"
        "V0@(pr0)	vr3 = mov.u32 r32;"
        "}"
        "{"
        "V1@(pr0)	vr2 = shr.u32 vr10, vr3;"
        "}"
        "{"
        "V0@(pr0)	vr3 = mov.u32 r48;"
        "}"
        "{"
        "V1@(pr0)	vr2 = shl.u32 vr2, vr3;"
        "}"
        "{"
        "V0@(pr0)	vr3 = mov.u32 r48;"
        "}"
        "{"
        "V0@(pr0)	vr2 = sub.s32 vr3, vr2;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 16256;"
        "V0@(pr0)	vr3 = mov.u32 r36;"
        "}"
        "{"
        "V1@(pr0)	vr4 = mov.u32 vr10;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 65535;"
        "pseudo@0	@pseudo imm_1 = 32767;"
        "pseudo@0	@pseudo imm_2 = 32640;"
        "V0@(pr0)	vr28 = and.u32 vr4, r44;"
        "V1@(pr0)	vmsk7 = eq.s32 vr28, r38;"
        "}"
        "{"
        "V0@(pr0)	vr11 = mul.f32 vr28, r50;"
        "V1@(pr0)	vr29 = mov.u32 vr28;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 23007;"
        "pseudo@0	@pseudo imm_1 = 24375;"
        "V0@(pr0)	vr13 = mov.u32 r44;"
        "V1@(pr0)	vr29 = shr.u32 vr29, r48;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 16320;"
        "V0@(pr0)	vr29 = sub.s32 vr13, vr29;"
        "V1@(pr0)	vr14 = mov.u32 r36;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 32768;"
        "V0@(pr0)	vr13 = mul.f32 vr29, vr29;"
        "V1@(pr0)	vr16 = and.u32 vr4, r36;"
        "}"
        "{"
        "V0@(pr0)	vr15 = mul.f32 vr11, vr13;"
        "V1@(pr0)	vr15 = sub.f32 vr14, vr15;"
        "}"
        "{"
        "V0@(pr0)	vr15 = mul.f32 vr15, vr29;"
        "V1@(pr0)	vr29 = mov.u32 vr15;"
        "}"
        "{"
        "V0@(pr0)	vr13 = mul.f32 vr29, vr29;"
        "V1@(pr0)	vmsk6 = eq.f32 vr4, r46;"
        "}"
        "{"
        "V0@(pr0)	vr15 = mul.f32 vr11, vr13;"
        "V1@(pr0)	vr15 = sub.f32 vr14, vr15;"
        "}"
        "{"
        "V0@(pr0)	vr15 = mul.f32 vr15, vr29;"
        "V1@(pr0)	vr29 = mov.u32 vr15;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 32640;"
        "V0@(pr0)	vr13 = mul.f32 vr29, vr29;"
        "V1@(pr0)	vr17 = or.u32 vr16, r36;"
        "}"
        "{"
        "V0@(pr0)	vr15 = mul.f32 vr11, vr13;"
        "V1@(pr0)	vr15 = sub.f32 vr14, vr15;"
        "}"
        "{"
        "V0@(pr0)	vr15 = mul.f32 vr15, vr29;"
        "V1@(pr0)	vr29 = or.u32 vr16, r46;"
        "}"
        "{"
        "V0@(pr0)	vr11 = mul.f32 vr15, vr15;"
        "V1@(pr0)	vr11 = or.u32 vr16, vr11;"
        "}"
        "{"
        "V0@(pr0)	vr4 = sel vmsk6 vr11, vr17;"
        "V1@(pr0)	vr4 = sel vmsk7 vr4, vr29;"
        "}"
        "{"
        "V0@(pr0)	vr3 = mul.f32 vr3, vr4;"
        "}"
        "{"
        "V1@(pr0)	vr2 = add.f32 vr2, vr3;"
        "}"
        "{"
        "V0@(pr0)	%[res0] = sel vmsk0 vr30, vr2;"
        "}"
        : [res0] "=x" (result0)
        : [input0] "x" (a)
        :"vr13", "vr5", "vr31", "vr28", "vr4", "vr16", "vr10", "vr30", "vr0", "vr2", "vr11", "vr3", "vr29", "vr15", "vr1", "vr6", "vr17", "vr7", "vr14", "vr12", "r1", "r3", "r9", "r0", "vmsk7", "vmsk5", "vmsk1", "vmsk3", "vmsk6", "vmsk2", "vmsk0"
        );
    return result0;
}
