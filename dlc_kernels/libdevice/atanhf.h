#pragma once
#include "../../dlc-intrinsics.h"
#include "../../typehint.h"

#ifndef _ATANHF_H_X86_
#define _ATANHF_H_X86_

inline float8_128 __dlc_atanhf(float8_128 a)
{
    float8_128 result0;
    asm (
        "{V0@(pr0)  vr10 = mov.u32 %[input0];}"
        "{"
        "pseudo@0	@pseudo imm_0 = 65535;"
        "pseudo@0	@pseudo imm_1 = 32767;"
        "V0@(pr0)	vr2 = and.u32 vr10, r44;"
        "}"
        "{"
        "V0@(pr0)	vr6 = mov.u32 r50;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 0;"
        "pseudo@0	@pseudo imm_1 = 16256;"
        "pseudo@0	@pseudo imm_2 = 0;"
        "pseudo@0	@pseudo imm_3 = 32704;"
        "V0@(pr0)	vmsk1 = lseq.f32 vr2, r44;"
        "V1@(pr0)	vr4 = mov.u32 r45;"
        "}"
        "{"
        "V1@(pr0)	vr1 = sel vmsk1 vr4, vr1;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 0;"
        "pseudo@0	@pseudo imm_1 = 16256;"
        "V0@(pr0)	vmsk1 = eq.f32 vr2, r44;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 0;"
        "pseudo@0	@pseudo imm_1 = 32640;"
        "V0@(pr0)	vr4 = mul.f32 vr10, r44;"
        "}"
        "{"
        "V1@(pr0)	vr1 = sel vmsk1 vr1, vr4;"
        "}"
        "{"
        "V1@(pr0)	vr3 = add.f32 vr10, vr10;"
        "}"
        "{"
        "V0@(pr0)	vr5 = mul.f32 vr3, vr10;"
        "V1@(pr0)	vr4 = mov.u32 r49;"
        "}"
        "{"
        "V1@(pr0)	vr4 = sub.f32 vr4, vr10;"
        "}"
        "{"
        "V0@(pr0)	(urf) = rcp.f32 vr4;"
        "}"
        "{"
        "MTR@(pr0)	vr4 = pop urf;"
        "}"
        "{"
        "V0@(pr0)	vr4 = mul.f32 vr4, vr5;"
        "}"
        "{"
        "V1@(pr0)	vr4 = add.f32 vr4, vr3;"
        "}"
        "{"
        "V1@(pr0)	vr4 = add.f32 vr4, r49;"
        "}"
        "{"
        "V0@(pr0)	(urf) = log.f32 vr4;"
        "}"
        "{"
        "MTR@(pr0)	vr4 = pop urf;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 29208;"
        "pseudo@0	@pseudo imm_1 = 16177;"
        "V0@(pr0)	vr4 = mul.f32 vr4, r44;"
        "}"
        "{"
        "V0@(pr0)	vr4 = mul.f32 vr4, vr6;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 0;"
        "pseudo@0	@pseudo imm_1 = 16256;"
        "V0@(pr0)	vmsk1 = ls.f32 vr2, r44;"
        "}"
        "{"
        "V1@(pr0)	vr1 = sel vmsk1 vr1, vr4;"
        "}"
        "{"
        "V0@(pr0)	vr4 = mov.u32 r49;"
        "V1@(pr0)	vr5 = add.f32 vr10, vr10;"
        "}"
        "{"
        "V1@(pr0)	vr4 = sub.f32 vr4, vr10;"
        "}"
        "{"
        "V0@(pr0)	(urf) = rcp.f32 vr4;"
        "}"
        "{"
        "MTR@(pr0)	vr4 = pop urf;"
        "}"
        "{"
        "V0@(pr0)	vr4 = mul.f32 vr4, vr5;"
        "}"
        "{"
        "V1@(pr0)	vr4 = add.f32 vr4, r49;"
        "}"
        "{"
        "V0@(pr0)	(urf) = log.f32 vr4;"
        "}"
        "{"
        "MTR@(pr0)	vr4 = pop urf;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 29208;"
        "pseudo@0	@pseudo imm_1 = 16177;"
        "V0@(pr0)	vr4 = mul.f32 vr4, r44;"
        "}"
        "{"
        "V0@(pr0)	vr4 = mul.f32 vr4, vr6;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 0;"
        "pseudo@0	@pseudo imm_1 = 16128;"
        "V0@(pr0)	vmsk1 = ls.f32 vr2, r44;"
        "}"
        "{"
        "V1@(pr0)	vr1 = sel vmsk1 vr1, vr4;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 0;"
        "pseudo@0	@pseudo imm_1 = 12672;"
        "V0@(pr0)	vmsk1 = ls.f32 vr2, r44;"
        "}"
        "{"
        "V1@(pr0)	vr1 = sel vmsk1 vr1, vr10;"
        "}"
        "{"
        "V0@(pr0)	%[res0] = mov.u32 vr1;"
        "}"
        : [res0] "=x" (result0)
        : [input0] "x" (a)
        :"vr2", "vr4", "vr1", "vr5", "vr3", "vr10", "vr6", "vmsk1"
        );
    return result0;
}

#endif // _ATANHF_H_
