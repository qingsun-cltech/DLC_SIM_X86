#pragma once
#include "../../dlc-intrinsics.h"
#include "../../typehint.h"

#ifndef _LGAMMAF_H_X86_
#define _LGAMMAF_H_X86_

inline float8_128 __dlc_lgammaf(float8_128 a)
{
    float8_128 result0;
    asm (
        "{V0@(pr0)  vr10 = mov.u32 %[input0];}"
        "{"
        "pseudo@0	@pseudo imm_0 = 65535;"
        "pseudo@0	@pseudo imm_1 = 32767;"
        "pseudo@0	@pseudo imm_2 = 40;"
        "S1@(pr0)	r6 = sub.s32 r6, r34;"
        "V0@(pr0)	vr6 = and.u32 vr10, r44;"
        "V1@(pr0)	vr0 = mov.u32 r46;"
        "}"
        "{"
        "V0@(pr0)	vr13 = mov.u32 r46;"
        "V1@(pr0)	vr28 = mov.u32 vr10;"
        "}"
        "{"
        "V0@(pr0)	vr11 = mov.u32 r48;"
        "}"
        "{"
        "V1@(pr0)	vr1 = sub.f32 vr10, vr10;"
        "}"
        "{"
        "V0@(pr0)	(urf) = rcp.f32 vr1;"
        "MTR@(pr0)	vr31 = pop urf;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 19200;"
        "V0@(pr0)	vmsk1 = gteq.s32 vr6, r36;"
        "V1@(pr0)	vr1 = mov.u32 vr31;"
        "}"
        "{"
        "V1@(pr0)	vr5 = sel vmsk1 vr0, vr1;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 4;"
        "S0@(pr0)	r3 = add.s32 r9, r32;"
        "S1@(pr0)	r3 = ld [smem:r3];"
        "}"
        "{"
        "S0@(pr0)	r3 = add.s32 r3, r9;"
        "S1@(pr0)	r0 = ld [smem:r3];"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 17408;"
        "pseudo@0	@pseudo imm_1 = 0;"
        "S1@(pr0)	r0 = sub.s32 r0, r44;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 0;"
        "pseudo@0	@pseudo imm_2 = 1;"
        "pseudo@0	@pseudo imm_4 = 0;"
        "pseudo@0	@pseudo vs_imm0 = 1;"
        "S0@(pr0)	r1 = add.s32 r0, r32;"
        "VS@(pr0)	[vmem:1+2,4,0] = st vr0;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 1024;"
        "pseudo@0	@pseudo imm_2 = 1;"
        "pseudo@0	@pseudo imm_4 = 0;"
        "pseudo@0	@pseudo vs_imm0 = 1;"
        "S0@(pr0)	r1 = add.s32 r0, r32;"
        "VS@(pr0)	[vmem:1+2,4,0] = st vr1;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 2048;"
        "pseudo@0	@pseudo imm_2 = 1;"
        "pseudo@0	@pseudo imm_4 = 0;"
        "pseudo@0	@pseudo vs_imm0 = 1;"
        "S0@(pr0)	r1 = add.s32 r0, r32;"
        "VS@(pr0)	[vmem:1+2,4,0] = st vr2;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 3072;"
        "pseudo@0	@pseudo imm_2 = 1;"
        "pseudo@0	@pseudo imm_4 = 0;"
        "pseudo@0	@pseudo vs_imm0 = 1;"
        "S0@(pr0)	r1 = add.s32 r0, r32;"
        "VS@(pr0)	[vmem:1+2,4,0] = st vr3;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 4096;"
        "pseudo@0	@pseudo imm_2 = 1;"
        "pseudo@0	@pseudo imm_4 = 0;"
        "pseudo@0	@pseudo vs_imm0 = 1;"
        "S0@(pr0)	r1 = add.s32 r0, r32;"
        "VS@(pr0)	[vmem:1+2,4,0] = st vr4;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 5120;"
        "pseudo@0	@pseudo imm_2 = 1;"
        "pseudo@0	@pseudo imm_4 = 0;"
        "pseudo@0	@pseudo vs_imm0 = 1;"
        "S0@(pr0)	r1 = add.s32 r0, r32;"
        "VS@(pr0)	[vmem:1+2,4,0] = st vr5;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 6144;"
        "pseudo@0	@pseudo imm_2 = 1;"
        "pseudo@0	@pseudo imm_4 = 0;"
        "pseudo@0	@pseudo vs_imm0 = 1;"
        "S0@(pr0)	r1 = add.s32 r0, r32;"
        "VS@(pr0)	[vmem:1+2,4,0] = st vr6;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 7168;"
        "pseudo@0	@pseudo imm_2 = 1;"
        "pseudo@0	@pseudo imm_4 = 0;"
        "pseudo@0	@pseudo vs_imm0 = 1;"
        "S0@(pr0)	r1 = add.s32 r0, r32;"
        "VS@(pr0)	[vmem:1+2,4,0] = st vr7;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 8192;"
        "pseudo@0	@pseudo imm_2 = 1;"
        "pseudo@0	@pseudo imm_4 = 0;"
        "pseudo@0	@pseudo vs_imm0 = 1;"
        "S0@(pr0)	r1 = add.s32 r0, r32;"
        "VS@(pr0)	[vmem:1+2,4,0] = st vr10;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 9216;"
        "pseudo@0	@pseudo imm_2 = 1;"
        "pseudo@0	@pseudo imm_4 = 0;"
        "pseudo@0	@pseudo vs_imm0 = 1;"
        "S0@(pr0)	r1 = add.s32 r0, r32;"
        "VS@(pr0)	[vmem:1+2,4,0] = st vr11;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 10240;"
        "pseudo@0	@pseudo imm_2 = 1;"
        "pseudo@0	@pseudo imm_4 = 0;"
        "pseudo@0	@pseudo vs_imm0 = 1;"
        "S0@(pr0)	r1 = add.s32 r0, r32;"
        "VS@(pr0)	[vmem:1+2,4,0] = st vr12;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 11264;"
        "pseudo@0	@pseudo imm_2 = 1;"
        "pseudo@0	@pseudo imm_4 = 0;"
        "pseudo@0	@pseudo vs_imm0 = 1;"
        "S0@(pr0)	r1 = add.s32 r0, r32;"
        "VS@(pr0)	[vmem:1+2,4,0] = st vr13;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 12288;"
        "pseudo@0	@pseudo imm_2 = 1;"
        "pseudo@0	@pseudo imm_4 = 0;"
        "pseudo@0	@pseudo vs_imm0 = 1;"
        "S0@(pr0)	r1 = add.s32 r0, r32;"
        "VS@(pr0)	[vmem:1+2,4,0] = st vr14;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 13312;"
        "pseudo@0	@pseudo imm_2 = 1;"
        "pseudo@0	@pseudo imm_4 = 0;"
        "pseudo@0	@pseudo vs_imm0 = 1;"
        "S0@(pr0)	r1 = add.s32 r0, r32;"
        "VS@(pr0)	[vmem:1+2,4,0] = st vr15;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 14336;"
        "pseudo@0	@pseudo imm_2 = 1;"
        "pseudo@0	@pseudo imm_4 = 0;"
        "pseudo@0	@pseudo vs_imm0 = 1;"
        "S0@(pr0)	r1 = add.s32 r0, r32;"
        "VS@(pr0)	[vmem:1+2,4,0] = st vr16;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 15360;"
        "pseudo@0	@pseudo imm_2 = 1;"
        "pseudo@0	@pseudo imm_4 = 0;"
        "pseudo@0	@pseudo vs_imm0 = 1;"
        "S0@(pr0)	r1 = add.s32 r0, r32;"
        "VS@(pr0)	[vmem:1+2,4,0] = st vr17;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 16384;"
        "pseudo@0	@pseudo imm_2 = 1;"
        "pseudo@0	@pseudo imm_4 = 0;"
        "pseudo@0	@pseudo vs_imm0 = 1;"
        "S0@(pr0)	r1 = add.s32 r0, r32;"
        "VS@(pr0)	[vmem:1+2,4,0] = st vr28;"
        "}"
        "{"
        "S1@(pr0)	[smem:r3] = st r0;"
        "}"
        "{"
        "V0@(pr0)	vr10 = mov.u32 vr10;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 65535;"
        "pseudo@0	@pseudo imm_1 = 32767;"
        "pseudo@0	@pseudo imm_2 = 32768;"
        "V0@(pr0)	vr5 = and.u32 vr10, r44;"
        "V1@(pr0)	vr6 = xor.u32 vr10, r38;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 23;"
        "V0@(pr0)	vr31 = mov.u32 vr10;"
        "V1@(pr0)	vr1 = shr.u32 vr6, r32;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 255;"
        "pseudo@0	@pseudo imm_1 = 127;"
        "V0@(pr0)	vr1 = and.u32 vr1, r32;"
        "V1@(pr0)	vr1 = sub.s32 vr1, r33;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 23;"
        "V0@(pr0)	vmsk1 = gteq.s32 vr1, r32;"
        "V1@(pr0)	vr7 = mov.u32 vr6;"
        "}"
        "{"
        "V0@(pr0)	vr2 = cvtftoint.s32 vr6, r46;"
        "V1@(pr0)	vmsk2 = gt.f32 vr6, r46;"
        "}"
        "{"
        "V0@(pr0)	vr3 = cvtftoint.s32 vr6, r56;"
        "V1@(pr0)	vr2 = sel vmsk2 vr2, vr3;"
        "}"
        "{"
        "V0@(pr0)	vr2 = cvtinttof.f32 vr2;"
        "V1@(pr0)	vr7 = sel vmsk1 vr2, vr7;"
        "}"
        "{"
        "V0@(pr0)	vr1 = mul.f32 vr6, r50;"
        "V1@(pr0)	vmsk1 = neq.f32 vr7, vr6;"
        "}"
        "{"
        "V0@(pr0)	vr2 = cvtftoint.s32 vr1, r46;"
        "V1@(pr0)	vmsk2 = gt.f32 vr1, r46;"
        "}"
        "{"
        "V0@(pr0)	vr3 = cvtftoint.s32 vr1, r56;"
        "V1@(pr0)	vr2 = sel vmsk2 vr2, vr3;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 23;"
        "V1@(pr0)	vr3 = shr.u32 vr1, r32;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 255;"
        "pseudo@0	@pseudo imm_1 = 127;"
        "V0@(pr0)	vr3 = and.u32 vr3, r32;"
        "V1@(pr0)	vr3 = sub.s32 vr3, r33;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 23;"
        "V0@(pr0)	vmsk2 = gteq.s32 vr3, r32;"
        "V1@(pr0)	vr2 = cvtinttof.f32 vr2;"
        "}"
        "{"
        "V0@(pr0)	vr2 = sel vmsk2 vr2, vr1;"
        "V1@(pr0)	vr1 = sub.f32 vr1, vr2;"
        "}"
        "{"
        "V0@(pr0)	vr1 = mul.f32 vr1, r51;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 0;"
        "pseudo@0	@pseudo imm_1 = 16512;"
        "V0@(pr0)	vr11 = mul.f32 vr1, r44;"
        "V1@(pr0)	vr6 = sel vmsk1 vr6, vr1;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 19328;"
        "V0@(pr0)	vmsk2 = gteq.s32 vr5, r36;"
        "V1@(pr0)	vr11 = cvtftoint.s32 vr11, r56;"
        "}"
        "{"
        "V0@(pr0)	vr1 = mov.u32 r46;"
        "V1@(pr0)	vr2 = mov.u32 r46;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 19200;"
        "pseudo@0	@pseudo imm_2 = 0;"
        "pseudo@0	@pseudo imm_3 = 19200;"
        "V0@(pr0)	vmsk3 = ls.s32 vr5, r36;"
        "V1@(pr0)	vr3 = add.f32 vr6, r45;"
        "}"
        "{"
        "V0@(pr0)	vr7 = sel vmsk3 vr7, vr3;"
        "V1@(pr0)	vr3 = and.u32 vr7, r48;"
        "}"
        "{"
        "V0@(pr0)	vr3 = cvtinttof.f32 vr3;"
        "V1@(pr0)	vr1 = sel vmsk2 vr3, vr1;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 2;"
        "pseudo@0	@pseudo imm_2 = 65535;"
        "pseudo@0	@pseudo imm_3 = 32767;"
        "V0@(pr0)	vr3 = cvtftoint.s32 vr3, r45;"
        "V1@(pr0)	vr3 = shl.u32 vr3, r32;"
        "}"
        "{"
        "V0@(pr0)	vr2 = sel vmsk2 vr3, vr2;"
        "V1@(pr0)	vr6 = sel vmsk1 vr1, vr6;"
        "}"
        "{"
        "V0@(pr0)	vr11 = sel vmsk1 vr2, vr11;"
        "}"
        "{"
        "V0@(pr0)	vr28 = mov.u32 vr6;"
        "V1@(pr0)	vr29 = mov.u32 vr11;"
        "}"
        "{"
        "V0@(pr0)	vr10 = mul.f32 vr28, r52;"
        "V1@(pr0)	vr11 = mov.u32 r46;"
        "}"
        "{"
        "V0@(pr0)	vr12 = mov.u32 r46;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 65535;"
        "pseudo@0	@pseudo imm_1 = 32767;"
        "V0@(pr0)	vr0 = and.u32 vr10, r44;"
        "}"
        "{"
        "V0@(pr0)	vr3 = mul.f32 vr10, vr10;"
        "V1@(pr0)	vr7 = mov.u32 r46;"
        "}"
        "{"
        "V0@(pr0)	vr4 = mul.f32 vr3, vr10;"
        "V1@(pr0)	vmsk1 = eq.s32 vr12, r46;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 51667;"
        "pseudo@0	@pseudo imm_1 = 12078;"
        "pseudo@0	@pseudo imm_2 = 12084;"
        "pseudo@0	@pseudo imm_3 = 45783;"
        "V0@(pr0)	vr1 = mul.f32 vr3, r44;"
        "V1@(pr0)	vr1 = add.f32 vr1, r45;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 61211;"
        "pseudo@0	@pseudo imm_1 = 13880;"
        "V0@(pr0)	vr1 = mul.f32 vr3, vr1;"
        "V1@(pr0)	vr1 = add.f32 vr1, r44;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 3329;"
        "pseudo@0	@pseudo imm_1 = 47440;"
        "V0@(pr0)	vr1 = mul.f32 vr3, vr1;"
        "V1@(pr0)	vr1 = add.f32 vr1, r44;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 34953;"
        "pseudo@0	@pseudo imm_1 = 15368;"
        "V0@(pr0)	vr1 = mul.f32 vr3, vr1;"
        "V1@(pr0)	vr5 = add.f32 vr1, r44;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 43691;"
        "pseudo@0	@pseudo imm_1 = 48682;"
        "V0@(pr0)	vr1 = mul.f32 vr3, vr5;"
        "V1@(pr0)	vr1 = add.f32 vr1, r44;"
        "}"
        "{"
        "V0@(pr0)	vr1 = mul.f32 vr4, vr1;"
        "V1@(pr0)	vr1 = add.f32 vr10, vr1;"
        "}"
        "{"
        "V0@(pr0)	vr2 = mul.f32 vr11, r50;"
        "V1@(pr0)	vr6 = sel vmsk1 vr6, vr1;"
        "}"
        "{"
        "V0@(pr0)	vr1 = mul.f32 vr4, vr5;"
        "V1@(pr0)	vr1 = sub.f32 vr2, vr1;"
        "}"
        "{"
        "V0@(pr0)	vr1 = mul.f32 vr3, vr1;"
        "V1@(pr0)	vr1 = sub.f32 vr1, vr11;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 43691;"
        "pseudo@0	@pseudo imm_1 = 48682;"
        "V0@(pr0)	vr2 = mul.f32 vr4, r44;"
        "V1@(pr0)	vr1 = sub.f32 vr1, vr2;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 65535;"
        "pseudo@0	@pseudo imm_1 = 32767;"
        "V0@(pr0)	vr2 = cvtftoint.s32 vr10, r44;"
        "V1@(pr0)	vr1 = sub.f32 vr10, vr1;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 12800;"
        "V0@(pr0)	vr6 = sel vmsk1 vr1, vr6;"
        "V1@(pr0)	vmsk1 = ls.s32 vr0, r36;"
        "}"
        "{"
        "V0@(pr0)	vr1 = sel vmsk1 vr6, vr10;"
        "V1@(pr0)	vmsk1 = eq.s32 vr2, r46;"
        "}"
        "{"
        "V0@(pr0)	vr6 = sel vmsk1 vr6, vr1;"
        "V1@(pr0)	vr10 = mov.u32 vr6;"
        "}"
        "{"
        "V0@(pr0)	vr30 = mov.u32 vr10;"
        "V1@(pr0)	vr1 = mov.u32 r50;"
        "}"
        "{"
        "V0@(pr0)	vr11 = mov.u32 r46;"
        "V1@(pr0)	vr10 = sub.f32 vr1, vr28;"
        "}"
        "{"
        "V0@(pr0)	vr10 = mul.f32 vr10, r52;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 65535;"
        "pseudo@0	@pseudo imm_1 = 32767;"
        "V0@(pr0)	vr4 = mul.f32 vr10, vr10;"
        "V1@(pr0)	vr7 = and.u32 vr10, r44;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 39322;"
        "pseudo@0	@pseudo imm_1 = 16025;"
        "V0@(pr0)	vr0 = mov.u32 r46;"
        "V1@(pr0)	vmsk1 = ls.s32 vr7, r44;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 55118;"
        "pseudo@0	@pseudo imm_1 = 44359;"
        "pseudo@0	@pseudo imm_2 = 29942;"
        "pseudo@0	@pseudo imm_3 = 12559;"
        "V0@(pr0)	vr5 = mul.f32 vr4, r44;"
        "V1@(pr0)	vr5 = add.f32 vr5, r45;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 62076;"
        "pseudo@0	@pseudo imm_1 = 46227;"
        "V0@(pr0)	vr5 = mul.f32 vr4, vr5;"
        "V1@(pr0)	vr5 = add.f32 vr5, r44;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 3329;"
        "pseudo@0	@pseudo imm_1 = 14288;"
        "V0@(pr0)	vr5 = mul.f32 vr4, vr5;"
        "V1@(pr0)	vr5 = add.f32 vr5, r44;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 2913;"
        "pseudo@0	@pseudo imm_1 = 47798;"
        "V0@(pr0)	vr5 = mul.f32 vr4, vr5;"
        "V1@(pr0)	vr5 = add.f32 vr5, r44;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 43691;"
        "pseudo@0	@pseudo imm_1 = 15658;"
        "V0@(pr0)	vr5 = mul.f32 vr4, vr5;"
        "V1@(pr0)	vr5 = add.f32 vr5, r44;"
        "}"
        "{"
        "V0@(pr0)	vr5 = mul.f32 vr4, vr5;"
        "}"
        "{"
        "V0@(pr0)	vr1 = mul.f32 vr10, vr11;"
        "}"
        "{"
        "V0@(pr0)	vr2 = mul.f32 vr4, vr5;"
        "V1@(pr0)	vr1 = sub.f32 vr2, vr1;"
        "}"
        "{"
        "V0@(pr0)	vr2 = mul.f32 vr4, r50;"
        "V1@(pr0)	vr1 = sub.f32 vr2, vr1;"
        "}"
        "{"
        "V0@(pr0)	vr2 = mov.u32 r49;"
        "V1@(pr0)	vr1 = sub.f32 vr2, vr1;"
        "}"
        "{"
        "V0@(pr0)	vr6 = sel vmsk1 vr0, vr1;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 16200;"
        "pseudo@0	@pseudo imm_1 = 256;"
        "V0@(pr0)	vmsk2 = gt.s32 vr7, r36;"
        "V1@(pr0)	vr1 = sub.s32 vr7, r37;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 0;"
        "pseudo@0	@pseudo imm_1 = 16016;"
        "V0@(pr0)	vr2 = mul.f32 vr4, r50;"
        "V1@(pr0)	vr1 = sel vmsk2 vr1, r44;"
        "}"
        "{"
        "V0@(pr0)	vr3 = mov.u32 r49;"
        "V1@(pr0)	vr2 = sub.f32 vr2, vr1;"
        "}"
        "{"
        "V1@(pr0)	vr1 = sub.f32 vr3, vr1;"
        "}"
        "{"
        "V0@(pr0)	vr3 = mul.f32 vr10, vr11;"
        "V1@(pr0)	vr3 = add.f32 vr3, vr2;"
        "}"
        "{"
        "V0@(pr0)	vr2 = mul.f32 vr4, vr5;"
        "V1@(pr0)	vr3 = sub.f32 vr3, vr2;"
        "}"
        "{"
        "V1@(pr0)	vr1 = sub.f32 vr1, vr3;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 12800;"
        "V0@(pr0)	vr6 = sel vmsk1 vr1, vr6;"
        "V1@(pr0)	vmsk1 = ls.s32 vr7, r36;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 65535;"
        "pseudo@0	@pseudo imm_1 = 32767;"
        "V0@(pr0)	vr2 = cvtftoint.s32 vr10, r44;"
        "}"
        "{"
        "V0@(pr0)	vr1 = sel vmsk1 vr6, r49;"
        "V1@(pr0)	vmsk1 = eq.s32 vr2, r46;"
        "}"
        "{"
        "V0@(pr0)	vr10 = sel vmsk1 vr6, vr1;"
        "}"
        "{"
        "V1@(pr0)	vmsk1 = gteq.s32 vr29, r48;"
        "}"
        "{"
        "V0@(pr0)	vr30 = sel vmsk1 vr30, vr10;"
        "V1@(pr0)	vr1 = mov.u32 r49;"
        "}"
        "{"
        "V1@(pr0)	vr10 = sub.f32 vr1, vr28;"
        "}"
        "{"
        "V0@(pr0)	vr10 = mul.f32 vr10, r52;"
        "V1@(pr0)	vr11 = mov.u32 r46;"
        "}"
        "{"
        "V0@(pr0)	vr12 = mov.u32 r46;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 65535;"
        "pseudo@0	@pseudo imm_1 = 32767;"
        "V0@(pr0)	vr0 = and.u32 vr10, r44;"
        "}"
        "{"
        "V0@(pr0)	vr3 = mul.f32 vr10, vr10;"
        "V1@(pr0)	vr7 = mov.u32 r46;"
        "}"
        "{"
        "V0@(pr0)	vr4 = mul.f32 vr3, vr10;"
        "V1@(pr0)	vmsk1 = eq.s32 vr12, r46;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 51667;"
        "pseudo@0	@pseudo imm_1 = 12078;"
        "pseudo@0	@pseudo imm_2 = 12084;"
        "pseudo@0	@pseudo imm_3 = 45783;"
        "V0@(pr0)	vr1 = mul.f32 vr3, r44;"
        "V1@(pr0)	vr1 = add.f32 vr1, r45;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 61211;"
        "pseudo@0	@pseudo imm_1 = 13880;"
        "V0@(pr0)	vr1 = mul.f32 vr3, vr1;"
        "V1@(pr0)	vr1 = add.f32 vr1, r44;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 3329;"
        "pseudo@0	@pseudo imm_1 = 47440;"
        "V0@(pr0)	vr1 = mul.f32 vr3, vr1;"
        "V1@(pr0)	vr1 = add.f32 vr1, r44;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 34953;"
        "pseudo@0	@pseudo imm_1 = 15368;"
        "V0@(pr0)	vr1 = mul.f32 vr3, vr1;"
        "V1@(pr0)	vr5 = add.f32 vr1, r44;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 43691;"
        "pseudo@0	@pseudo imm_1 = 48682;"
        "V0@(pr0)	vr1 = mul.f32 vr3, vr5;"
        "V1@(pr0)	vr1 = add.f32 vr1, r44;"
        "}"
        "{"
        "V0@(pr0)	vr1 = mul.f32 vr4, vr1;"
        "V1@(pr0)	vr1 = add.f32 vr10, vr1;"
        "}"
        "{"
        "V0@(pr0)	vr2 = mul.f32 vr11, r50;"
        "V1@(pr0)	vr6 = sel vmsk1 vr6, vr1;"
        "}"
        "{"
        "V0@(pr0)	vr1 = mul.f32 vr4, vr5;"
        "V1@(pr0)	vr1 = sub.f32 vr2, vr1;"
        "}"
        "{"
        "V0@(pr0)	vr1 = mul.f32 vr3, vr1;"
        "V1@(pr0)	vr1 = sub.f32 vr1, vr11;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 43691;"
        "pseudo@0	@pseudo imm_1 = 48682;"
        "V0@(pr0)	vr2 = mul.f32 vr4, r44;"
        "V1@(pr0)	vr1 = sub.f32 vr1, vr2;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 65535;"
        "pseudo@0	@pseudo imm_1 = 32767;"
        "V0@(pr0)	vr2 = cvtftoint.s32 vr10, r44;"
        "V1@(pr0)	vr1 = sub.f32 vr10, vr1;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 12800;"
        "V0@(pr0)	vr6 = sel vmsk1 vr1, vr6;"
        "V1@(pr0)	vmsk1 = ls.s32 vr0, r36;"
        "}"
        "{"
        "V0@(pr0)	vr1 = sel vmsk1 vr6, vr10;"
        "V1@(pr0)	vmsk1 = eq.s32 vr2, r46;"
        "}"
        "{"
        "V0@(pr0)	vr6 = sel vmsk1 vr6, vr1;"
        "V1@(pr0)	vr10 = mov.u32 vr6;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 3;"
        "V0@(pr0)	vmsk1 = gteq.s32 vr29, r32;"
        "V1@(pr0)	vr30 = sel vmsk1 vr30, vr10;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 0;"
        "pseudo@0	@pseudo imm_1 = 16320;"
        "V0@(pr0)	vr11 = mov.u32 r46;"
        "V1@(pr0)	vr10 = sub.f32 vr28, r44;"
        "}"
        "{"
        "V0@(pr0)	vr10 = mul.f32 vr10, r52;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 65535;"
        "pseudo@0	@pseudo imm_1 = 32767;"
        "V0@(pr0)	vr4 = mul.f32 vr10, vr10;"
        "V1@(pr0)	vr7 = and.u32 vr10, r44;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 39322;"
        "pseudo@0	@pseudo imm_1 = 16025;"
        "V0@(pr0)	vr0 = mov.u32 r46;"
        "V1@(pr0)	vmsk1 = ls.s32 vr7, r44;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 55118;"
        "pseudo@0	@pseudo imm_1 = 44359;"
        "pseudo@0	@pseudo imm_2 = 29942;"
        "pseudo@0	@pseudo imm_3 = 12559;"
        "V0@(pr0)	vr5 = mul.f32 vr4, r44;"
        "V1@(pr0)	vr5 = add.f32 vr5, r45;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 62076;"
        "pseudo@0	@pseudo imm_1 = 46227;"
        "V0@(pr0)	vr5 = mul.f32 vr4, vr5;"
        "V1@(pr0)	vr5 = add.f32 vr5, r44;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 3329;"
        "pseudo@0	@pseudo imm_1 = 14288;"
        "V0@(pr0)	vr5 = mul.f32 vr4, vr5;"
        "V1@(pr0)	vr5 = add.f32 vr5, r44;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 2913;"
        "pseudo@0	@pseudo imm_1 = 47798;"
        "V0@(pr0)	vr5 = mul.f32 vr4, vr5;"
        "V1@(pr0)	vr5 = add.f32 vr5, r44;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 43691;"
        "pseudo@0	@pseudo imm_1 = 15658;"
        "V0@(pr0)	vr5 = mul.f32 vr4, vr5;"
        "V1@(pr0)	vr5 = add.f32 vr5, r44;"
        "}"
        "{"
        "V0@(pr0)	vr5 = mul.f32 vr4, vr5;"
        "}"
        "{"
        "V0@(pr0)	vr1 = mul.f32 vr10, vr11;"
        "}"
        "{"
        "V0@(pr0)	vr2 = mul.f32 vr4, vr5;"
        "V1@(pr0)	vr1 = sub.f32 vr2, vr1;"
        "}"
        "{"
        "V0@(pr0)	vr2 = mul.f32 vr4, r50;"
        "V1@(pr0)	vr1 = sub.f32 vr2, vr1;"
        "}"
        "{"
        "V0@(pr0)	vr2 = mov.u32 r49;"
        "V1@(pr0)	vr1 = sub.f32 vr2, vr1;"
        "}"
        "{"
        "V0@(pr0)	vr6 = sel vmsk1 vr0, vr1;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 16200;"
        "pseudo@0	@pseudo imm_1 = 256;"
        "V0@(pr0)	vmsk2 = gt.s32 vr7, r36;"
        "V1@(pr0)	vr1 = sub.s32 vr7, r37;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 0;"
        "pseudo@0	@pseudo imm_1 = 16016;"
        "V0@(pr0)	vr2 = mul.f32 vr4, r50;"
        "V1@(pr0)	vr1 = sel vmsk2 vr1, r44;"
        "}"
        "{"
        "V0@(pr0)	vr3 = mov.u32 r49;"
        "V1@(pr0)	vr2 = sub.f32 vr2, vr1;"
        "}"
        "{"
        "V1@(pr0)	vr1 = sub.f32 vr3, vr1;"
        "}"
        "{"
        "V0@(pr0)	vr3 = mul.f32 vr10, vr11;"
        "V1@(pr0)	vr3 = add.f32 vr3, vr2;"
        "}"
        "{"
        "V0@(pr0)	vr2 = mul.f32 vr4, vr5;"
        "V1@(pr0)	vr3 = sub.f32 vr3, vr2;"
        "}"
        "{"
        "V1@(pr0)	vr1 = sub.f32 vr1, vr3;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 12800;"
        "V0@(pr0)	vr6 = sel vmsk1 vr1, vr6;"
        "V1@(pr0)	vmsk1 = ls.s32 vr7, r36;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 65535;"
        "pseudo@0	@pseudo imm_1 = 32767;"
        "V0@(pr0)	vr2 = cvtftoint.s32 vr10, r44;"
        "}"
        "{"
        "V0@(pr0)	vr1 = sel vmsk1 vr6, r49;"
        "V1@(pr0)	vmsk1 = eq.s32 vr2, r46;"
        "}"
        "{"
        "V0@(pr0)	vr10 = sel vmsk1 vr6, vr1;"
        "}"
        "{"
        "V0@(pr0)	vr10 = mul.f32 vr10, r57;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 5;"
        "V0@(pr0)	vmsk1 = gteq.s32 vr29, r32;"
        "V1@(pr0)	vr30 = sel vmsk1 vr30, vr10;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 0;"
        "pseudo@0	@pseudo imm_1 = 16384;"
        "V0@(pr0)	vr11 = mov.u32 r46;"
        "V1@(pr0)	vr10 = sub.f32 vr28, r44;"
        "}"
        "{"
        "V0@(pr0)	vr10 = mul.f32 vr10, r52;"
        "V1@(pr0)	vr12 = mov.u32 r46;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 65535;"
        "pseudo@0	@pseudo imm_1 = 32767;"
        "V0@(pr0)	vr0 = and.u32 vr10, r44;"
        "}"
        "{"
        "V0@(pr0)	vr3 = mul.f32 vr10, vr10;"
        "V1@(pr0)	vr7 = mov.u32 r46;"
        "}"
        "{"
        "V0@(pr0)	vr4 = mul.f32 vr3, vr10;"
        "V1@(pr0)	vmsk1 = eq.s32 vr12, r46;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 51667;"
        "pseudo@0	@pseudo imm_1 = 12078;"
        "pseudo@0	@pseudo imm_2 = 12084;"
        "pseudo@0	@pseudo imm_3 = 45783;"
        "V0@(pr0)	vr1 = mul.f32 vr3, r44;"
        "V1@(pr0)	vr1 = add.f32 vr1, r45;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 61211;"
        "pseudo@0	@pseudo imm_1 = 13880;"
        "V0@(pr0)	vr1 = mul.f32 vr3, vr1;"
        "V1@(pr0)	vr1 = add.f32 vr1, r44;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 3329;"
        "pseudo@0	@pseudo imm_1 = 47440;"
        "V0@(pr0)	vr1 = mul.f32 vr3, vr1;"
        "V1@(pr0)	vr1 = add.f32 vr1, r44;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 34953;"
        "pseudo@0	@pseudo imm_1 = 15368;"
        "V0@(pr0)	vr1 = mul.f32 vr3, vr1;"
        "V1@(pr0)	vr5 = add.f32 vr1, r44;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 43691;"
        "pseudo@0	@pseudo imm_1 = 48682;"
        "V0@(pr0)	vr1 = mul.f32 vr3, vr5;"
        "V1@(pr0)	vr1 = add.f32 vr1, r44;"
        "}"
        "{"
        "V0@(pr0)	vr1 = mul.f32 vr4, vr1;"
        "V1@(pr0)	vr1 = add.f32 vr10, vr1;"
        "}"
        "{"
        "V0@(pr0)	vr2 = mul.f32 vr11, r50;"
        "V1@(pr0)	vr6 = sel vmsk1 vr6, vr1;"
        "}"
        "{"
        "V0@(pr0)	vr1 = mul.f32 vr4, vr5;"
        "V1@(pr0)	vr1 = sub.f32 vr2, vr1;"
        "}"
        "{"
        "V0@(pr0)	vr1 = mul.f32 vr3, vr1;"
        "V1@(pr0)	vr1 = sub.f32 vr1, vr11;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 43691;"
        "pseudo@0	@pseudo imm_1 = 48682;"
        "V0@(pr0)	vr2 = mul.f32 vr4, r44;"
        "V1@(pr0)	vr1 = sub.f32 vr1, vr2;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 65535;"
        "pseudo@0	@pseudo imm_1 = 32767;"
        "V0@(pr0)	vr2 = cvtftoint.s32 vr10, r44;"
        "V1@(pr0)	vr1 = sub.f32 vr10, vr1;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 12800;"
        "V0@(pr0)	vr6 = sel vmsk1 vr1, vr6;"
        "V1@(pr0)	vmsk1 = ls.s32 vr0, r36;"
        "}"
        "{"
        "V0@(pr0)	vr1 = sel vmsk1 vr6, vr10;"
        "V1@(pr0)	vmsk1 = eq.s32 vr2, r46;"
        "}"
        "{"
        "V0@(pr0)	vr6 = sel vmsk1 vr6, vr1;"
        "V1@(pr0)	vr10 = mov.u32 vr6;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 7;"
        "V0@(pr0)	vmsk1 = gteq.s32 vr29, r32;"
        "V1@(pr0)	vr30 = sel vmsk1 vr30, vr10;"
        "}"
        "{"
        "V0@(pr0)	vr10 = mul.f32 vr31, r52;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 65535;"
        "pseudo@0	@pseudo imm_1 = 32767;"
        "V0@(pr0)	vr0 = and.u32 vr10, r44;"
        "}"
        "{"
        "V0@(pr0)	vr3 = mul.f32 vr10, vr10;"
        "V1@(pr0)	vr7 = mov.u32 r46;"
        "}"
        "{"
        "V0@(pr0)	vr4 = mul.f32 vr3, vr10;"
        "V1@(pr0)	vmsk1 = eq.s32 vr12, r46;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 51667;"
        "pseudo@0	@pseudo imm_1 = 12078;"
        "pseudo@0	@pseudo imm_2 = 12084;"
        "pseudo@0	@pseudo imm_3 = 45783;"
        "V0@(pr0)	vr1 = mul.f32 vr3, r44;"
        "V1@(pr0)	vr1 = add.f32 vr1, r45;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 61211;"
        "pseudo@0	@pseudo imm_1 = 13880;"
        "V0@(pr0)	vr1 = mul.f32 vr3, vr1;"
        "V1@(pr0)	vr1 = add.f32 vr1, r44;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 3329;"
        "pseudo@0	@pseudo imm_1 = 47440;"
        "V0@(pr0)	vr1 = mul.f32 vr3, vr1;"
        "V1@(pr0)	vr1 = add.f32 vr1, r44;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 34953;"
        "pseudo@0	@pseudo imm_1 = 15368;"
        "V0@(pr0)	vr1 = mul.f32 vr3, vr1;"
        "V1@(pr0)	vr5 = add.f32 vr1, r44;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 43691;"
        "pseudo@0	@pseudo imm_1 = 48682;"
        "V0@(pr0)	vr1 = mul.f32 vr3, vr5;"
        "V1@(pr0)	vr1 = add.f32 vr1, r44;"
        "}"
        "{"
        "V0@(pr0)	vr1 = mul.f32 vr4, vr1;"
        "V1@(pr0)	vr1 = add.f32 vr10, vr1;"
        "}"
        "{"
        "V0@(pr0)	vr2 = mul.f32 vr11, r50;"
        "V1@(pr0)	vr6 = sel vmsk1 vr6, vr1;"
        "}"
        "{"
        "V0@(pr0)	vr1 = mul.f32 vr4, vr5;"
        "V1@(pr0)	vr1 = sub.f32 vr2, vr1;"
        "}"
        "{"
        "V0@(pr0)	vr1 = mul.f32 vr3, vr1;"
        "V1@(pr0)	vr1 = sub.f32 vr1, vr11;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 43691;"
        "pseudo@0	@pseudo imm_1 = 48682;"
        "V0@(pr0)	vr2 = mul.f32 vr4, r44;"
        "V1@(pr0)	vr1 = sub.f32 vr1, vr2;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 65535;"
        "pseudo@0	@pseudo imm_1 = 32767;"
        "V0@(pr0)	vr2 = cvtftoint.s32 vr10, r44;"
        "V1@(pr0)	vr1 = sub.f32 vr10, vr1;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 12800;"
        "V0@(pr0)	vr6 = sel vmsk1 vr1, vr6;"
        "V1@(pr0)	vmsk1 = ls.s32 vr0, r36;"
        "}"
        "{"
        "V0@(pr0)	vr1 = sel vmsk1 vr6, vr10;"
        "V1@(pr0)	vmsk1 = eq.s32 vr2, r46;"
        "}"
        "{"
        "V0@(pr0)	vr6 = sel vmsk1 vr6, vr1;"
        "V1@(pr0)	vr10 = mov.u32 vr6;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 65535;"
        "pseudo@0	@pseudo imm_1 = 32767;"
        "pseudo@0	@pseudo imm_2 = 16000;"
        "V0@(pr0)	vr1 = and.u32 vr31, r44;"
        "V1@(pr0)	vmsk1 = ls.s32 vr1, r38;"
        "}"
        "{"
        "V0@(pr0)	vr30 = mul.f32 vr30, r57;"
        "V1@(pr0)	vr10 = sel vmsk1 vr30, vr10;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 32704;"
        "pseudo@0	@pseudo imm_2 = 32640;"
        "V0@(pr0)	vmsk1 = eq.s32 vr1, r38;"
        "V1@(pr0)	vr10 = sel vmsk1 vr10, r36;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 32704;"
        "pseudo@0	@pseudo imm_2 = 32640;"
        "V0@(pr0)	vmsk1 = gt.s32 vr1, r38;"
        "V1@(pr0)	vr10 = sel vmsk1 vr10, r36;"
        "}"
        "{"
        "V0@(pr0)	vmsk1 = eq.s32 vr31, r46;"
        "V1@(pr0)	vr10 = sel vmsk1 vr10, r46;"
        "}"
        "{"
        "V0@(pr0)	vmsk1 = eq.s32 vr31, r47;"
        "V1@(pr0)	vr10 = sel vmsk1 vr10, r47;"
        "}"
        "{"
        "V0@(pr0)	vmsk1 = eq.f32 vr10, r46;"
        "V1@(pr0)	vr31 = mov.u32 vr10;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 4;"
        "S0@(pr0)	r3 = add.s32 r9, r32;"
        "S1@(pr0)	r3 = ld [smem:r3];"
        "}"
        "{"
        "S0@(pr0)	r3 = add.s32 r3, r9;"
        "S1@(pr0)	r0 = ld [smem:r3];"
        "}"
        "{"
        "S1@(pr0)	r0 = ld [smem:r3];"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 0;"
        "pseudo@0	@pseudo imm_2 = 1;"
        "pseudo@0	@pseudo imm_4 = 0;"
        "pseudo@0	@pseudo vs_imm0 = 1;"
        "S0@(pr0)	r1 = add.s32 r0, r32;"
        "VL@(pr0)	vr0 = ld [vmem:1+2,4,0];"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 1024;"
        "pseudo@0	@pseudo imm_2 = 1;"
        "pseudo@0	@pseudo imm_4 = 0;"
        "pseudo@0	@pseudo vs_imm0 = 1;"
        "S0@(pr0)	r1 = add.s32 r0, r32;"
        "VL@(pr0)	vr1 = ld [vmem:1+2,4,0];"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 2048;"
        "pseudo@0	@pseudo imm_2 = 1;"
        "pseudo@0	@pseudo imm_4 = 0;"
        "pseudo@0	@pseudo vs_imm0 = 1;"
        "S0@(pr0)	r1 = add.s32 r0, r32;"
        "VL@(pr0)	vr2 = ld [vmem:1+2,4,0];"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 3072;"
        "pseudo@0	@pseudo imm_2 = 1;"
        "pseudo@0	@pseudo imm_4 = 0;"
        "pseudo@0	@pseudo vs_imm0 = 1;"
        "S0@(pr0)	r1 = add.s32 r0, r32;"
        "VL@(pr0)	vr3 = ld [vmem:1+2,4,0];"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 4096;"
        "pseudo@0	@pseudo imm_2 = 1;"
        "pseudo@0	@pseudo imm_4 = 0;"
        "pseudo@0	@pseudo vs_imm0 = 1;"
        "S0@(pr0)	r1 = add.s32 r0, r32;"
        "VL@(pr0)	vr4 = ld [vmem:1+2,4,0];"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 5120;"
        "pseudo@0	@pseudo imm_2 = 1;"
        "pseudo@0	@pseudo imm_4 = 0;"
        "pseudo@0	@pseudo vs_imm0 = 1;"
        "S0@(pr0)	r1 = add.s32 r0, r32;"
        "VL@(pr0)	vr5 = ld [vmem:1+2,4,0];"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 6144;"
        "pseudo@0	@pseudo imm_2 = 1;"
        "pseudo@0	@pseudo imm_4 = 0;"
        "pseudo@0	@pseudo vs_imm0 = 1;"
        "S0@(pr0)	r1 = add.s32 r0, r32;"
        "VL@(pr0)	vr6 = ld [vmem:1+2,4,0];"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 7168;"
        "pseudo@0	@pseudo imm_2 = 1;"
        "pseudo@0	@pseudo imm_4 = 0;"
        "pseudo@0	@pseudo vs_imm0 = 1;"
        "S0@(pr0)	r1 = add.s32 r0, r32;"
        "VL@(pr0)	vr7 = ld [vmem:1+2,4,0];"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 8192;"
        "pseudo@0	@pseudo imm_2 = 1;"
        "pseudo@0	@pseudo imm_4 = 0;"
        "pseudo@0	@pseudo vs_imm0 = 1;"
        "S0@(pr0)	r1 = add.s32 r0, r32;"
        "VL@(pr0)	vr10 = ld [vmem:1+2,4,0];"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 9216;"
        "pseudo@0	@pseudo imm_2 = 1;"
        "pseudo@0	@pseudo imm_4 = 0;"
        "pseudo@0	@pseudo vs_imm0 = 1;"
        "S0@(pr0)	r1 = add.s32 r0, r32;"
        "VL@(pr0)	vr11 = ld [vmem:1+2,4,0];"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 10240;"
        "pseudo@0	@pseudo imm_2 = 1;"
        "pseudo@0	@pseudo imm_4 = 0;"
        "pseudo@0	@pseudo vs_imm0 = 1;"
        "S0@(pr0)	r1 = add.s32 r0, r32;"
        "VL@(pr0)	vr12 = ld [vmem:1+2,4,0];"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 11264;"
        "pseudo@0	@pseudo imm_2 = 1;"
        "pseudo@0	@pseudo imm_4 = 0;"
        "pseudo@0	@pseudo vs_imm0 = 1;"
        "S0@(pr0)	r1 = add.s32 r0, r32;"
        "VL@(pr0)	vr13 = ld [vmem:1+2,4,0];"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 12288;"
        "pseudo@0	@pseudo imm_2 = 1;"
        "pseudo@0	@pseudo imm_4 = 0;"
        "pseudo@0	@pseudo vs_imm0 = 1;"
        "S0@(pr0)	r1 = add.s32 r0, r32;"
        "VL@(pr0)	vr14 = ld [vmem:1+2,4,0];"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 13312;"
        "pseudo@0	@pseudo imm_2 = 1;"
        "pseudo@0	@pseudo imm_4 = 0;"
        "pseudo@0	@pseudo vs_imm0 = 1;"
        "S0@(pr0)	r1 = add.s32 r0, r32;"
        "VL@(pr0)	vr15 = ld [vmem:1+2,4,0];"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 14336;"
        "pseudo@0	@pseudo imm_2 = 1;"
        "pseudo@0	@pseudo imm_4 = 0;"
        "pseudo@0	@pseudo vs_imm0 = 1;"
        "S0@(pr0)	r1 = add.s32 r0, r32;"
        "VL@(pr0)	vr16 = ld [vmem:1+2,4,0];"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 15360;"
        "pseudo@0	@pseudo imm_2 = 1;"
        "pseudo@0	@pseudo imm_4 = 0;"
        "pseudo@0	@pseudo vs_imm0 = 1;"
        "S0@(pr0)	r1 = add.s32 r0, r32;"
        "VL@(pr0)	vr17 = ld [vmem:1+2,4,0];"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 16384;"
        "pseudo@0	@pseudo imm_2 = 1;"
        "pseudo@0	@pseudo imm_4 = 0;"
        "pseudo@0	@pseudo vs_imm0 = 1;"
        "S0@(pr0)	r1 = add.s32 r0, r32;"
        "VL@(pr0)	vr28 = ld [vmem:1+2,4,0];"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 17408;"
        "pseudo@0	@pseudo imm_1 = 0;"
        "S0@(pr0)	r0 = add.s32 r0, r44;"
        "S1@(pr0)	[smem:r3] = st r0;"
        "}"
        "{"
        "V0@(pr0)	vr2 = mul.f32 vr31, vr10;"
        "V1@(pr0)	vr5 = sel vmsk1 vr5, vr1;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 65535;"
        "pseudo@0	@pseudo imm_1 = 32767;"
        "V0@(pr0)	vr2 = and.u32 vr2, r44;"
        "V1@(pr0)	vmsk1 = ls.f32 vr31, r46;"
        "}"
        "{"
        "V0@(pr0)	vr4 = sel vmsk1 vr11, r56;"
        "V1@(pr0)	vmsk1 = eq.f32 vr31, r46;"
        "}"
        "{"
        "V0@(pr0)	vr4 = sel vmsk1 vr4, r48;"
        "}"
        "{"
        "V0@(pr0)	(urf) = rcp.f32 vr2;"
        "MTR@(pr0)	vr31 = pop urf;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 19200;"
        "V0@(pr0)	vmsk1 = gteq.s32 vr6, r36;"
        "V1@(pr0)	vr2 = mov.u32 vr31;"
        "}"
        "{"
        "V0@(pr0)	vr4 = sel vmsk1 vr4, r48;"
        "V1@(pr0)	vmsk1 = ls.s32 vr28, r46;"
        "}"
        "{"
        "V0@(pr0)	vr2 = mul.f32 vr2, r52;"
        "V1@(pr0)	vr11 = sel vmsk1 vr11, vr4;"
        "}"
        "{"
        "V0@(pr0)	(urf) = log.f32 vr2;"
        "MTR@(pr0)	vr31 = pop urf;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 29208;"
        "pseudo@0	@pseudo imm_1 = 16177;"
        "V0@(pr0)	vr31 = mul.f32 vr31, r44;"
        "}"
        "{"
        "V1@(pr0)	vr2 = mov.u32 vr31;"
        "}"
        "{"
        "V0@(pr0)	vmsk1 = ls.s32 vr28, r46;"
        "}"
        "{"
        "V0@(pr0)	vr13 = sel vmsk1 vr13, vr2;"
        "V1@(pr0)	vr12 = sel vmsk1 vr12, vr5;"
        "}"
        "{"
        "V0@(pr0)	vr1 = mul.f32 vr10, r57;"
        "V1@(pr0)	vr10 = sel vmsk1 vr10, vr1;"
        "}"
        "{"
        "V0@(pr0)	vr1 = mul.f32 vr28, r57;"
        "}"
        "{"
        "V0@(pr0)	(urf) = log.f32 vr1;"
        "MTR@(pr0)	vr31 = pop urf;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 29208;"
        "pseudo@0	@pseudo imm_1 = 16177;"
        "V0@(pr0)	vr31 = mul.f32 vr31, r44;"
        "}"
        "{"
        "V1@(pr0)	vr1 = mov.u32 vr31;"
        "}"
        "{"
        "V0@(pr0)	(urf) = log.f32 vr28;"
        "MTR@(pr0)	vr31 = pop urf;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 29208;"
        "pseudo@0	@pseudo imm_1 = 16177;"
        "V0@(pr0)	vr31 = mul.f32 vr31, r44;"
        "}"
        "{"
        "V0@(pr0)	vr3 = mov.u32 vr31;"
        "V1@(pr0)	vmsk1 = ls.s32 vr28, r46;"
        "}"
        "{"
        "V0@(pr0)	vr1 = mul.f32 vr1, r57;"
        "}"
        "{"
        "V0@(pr0)	vr3 = mul.f32 vr3, r57;"
        "V1@(pr0)	vr5 = sel vmsk1 vr0, vr1;"
        "}"
        "{"
        "V0@(pr0)	vr1 = mov.u32 r48;"
        "V1@(pr0)	vr5 = sel vmsk1 vr3, vr5;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 12416;"
        "V0@(pr0)	vr4 = sel vmsk1 vr1, r56;"
        "V1@(pr0)	vmsk1 = ls.s32 vr6, r36;"
        "}"
        "{"
        "V0@(pr0)	vr12 = sel vmsk1 vr12, vr5;"
        "V1@(pr0)	vr11 = sel vmsk1 vr11, vr4;"
        "}"
        "{"
        "V1@(pr0)	vr1 = sub.f32 vr10, vr10;"
        "}"
        "{"
        "V0@(pr0)	(urf) = rcp.f32 vr1;"
        "MTR@(pr0)	vr31 = pop urf;"
        "}"
        "{"
        "V0@(pr0)	vr2 = mov.u32 r48;"
        "V1@(pr0)	vmsk1 = ls.s32 vr28, r46;"
        "}"
        "{"
        "V0@(pr0)	vr2 = sel vmsk1 vr2, r56;"
        "}"
        "{"
        "V0@(pr0)	vr1 = mov.u32 vr31;"
        "V1@(pr0)	vmsk1 = eq.s32 vr6, r46;"
        "}"
        "{"
        "V0@(pr0)	vr12 = sel vmsk1 vr12, vr1;"
        "V1@(pr0)	vr11 = sel vmsk1 vr11, vr2;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 32640;"
        "V0@(pr0)	vr1 = mul.f32 vr10, vr10;"
        "V1@(pr0)	vmsk1 = gteq.s32 vr6, r36;"
        "}"
        "{"
        "V0@(pr0)	vr12 = sel vmsk1 vr12, vr1;"
        "V1@(pr0)	vr11 = sel vmsk1 vr11, r48;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 2;"
        "V0@(pr0)	vr4 = mov.u32 vr10;"
        "V1@(pr0)	vr5 = mov.u32 r32;"
        "}"
        "{"
        "V0@(pr0)	vr1 = mov.u32 r49;"
        "V1@(pr0)	vr2 = sub.f32 vr1, vr10;"
        "}"
        "{"
        "V1@(pr0)	vr3 = mov.u32 r46;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 18976;"
        "pseudo@0	@pseudo imm_1 = 16187;"
        "V0@(pr0)	vmsk1 = gteq.s32 vr6, r44;"
        "}"
        "{"
        "V0@(pr0)	vr4 = sel vmsk1 vr4, vr2;"
        "V1@(pr0)	vr5 = sel vmsk1 vr5, vr3;"
        "}"
        "{"
        "V0@(pr0)	vr3 = mov.u32 r48;"
        "V1@(pr0)	vr2 = add.f32 vr10, r49;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 13064;"
        "pseudo@0	@pseudo imm_1 = 15981;"
        "pseudo@0	@pseudo imm_2 = 5827;"
        "pseudo@0	@pseudo imm_3 = 16315;"
        "V0@(pr0)	vmsk1 = gteq.s32 vr6, r44;"
        "V1@(pr0)	vr2 = sub.f32 vr2, r45;"
        "}"
        "{"
        "V0@(pr0)	vr4 = sel vmsk1 vr4, vr2;"
        "V1@(pr0)	vr5 = sel vmsk1 vr5, vr3;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 26214;"
        "pseudo@0	@pseudo imm_1 = 16230;"
        "V0@(pr0)	vmsk1 = lseq.s32 vr6, r44;"
        "}"
        "{"
        "V0@(pr0)	vr15 = sel vmsk1 vr0, vr4;"
        "V1@(pr0)	vr16 = sel vmsk1 vr0, vr5;"
        "}"
        "{"
        "V0@(pr0)	(urf) = log.f32 vr10;"
        "MTR@(pr0)	vr31 = pop urf;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 29208;"
        "pseudo@0	@pseudo imm_1 = 16177;"
        "V0@(pr0)	vr31 = mul.f32 vr31, r44;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 26214;"
        "pseudo@0	@pseudo imm_1 = 16230;"
        "V0@(pr0)	vr1 = mov.u32 vr31;"
        "V1@(pr0)	vmsk1 = lseq.s32 vr6, r44;"
        "}"
        "{"
        "V0@(pr0)	vr1 = mul.f32 vr1, r57;"
        "V1@(pr0)	vr17 = sel vmsk1 vr0, vr1;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 2;"
        "V0@(pr0)	vr5 = mov.u32 r32;"
        "V1@(pr0)	vr4 = sub.f32 vr10, r49;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_2 = 5827;"
        "pseudo@0	@pseudo imm_3 = 16315;"
        "V0@(pr0)	vr3 = mov.u32 r48;"
        "V1@(pr0)	vr2 = sub.f32 vr10, r45;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 42528;"
        "pseudo@0	@pseudo imm_1 = 16285;"
        "V0@(pr0)	vmsk1 = gteq.s32 vr6, r44;"
        "}"
        "{"
        "V0@(pr0)	vr4 = sel vmsk1 vr4, vr2;"
        "V1@(pr0)	vr5 = sel vmsk1 vr5, vr3;"
        "}"
        "{"
        "V0@(pr0)	vr1 = mov.u32 r51;"
        "V1@(pr0)	vr2 = sub.f32 vr1, vr10;"
        "}"
        "{"
        "V0@(pr0)	vr3 = mov.u32 r46;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 42520;"
        "pseudo@0	@pseudo imm_1 = 16349;"
        "V0@(pr0)	vmsk1 = gteq.s32 vr6, r44;"
        "}"
        "{"
        "V0@(pr0)	vr4 = sel vmsk1 vr4, vr2;"
        "V1@(pr0)	vr5 = sel vmsk1 vr5, vr3;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 26214;"
        "pseudo@0	@pseudo imm_1 = 16230;"
        "V0@(pr0)	vmsk1 = lseq.s32 vr6, r44;"
        "}"
        "{"
        "V0@(pr0)	vr15 = sel vmsk1 vr4, vr15;"
        "V1@(pr0)	vr16 = sel vmsk1 vr5, vr16;"
        "}"
        "{"
        "V0@(pr0)	vr17 = sel vmsk1 vr0, vr17;"
        "}"
        "{"
        "V0@(pr0)	vr1 = mul.f32 vr15, vr15;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 33698;"
        "pseudo@0	@pseudo imm_1 = 14291;"
        "pseudo@0	@pseudo imm_2 = 38759;"
        "pseudo@0	@pseudo imm_3 = 14695;"
        "V0@(pr0)	vr2 = mul.f32 vr1, r44;"
        "V1@(pr0)	vr2 = add.f32 vr2, r45;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_2 = 21665;"
        "pseudo@0	@pseudo imm_3 = 15004;"
        "V0@(pr0)	vr2 = mul.f32 vr1, vr2;"
        "V1@(pr0)	vr2 = add.f32 vr2, r45;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_2 = 638;"
        "pseudo@0	@pseudo imm_3 = 15346;"
        "V0@(pr0)	vr2 = mul.f32 vr1, vr2;"
        "V1@(pr0)	vr2 = add.f32 vr2, r45;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_2 = 61441;"
        "pseudo@0	@pseudo imm_3 = 15753;"
        "V0@(pr0)	vr2 = mul.f32 vr1, vr2;"
        "V1@(pr0)	vr2 = add.f32 vr2, r45;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_2 = 9023;"
        "pseudo@0	@pseudo imm_3 = 15774;"
        "V0@(pr0)	vr2 = mul.f32 vr1, vr2;"
        "V1@(pr0)	vr2 = add.f32 vr2, r45;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 11381;"
        "pseudo@0	@pseudo imm_1 = 14396;"
        "pseudo@0	@pseudo imm_2 = 33861;"
        "pseudo@0	@pseudo imm_3 = 14562;"
        "V0@(pr0)	vr3 = mul.f32 vr1, r44;"
        "V1@(pr0)	vr3 = add.f32 vr3, r45;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_2 = 46644;"
        "pseudo@0	@pseudo imm_3 = 14853;"
        "V0@(pr0)	vr3 = mul.f32 vr1, vr3;"
        "V1@(pr0)	vr3 = add.f32 vr3, r45;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_2 = 28358;"
        "pseudo@0	@pseudo imm_3 = 15165;"
        "V0@(pr0)	vr3 = mul.f32 vr1, vr3;"
        "V1@(pr0)	vr3 = add.f32 vr3, r45;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_2 = 39189;"
        "pseudo@0	@pseudo imm_3 = 15528;"
        "V0@(pr0)	vr3 = mul.f32 vr1, vr3;"
        "V1@(pr0)	vr3 = add.f32 vr3, r45;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_2 = 6758;"
        "pseudo@0	@pseudo imm_3 = 16037;"
        "V0@(pr0)	vr3 = mul.f32 vr1, vr3;"
        "V1@(pr0)	vr3 = add.f32 vr3, r45;"
        "}"
        "{"
        "V0@(pr0)	vr3 = mul.f32 vr1, vr3;"
        "}"
        "{"
        "V0@(pr0)	vr1 = mul.f32 vr15, vr2;"
        "V1@(pr0)	vr1 = add.f32 vr1, vr3;"
        "}"
        "{"
        "V0@(pr0)	vr2 = mul.f32 vr15, r50;"
        "V1@(pr0)	vr1 = sub.f32 vr1, vr2;"
        "}"
        "{"
        "V0@(pr0)	vmsk1 = eq.s32 vr16, r46;"
        "V1@(pr0)	vr1 = add.f32 vr1, vr17;"
        "}"
        "{"
        "V0@(pr0)	vr17 = sel vmsk1 vr17, vr1;"
        "}"
        "{"
        "V0@(pr0)	vr1 = mul.f32 vr15, vr15;"
        "}"
        "{"
        "V0@(pr0)	vr2 = mul.f32 vr1, vr15;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 31595;"
        "pseudo@0	@pseudo imm_1 = 14757;"
        "pseudo@0	@pseudo imm_2 = 62582;"
        "pseudo@0	@pseudo imm_3 = 47799;"
        "V0@(pr0)	vr3 = mul.f32 vr2, r44;"
        "V1@(pr0)	vr3 = add.f32 vr3, r45;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_2 = 59143;"
        "pseudo@0	@pseudo imm_3 = 15303;"
        "V0@(pr0)	vr3 = mul.f32 vr3, vr2;"
        "V1@(pr0)	vr3 = add.f32 vr3, r45;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_2 = 19783;"
        "pseudo@0	@pseudo imm_3 = 48390;"
        "V0@(pr0)	vr3 = mul.f32 vr3, vr2;"
        "V1@(pr0)	vr3 = add.f32 vr3, r45;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_2 = 47454;"
        "pseudo@0	@pseudo imm_3 = 16119;"
        "V0@(pr0)	vr3 = mul.f32 vr3, vr2;"
        "V1@(pr0)	vr3 = add.f32 vr3, r45;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 63783;"
        "pseudo@0	@pseudo imm_1 = 47523;"
        "pseudo@0	@pseudo imm_2 = 63591;"
        "pseudo@0	@pseudo imm_3 = 14950;"
        "V0@(pr0)	vr4 = mul.f32 vr2, r44;"
        "V1@(pr0)	vr4 = add.f32 vr4, r45;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_2 = 30718;"
        "pseudo@0	@pseudo imm_3 = 47985;"
        "V0@(pr0)	vr4 = mul.f32 vr2, vr4;"
        "V1@(pr0)	vr4 = add.f32 vr4, r45;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_2 = 14141;"
        "pseudo@0	@pseudo imm_3 = 15507;"
        "V0@(pr0)	vr4 = mul.f32 vr2, vr4;"
        "V1@(pr0)	vr4 = add.f32 vr4, r45;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_2 = 8508;"
        "pseudo@0	@pseudo imm_3 = 48663;"
        "V0@(pr0)	vr4 = mul.f32 vr2, vr4;"
        "V1@(pr0)	vr4 = add.f32 vr4, r45;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 59895;"
        "pseudo@0	@pseudo imm_1 = 14767;"
        "pseudo@0	@pseudo imm_2 = 12421;"
        "pseudo@0	@pseudo imm_3 = 47629;"
        "V0@(pr0)	vr5 = mul.f32 vr2, r44;"
        "V1@(pr0)	vr5 = add.f32 vr5, r45;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_2 = 5785;"
        "pseudo@0	@pseudo imm_3 = 15124;"
        "V0@(pr0)	vr5 = mul.f32 vr2, vr5;"
        "V1@(pr0)	vr5 = add.f32 vr5, r45;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_2 = 64766;"
        "pseudo@0	@pseudo imm_3 = 48168;"
        "V0@(pr0)	vr5 = mul.f32 vr2, vr5;"
        "V1@(pr0)	vr5 = add.f32 vr5, r45;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_2 = 23061;"
        "pseudo@0	@pseudo imm_3 = 15748;"
        "V0@(pr0)	vr5 = mul.f32 vr2, vr5;"
        "V1@(pr0)	vr5 = add.f32 vr5, r45;"
        "}"
        "{"
        "V0@(pr0)	vr5 = mul.f32 vr15, vr5;"
        "V1@(pr0)	vr5 = add.f32 vr5, vr4;"
        "}"
        "{"
        "V0@(pr0)	vr5 = mul.f32 vr2, vr5;"
        "}"
        "{"
        "V0@(pr0)	vr3 = mul.f32 vr1, vr3;"
        "V1@(pr0)	vr5 = add.f32 vr3, vr5;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 7250;"
        "pseudo@0	@pseudo imm_1 = 12774;"
        "V1@(pr0)	vr5 = sub.f32 vr5, r44;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 52685;"
        "pseudo@0	@pseudo imm_1 = 48632;"
        "V1@(pr0)	vr1 = add.f32 vr5, r44;"
        "}"
        "{"
        "V0@(pr0)	vmsk1 = eq.s32 vr16, r48;"
        "V1@(pr0)	vr1 = add.f32 vr17, vr1;"
        "}"
        "{"
        "V0@(pr0)	vr17 = sel vmsk1 vr17, vr1;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 15454;"
        "pseudo@0	@pseudo imm_1 = 15451;"
        "pseudo@0	@pseudo imm_2 = 30072;"
        "pseudo@0	@pseudo imm_3 = 15978;"
        "V0@(pr0)	vr1 = mul.f32 vr15, r44;"
        "V1@(pr0)	vr1 = add.f32 vr1, r45;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_2 = 19378;"
        "pseudo@0	@pseudo imm_3 = 16250;"
        "V0@(pr0)	vr1 = mul.f32 vr15, vr1;"
        "V1@(pr0)	vr1 = add.f32 vr1, r45;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_2 = 15079;"
        "pseudo@0	@pseudo imm_3 = 16314;"
        "V0@(pr0)	vr1 = mul.f32 vr15, vr1;"
        "V1@(pr0)	vr1 = add.f32 vr1, r45;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_2 = 244;"
        "pseudo@0	@pseudo imm_3 = 16162;"
        "V0@(pr0)	vr1 = mul.f32 vr15, vr1;"
        "V1@(pr0)	vr1 = add.f32 vr1, r45;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_2 = 9023;"
        "pseudo@0	@pseudo imm_3 = 48542;"
        "V0@(pr0)	vr1 = mul.f32 vr15, vr1;"
        "V1@(pr0)	vr1 = add.f32 vr1, r45;"
        "}"
        "{"
        "V0@(pr0)	vr1 = mul.f32 vr15, vr1;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 54747;"
        "pseudo@0	@pseudo imm_1 = 15186;"
        "pseudo@0	@pseudo imm_2 = 29359;"
        "pseudo@0	@pseudo imm_3 = 15829;"
        "V0@(pr0)	vr2 = mul.f32 vr15, r44;"
        "V1@(pr0)	vr2 = add.f32 vr2, r45;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_2 = 61407;"
        "pseudo@0	@pseudo imm_3 = 16196;"
        "V0@(pr0)	vr2 = mul.f32 vr15, vr2;"
        "V1@(pr0)	vr2 = add.f32 vr2, r45;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_2 = 14637;"
        "pseudo@0	@pseudo imm_3 = 16392;"
        "V0@(pr0)	vr2 = mul.f32 vr15, vr2;"
        "V1@(pr0)	vr2 = add.f32 vr2, r45;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_2 = 11966;"
        "pseudo@0	@pseudo imm_3 = 16413;"
        "V0@(pr0)	vr2 = mul.f32 vr15, vr2;"
        "V1@(pr0)	vr2 = add.f32 vr2, r45;"
        "}"
        "{"
        "V0@(pr0)	vr2 = mul.f32 vr15, vr2;"
        "V1@(pr0)	vr2 = add.f32 vr2, r49;"
        "}"
        "{"
        "V0@(pr0)	(urf) = rcp.f32 vr2;"
        "MTR@(pr0)	vr31 = pop urf;"
        "}"
        "{"
        "V0@(pr0)	vr2 = mov.u32 vr31;"
        "V1@(pr0)	vmsk1 = eq.s32 vr28, r46;"
        "}"
        "{"
        "V0@(pr0)	vr3 = mul.f32 vr15, r58;"
        "}"
        "{"
        "V0@(pr0)	vr1 = mul.f32 vr1, vr2;"
        "V1@(pr0)	vr1 = add.f32 vr1, vr3;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 2;"
        "V0@(pr0)	vmsk1 = eq.s32 vr16, r32;"
        "V1@(pr0)	vr1 = add.f32 vr1, vr17;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 16384;"
        "V0@(pr0)	vr17 = sel vmsk1 vr17, vr1;"
        "V1@(pr0)	vmsk1 = ls.s32 vr6, r36;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 16256;"
        "V0@(pr0)	vr14 = sel vmsk1 vr14, vr17;"
        "V1@(pr0)	vmsk1 = eq.s32 vr6, r36;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 16384;"
        "V0@(pr0)	vr14 = sel vmsk1 vr14, r46;"
        "V1@(pr0)	vmsk1 = eq.s32 vr6, r36;"
        "}"
        "{"
        "V1@(pr0)	vr14 = sel vmsk1 vr14, r46;"
        "}"
        "{"
        "V0@(pr0)	vr16 = cvtftoint.s32 vr10, r56;"
        "V1@(pr0)	vr1 = mov.u32 r46;"
        "}"
        "{"
        "V0@(pr0)	vr2 = cvtinttof.f32 vr16;"
        "V1@(pr0)	vr15 = sub.f32 vr10, vr2;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 65383;"
        "pseudo@0	@pseudo imm_1 = 14341;"
        "pseudo@0	@pseudo imm_2 = 13748;"
        "pseudo@0	@pseudo imm_3 = 15089;"
        "V0@(pr0)	vr2 = mul.f32 vr15, r44;"
        "V1@(pr0)	vr2 = add.f32 vr2, r45;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_2 = 16612;"
        "pseudo@0	@pseudo imm_3 = 15578;"
        "V0@(pr0)	vr2 = mul.f32 vr15, vr2;"
        "V1@(pr0)	vr2 = add.f32 vr2, r45;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_2 = 56550;"
        "pseudo@0	@pseudo imm_3 = 15893;"
        "V0@(pr0)	vr2 = mul.f32 vr15, vr2;"
        "V1@(pr0)	vr2 = add.f32 vr2, r45;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_2 = 52346;"
        "pseudo@0	@pseudo imm_3 = 16038;"
        "V0@(pr0)	vr2 = mul.f32 vr15, vr2;"
        "V1@(pr0)	vr2 = add.f32 vr2, r45;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_2 = 9306;"
        "pseudo@0	@pseudo imm_3 = 15964;"
        "V0@(pr0)	vr2 = mul.f32 vr15, vr2;"
        "V1@(pr0)	vr2 = add.f32 vr2, r45;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_2 = 9023;"
        "pseudo@0	@pseudo imm_3 = 48542;"
        "V0@(pr0)	vr2 = mul.f32 vr15, vr2;"
        "V1@(pr0)	vr2 = add.f32 vr2, r45;"
        "}"
        "{"
        "V0@(pr0)	vr2 = mul.f32 vr15, vr2;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 55229;"
        "pseudo@0	@pseudo imm_1 = 14069;"
        "pseudo@0	@pseudo imm_2 = 61142;"
        "pseudo@0	@pseudo imm_3 = 14923;"
        "V0@(pr0)	vr3 = mul.f32 vr15, r44;"
        "V1@(pr0)	vr3 = add.f32 vr3, r45;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_2 = 48980;"
        "pseudo@0	@pseudo imm_3 = 15512;"
        "V0@(pr0)	vr3 = mul.f32 vr15, vr3;"
        "V1@(pr0)	vr3 = add.f32 vr3, r45;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_2 = 3950;"
        "pseudo@0	@pseudo imm_3 = 15920;"
        "V0@(pr0)	vr3 = mul.f32 vr15, vr3;"
        "V1@(pr0)	vr3 = add.f32 vr3, r45;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_2 = 53445;"
        "pseudo@0	@pseudo imm_3 = 16184;"
        "V0@(pr0)	vr3 = mul.f32 vr15, vr3;"
        "V1@(pr0)	vr3 = add.f32 vr3, r45;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_2 = 11579;"
        "pseudo@0	@pseudo imm_3 = 16306;"
        "V0@(pr0)	vr3 = mul.f32 vr15, vr3;"
        "V1@(pr0)	vr3 = add.f32 vr3, r45;"
        "}"
        "{"
        "V0@(pr0)	vr3 = mul.f32 vr15, vr3;"
        "V1@(pr0)	vr3 = add.f32 vr3, r49;"
        "}"
        "{"
        "V0@(pr0)	(urf) = rcp.f32 vr3;"
        "MTR@(pr0)	vr31 = pop urf;"
        "}"
        "{"
        "V0@(pr0)	vr3 = mov.u32 vr31;"
        "V1@(pr0)	vmsk1 = eq.s32 vr28, r46;"
        "}"
        "{"
        "V0@(pr0)	vr4 = mul.f32 vr15, r50;"
        "V1@(pr0)	vr5 = mov.u32 r49;"
        "}"
        "{"
        "V0@(pr0)	vr3 = mul.f32 vr2, vr3;"
        "V1@(pr0)	vr17 = add.f32 vr3, vr4;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 3;"
        "pseudo@0	@pseudo imm_2 = 0;"
        "pseudo@0	@pseudo imm_3 = 16384;"
        "V0@(pr0)	vmsk1 = eq.s32 vr16, r32;"
        "V1@(pr0)	vr2 = add.f32 vr15, r45;"
        "}"
        "{"
        "V0@(pr0)	vr3 = mov.u32 r49;"
        "}"
        "{"
        "V0@(pr0)	vr5 = mul.f32 vr5, vr2;"
        "V1@(pr0)	vr4 = sel vmsk1 vr3, vr5;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 4;"
        "pseudo@0	@pseudo imm_2 = 0;"
        "pseudo@0	@pseudo imm_3 = 16448;"
        "V0@(pr0)	vmsk1 = eq.s32 vr16, r32;"
        "V1@(pr0)	vr2 = add.f32 vr15, r45;"
        "}"
        "{"
        "V0@(pr0)	vr5 = mul.f32 vr5, vr2;"
        "V1@(pr0)	vr4 = sel vmsk1 vr4, vr5;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 5;"
        "pseudo@0	@pseudo imm_2 = 0;"
        "pseudo@0	@pseudo imm_3 = 16512;"
        "V0@(pr0)	vmsk1 = eq.s32 vr16, r32;"
        "V1@(pr0)	vr2 = add.f32 vr15, r45;"
        "}"
        "{"
        "V0@(pr0)	vr5 = mul.f32 vr5, vr2;"
        "V1@(pr0)	vr4 = sel vmsk1 vr4, vr5;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 6;"
        "pseudo@0	@pseudo imm_2 = 0;"
        "pseudo@0	@pseudo imm_3 = 16544;"
        "V0@(pr0)	vmsk1 = eq.s32 vr16, r32;"
        "V1@(pr0)	vr2 = add.f32 vr15, r45;"
        "}"
        "{"
        "V0@(pr0)	vr5 = mul.f32 vr5, vr2;"
        "V1@(pr0)	vr4 = sel vmsk1 vr4, vr5;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 7;"
        "pseudo@0	@pseudo imm_2 = 0;"
        "pseudo@0	@pseudo imm_3 = 16576;"
        "V0@(pr0)	vmsk1 = eq.s32 vr16, r32;"
        "V1@(pr0)	vr2 = add.f32 vr15, r45;"
        "}"
        "{"
        "V0@(pr0)	vr5 = mul.f32 vr5, vr2;"
        "V1@(pr0)	vr4 = sel vmsk1 vr4, vr5;"
        "}"
        "{"
        "V0@(pr0)	(urf) = log.f32 vr4;"
        "MTR@(pr0)	vr31 = pop urf;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 29208;"
        "pseudo@0	@pseudo imm_1 = 16177;"
        "V0@(pr0)	vr31 = mul.f32 vr31, r44;"
        "}"
        "{"
        "V0@(pr0)	vr4 = mov.u32 vr31;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 16384;"
        "V0@(pr0)	vmsk1 = lseq.s32 vr6, r36;"
        "V1@(pr0)	vr17 = add.f32 vr17, vr4;"
        "}"
        "{"
        "V0@(pr0)	vr14 = sel vmsk1 vr17, vr14;"
        "}"
        "{"
        "V0@(pr0)	(urf) = log.f32 vr10;"
        "MTR@(pr0)	vr31 = pop urf;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 29208;"
        "pseudo@0	@pseudo imm_1 = 16177;"
        "V0@(pr0)	vr31 = mul.f32 vr31, r44;"
        "}"
        "{"
        "V0@(pr0)	vr1 = mov.u32 vr31;"
        "}"
        "{"
        "V0@(pr0)	(urf) = rcp.f32 vr10;"
        "MTR@(pr0)	vr31 = pop urf;"
        "}"
        "{"
        "V0@(pr0)	vr2 = mov.u32 vr31;"
        "}"
        "{"
        "V0@(pr0)	vr15 = mul.f32 vr2, vr2;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 50408;"
        "pseudo@0	@pseudo imm_1 = 47829;"
        "pseudo@0	@pseudo imm_2 = 15826;"
        "pseudo@0	@pseudo imm_3 = 14939;"
        "V0@(pr0)	vr3 = mul.f32 vr15, r44;"
        "V1@(pr0)	vr3 = add.f32 vr3, r45;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_2 = 1628;"
        "pseudo@0	@pseudo imm_3 = 47644;"
        "V0@(pr0)	vr3 = mul.f32 vr15, vr3;"
        "V1@(pr0)	vr3 = add.f32 vr3, r45;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_2 = 1628;"
        "pseudo@0	@pseudo imm_3 = 47644;"
        "V0@(pr0)	vr3 = mul.f32 vr15, vr3;"
        "V1@(pr0)	vr3 = add.f32 vr3, r45;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_2 = 1628;"
        "pseudo@0	@pseudo imm_3 = 47644;"
        "V0@(pr0)	vr3 = mul.f32 vr15, vr3;"
        "V1@(pr0)	vr3 = add.f32 vr3, r45;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_2 = 3325;"
        "pseudo@0	@pseudo imm_3 = 14928;"
        "V0@(pr0)	vr3 = mul.f32 vr15, vr3;"
        "V1@(pr0)	vr3 = add.f32 vr3, r45;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_2 = 2913;"
        "pseudo@0	@pseudo imm_3 = 47926;"
        "V0@(pr0)	vr3 = mul.f32 vr15, vr3;"
        "V1@(pr0)	vr3 = add.f32 vr3, r45;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_2 = 43691;"
        "pseudo@0	@pseudo imm_3 = 15786;"
        "V0@(pr0)	vr3 = mul.f32 vr15, vr3;"
        "V1@(pr0)	vr3 = add.f32 vr3, r45;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_2 = 32541;"
        "pseudo@0	@pseudo imm_3 = 16086;"
        "V0@(pr0)	vr3 = mul.f32 vr2, vr3;"
        "V1@(pr0)	vr3 = add.f32 vr3, r45;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 16640;"
        "V0@(pr0)	vmsk1 = ls.s32 vr6, r36;"
        "V1@(pr0)	vr4 = sub.f32 vr10, r50;"
        "}"
        "{"
        "V1@(pr0)	vr5 = sub.f32 vr1, r49;"
        "}"
        "{"
        "V0@(pr0)	vr5 = mul.f32 vr4, vr5;"
        "V1@(pr0)	vr17 = add.f32 vr3, vr5;"
        "}"
        "{"
        "V0@(pr0)	vr14 = sel vmsk1 vr17, vr14;"
        "}"
        "{"
        "V0@(pr0)	(urf) = log.f32 vr10;"
        "MTR@(pr0)	vr31 = pop urf;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 29208;"
        "pseudo@0	@pseudo imm_1 = 16177;"
        "V0@(pr0)	vr31 = mul.f32 vr31, r44;"
        "}"
        "{"
        "V0@(pr0)	vr1 = mov.u32 vr31;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 23680;"
        "V0@(pr0)	vmsk1 = ls.s32 vr6, r36;"
        "V1@(pr0)	vr1 = sub.f32 vr1, r49;"
        "}"
        "{"
        "V0@(pr0)	vr17 = mul.f32 vr10, vr1;"
        "V1@(pr0)	vr14 = sel vmsk1 vr17, vr14;"
        "}"
        "{"
        "V0@(pr0)	vmsk1 = ls.s32 vr28, r46;"
        "V1@(pr0)	vr17 = sub.f32 vr13, vr14;"
        "}"
        "{"
        "V0@(pr0)	vr10 = sel vmsk1 vr14, vr17;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_2 = 40;"
        "S1@(pr0)	r6 = add.s32 r6, r34;"
        "V0@(pr0)	vmsk1 = neq.s32 vr12, r46;"
        "V1@(pr0)	%[res0] = sel vmsk1 vr10, vr12;"
        "}"
        : [res0] "=x" (result0)
        : [input0] "x" (a)
        :"vr4", "vr30", "vr10", "vr6", "vr12", "vr7", "vr15", "vr31", "vr1", "vr5", "vr0", "vr28", "vr13", "vr29", "vr2", "vr17", "vr16", "vr11", "vr3", "vr14", "r0", "r9", "r1", "r3", "r6", "vmsk1", "vmsk2", "vmsk3"
        );
    return result0;
}

#endif // _LGAMMAF_H_
