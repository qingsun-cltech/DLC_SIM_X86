#pragma once
#include "../../dlc-intrinsics.h"
#include "../../typehint.h"

#ifndef _BYTE_PERM_H_X86_
#define _BYTE_PERM_H_X86_

inline int8_128 __dlc_byte_perm(int8_128 a, int8_128 b, int8_128 c)
{
    int8_128 result0;
    asm (
        "{V0@(pr0)  vr10 = mov.u32 %[input0];}"
        "{V0@(pr0)  vr11 = mov.u32 %[input1];}"
        "{V0@(pr0)  vr12 = mov.u32 %[input2];}"
        "{"
        "pseudo@0	@pseudo imm_0 = 0;"
        "pseudo@0	@pseudo imm_1 = 65280;"
        "V0@(pr0)	vr4 = and.u32 vr10, r44;"
        "V1@(pr0)	vr5 = and.u32 vr11, r44;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 0;"
        "pseudo@0	@pseudo imm_1 = 255;"
        "V0@(pr0)	vr6 = and.u32 vr10, r44;"
        "V1@(pr0)	vr13 = and.u32 vr11, r44;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 65280;"
        "pseudo@0	@pseudo imm_1 = 0;"
        "V0@(pr0)	vr14 = and.u32 vr10, r44;"
        "V1@(pr0)	vr15 = and.u32 vr11, r44;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 255;"
        "pseudo@0	@pseudo imm_1 = 0;"
        "V0@(pr0)	vr16 = and.u32 vr10, r44;"
        "V1@(pr0)	vr7 = and.u32 vr11, r44;"
        "}"
        "{"
        "V0@(pr0)	vr2 = mov.u32 r46;"
        "}"
        "{"
        "V0@(pr0)	vr0 = mov.u32 r46;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 28672;"
        "pseudo@0	@pseudo imm_1 = 0;"
        "V0@(pr0)	vr31 = and.u32 vr12, r44;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 12;"
        "pseudo@0	@pseudo imm_1 = 0;"
        "V1@(pr0)	vr31 = shr.u32 vr31, r44;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 4;"
        "pseudo@0	@pseudo imm_1 = 0;"
        "V0@(pr0)	vmsk0 = gteq.s32 vr31, r44;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 4;"
        "pseudo@0	@pseudo imm_1 = 0;"
        "V0@(pr0)	vr3 = sub.s32 vr31, r44;"
        "V1@(pr0)	vr31 = sel vmsk0 vr31, vr3;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 3;"
        "pseudo@0	@pseudo imm_1 = 0;"
        "V0@(pr0)	vmsk1 = eq.s32 vr31, r44;"
        "}"
        "{"
        "V0@(pr0)	vr28 = sel vmsk1 vr2, vr4;"
        "V1@(pr0)	vr29 = sel vmsk1 vr2, vr5;"
        "}"
        "{"
        "V0@(pr0)	vr30 = sel vmsk0 vr28, vr29;"
        "}"
        "{"
        "V0@(pr0)	vr1 = mov.u32 r46;"
        "}"
        "{"
        "V0@(pr0)	vr28 = mov.u32 r46;"
        "V1@(pr0)	vr29 = mov.u32 r46;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 2;"
        "pseudo@0	@pseudo imm_1 = 0;"
        "V0@(pr0)	vmsk1 = eq.s32 vr31, r44;"
        "}"
        "{"
        "V0@(pr0)	vr28 = sel vmsk1 vr2, vr6;"
        "V1@(pr0)	vr29 = sel vmsk1 vr2, vr13;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 8;"
        "pseudo@0	@pseudo imm_1 = 0;"
        "V1@(pr0)	vr28 = shl.u32 vr28, r44;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 8;"
        "pseudo@0	@pseudo imm_1 = 0;"
        "V1@(pr0)	vr29 = shl.u32 vr29, r44;"
        "}"
        "{"
        "V0@(pr0)	vr1 = mov.u32 r46;"
        "}"
        "{"
        "V0@(pr0)	vr1 = sel vmsk0 vr28, vr29;"
        "}"
        "{"
        "V0@(pr0)	vr30 = or.u32 vr1, vr30;"
        "}"
        "{"
        "V0@(pr0)	vr1 = mov.u32 r46;"
        "}"
        "{"
        "V0@(pr0)	vr28 = mov.u32 r46;"
        "V1@(pr0)	vr29 = mov.u32 r46;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 1;"
        "pseudo@0	@pseudo imm_1 = 0;"
        "V0@(pr0)	vmsk1 = eq.s32 vr31, r44;"
        "}"
        "{"
        "V0@(pr0)	vr28 = sel vmsk1 vr2, vr14;"
        "V1@(pr0)	vr29 = sel vmsk1 vr2, vr15;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 16;"
        "pseudo@0	@pseudo imm_1 = 0;"
        "V1@(pr0)	vr28 = shl.u32 vr28, r44;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 16;"
        "pseudo@0	@pseudo imm_1 = 0;"
        "V1@(pr0)	vr29 = shl.u32 vr29, r44;"
        "}"
        "{"
        "V0@(pr0)	vr1 = mov.u32 r46;"
        "}"
        "{"
        "V0@(pr0)	vr1 = sel vmsk0 vr28, vr29;"
        "}"
        "{"
        "V0@(pr0)	vr30 = or.u32 vr1, vr30;"
        "}"
        "{"
        "V0@(pr0)	vr1 = mov.u32 r46;"
        "}"
        "{"
        "V0@(pr0)	vr28 = mov.u32 r46;"
        "V1@(pr0)	vr29 = mov.u32 r46;"
        "}"
        "{"
        "V0@(pr0)	vmsk1 = eq.s32 vr31, r46;"
        "}"
        "{"
        "V0@(pr0)	vr28 = sel vmsk1 vr2, vr16;"
        "V1@(pr0)	vr29 = sel vmsk1 vr2, vr7;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 24;"
        "pseudo@0	@pseudo imm_1 = 0;"
        "V1@(pr0)	vr28 = shl.u32 vr28, r44;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 24;"
        "pseudo@0	@pseudo imm_1 = 0;"
        "V1@(pr0)	vr29 = shl.u32 vr29, r44;"
        "}"
        "{"
        "V0@(pr0)	vr1 = mov.u32 r46;"
        "}"
        "{"
        "V0@(pr0)	vr1 = sel vmsk0 vr28, vr29;"
        "}"
        "{"
        "V0@(pr0)	vr30 = or.u32 vr1, vr30;"
        "}"
        "{"
        "V0@(pr0)	vr0 = mov.u32 r46;"
        "V1@(pr0)	vr1 = mov.u32 r46;"
        "}"
        "{"
        "V0@(pr0)	vr3 = mov.u32 r46;"
        "V1@(pr0)	vr31 = mov.u32 r46;"
        "}"
        "{"
        "V0@(pr0)	vr28 = mov.u32 r46;"
        "V1@(pr0)	vr29 = mov.u32 r46;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 1792;"
        "pseudo@0	@pseudo imm_1 = 0;"
        "V0@(pr0)	vr31 = and.u32 vr12, r44;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 8;"
        "pseudo@0	@pseudo imm_1 = 0;"
        "V1@(pr0)	vr31 = shr.u32 vr31, r44;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 4;"
        "pseudo@0	@pseudo imm_1 = 0;"
        "V0@(pr0)	vmsk0 = gteq.s32 vr31, r44;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 4;"
        "pseudo@0	@pseudo imm_1 = 0;"
        "V0@(pr0)	vr3 = sub.s32 vr31, r44;"
        "V1@(pr0)	vr31 = sel vmsk0 vr31, vr3;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 3;"
        "pseudo@0	@pseudo imm_1 = 0;"
        "V0@(pr0)	vmsk1 = eq.s32 vr31, r44;"
        "}"
        "{"
        "V0@(pr0)	vr28 = sel vmsk1 vr2, vr4;"
        "V1@(pr0)	vr29 = sel vmsk1 vr2, vr5;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 8;"
        "pseudo@0	@pseudo imm_1 = 0;"
        "V1@(pr0)	vr28 = shr.u32 vr28, r44;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 8;"
        "pseudo@0	@pseudo imm_1 = 0;"
        "V1@(pr0)	vr29 = shr.u32 vr29, r44;"
        "}"
        "{"
        "V0@(pr0)	vr1 = mov.u32 r46;"
        "}"
        "{"
        "V0@(pr0)	vr1 = sel vmsk0 vr28, vr29;"
        "}"
        "{"
        "V0@(pr0)	vr30 = or.u32 vr1, vr30;"
        "}"
        "{"
        "V0@(pr0)	vr1 = mov.u32 r46;"
        "}"
        "{"
        "V0@(pr0)	vr28 = mov.u32 r46;"
        "V1@(pr0)	vr29 = mov.u32 r46;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 2;"
        "pseudo@0	@pseudo imm_1 = 0;"
        "V0@(pr0)	vmsk1 = eq.s32 vr31, r44;"
        "}"
        "{"
        "V0@(pr0)	vr28 = sel vmsk1 vr2, vr6;"
        "V1@(pr0)	vr29 = sel vmsk1 vr2, vr13;"
        "}"
        "{"
        "V0@(pr0)	vr1 = mov.u32 r46;"
        "}"
        "{"
        "V0@(pr0)	vr1 = sel vmsk0 vr28, vr29;"
        "}"
        "{"
        "V0@(pr0)	vr30 = or.u32 vr1, vr30;"
        "}"
        "{"
        "V0@(pr0)	vr1 = mov.u32 r46;"
        "}"
        "{"
        "V0@(pr0)	vr28 = mov.u32 r46;"
        "V1@(pr0)	vr29 = mov.u32 r46;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 1;"
        "pseudo@0	@pseudo imm_1 = 0;"
        "V0@(pr0)	vmsk1 = eq.s32 vr31, r44;"
        "}"
        "{"
        "V0@(pr0)	vr28 = sel vmsk1 vr2, vr14;"
        "V1@(pr0)	vr29 = sel vmsk1 vr2, vr15;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 8;"
        "pseudo@0	@pseudo imm_1 = 0;"
        "V1@(pr0)	vr28 = shl.u32 vr28, r44;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 8;"
        "pseudo@0	@pseudo imm_1 = 0;"
        "V1@(pr0)	vr29 = shl.u32 vr29, r44;"
        "}"
        "{"
        "V0@(pr0)	vr1 = mov.u32 r46;"
        "}"
        "{"
        "V0@(pr0)	vr1 = sel vmsk0 vr28, vr29;"
        "}"
        "{"
        "V0@(pr0)	vr30 = or.u32 vr1, vr30;"
        "}"
        "{"
        "V0@(pr0)	vr1 = mov.u32 r46;"
        "}"
        "{"
        "V0@(pr0)	vr28 = mov.u32 r46;"
        "V1@(pr0)	vr29 = mov.u32 r46;"
        "}"
        "{"
        "V0@(pr0)	vmsk1 = eq.s32 vr31, r46;"
        "}"
        "{"
        "V0@(pr0)	vr28 = sel vmsk1 vr2, vr16;"
        "V1@(pr0)	vr29 = sel vmsk1 vr2, vr7;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 16;"
        "pseudo@0	@pseudo imm_1 = 0;"
        "V1@(pr0)	vr28 = shl.u32 vr28, r44;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 16;"
        "pseudo@0	@pseudo imm_1 = 0;"
        "V1@(pr0)	vr29 = shl.u32 vr29, r44;"
        "}"
        "{"
        "V0@(pr0)	vr1 = mov.u32 r46;"
        "}"
        "{"
        "V0@(pr0)	vr1 = sel vmsk0 vr28, vr29;"
        "}"
        "{"
        "V0@(pr0)	vr30 = or.u32 vr1, vr30;"
        "}"
        "{"
        "V0@(pr0)	vr0 = mov.u32 r46;"
        "V1@(pr0)	vr1 = mov.u32 r46;"
        "}"
        "{"
        "V0@(pr0)	vr3 = mov.u32 r46;"
        "V1@(pr0)	vr31 = mov.u32 r46;"
        "}"
        "{"
        "V0@(pr0)	vr28 = mov.u32 r46;"
        "V1@(pr0)	vr29 = mov.u32 r46;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 1792;"
        "pseudo@0	@pseudo imm_1 = 0;"
        "V0@(pr0)	vr31 = and.u32 vr12, r44;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 8;"
        "pseudo@0	@pseudo imm_1 = 0;"
        "V1@(pr0)	vr31 = shr.u32 vr31, r44;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 4;"
        "pseudo@0	@pseudo imm_1 = 0;"
        "V0@(pr0)	vmsk0 = gteq.s32 vr31, r44;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 4;"
        "pseudo@0	@pseudo imm_1 = 0;"
        "V0@(pr0)	vr3 = sub.s32 vr31, r44;"
        "V1@(pr0)	vr31 = sel vmsk0 vr31, vr3;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 3;"
        "pseudo@0	@pseudo imm_1 = 0;"
        "V0@(pr0)	vmsk1 = eq.s32 vr31, r44;"
        "}"
        "{"
        "V0@(pr0)	vr28 = sel vmsk1 vr2, vr4;"
        "V1@(pr0)	vr29 = sel vmsk1 vr2, vr5;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 8;"
        "pseudo@0	@pseudo imm_1 = 0;"
        "V1@(pr0)	vr28 = shr.u32 vr28, r44;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 8;"
        "pseudo@0	@pseudo imm_1 = 0;"
        "V1@(pr0)	vr29 = shr.u32 vr29, r44;"
        "}"
        "{"
        "V0@(pr0)	vr1 = mov.u32 r46;"
        "}"
        "{"
        "V0@(pr0)	vr1 = sel vmsk0 vr28, vr29;"
        "}"
        "{"
        "V0@(pr0)	vr30 = or.u32 vr1, vr30;"
        "}"
        "{"
        "V0@(pr0)	vr1 = mov.u32 r46;"
        "}"
        "{"
        "V0@(pr0)	vr28 = mov.u32 r46;"
        "V1@(pr0)	vr29 = mov.u32 r46;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 2;"
        "pseudo@0	@pseudo imm_1 = 0;"
        "V0@(pr0)	vmsk1 = eq.s32 vr31, r44;"
        "}"
        "{"
        "V0@(pr0)	vr28 = sel vmsk1 vr2, vr6;"
        "V1@(pr0)	vr29 = sel vmsk1 vr2, vr13;"
        "}"
        "{"
        "V0@(pr0)	vr1 = mov.u32 r46;"
        "}"
        "{"
        "V0@(pr0)	vr1 = sel vmsk0 vr28, vr29;"
        "}"
        "{"
        "V0@(pr0)	vr30 = or.u32 vr1, vr30;"
        "}"
        "{"
        "V0@(pr0)	vr1 = mov.u32 r46;"
        "}"
        "{"
        "V0@(pr0)	vr28 = mov.u32 r46;"
        "V1@(pr0)	vr29 = mov.u32 r46;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 1;"
        "pseudo@0	@pseudo imm_1 = 0;"
        "V0@(pr0)	vmsk1 = eq.s32 vr31, r44;"
        "}"
        "{"
        "V0@(pr0)	vr28 = sel vmsk1 vr2, vr14;"
        "V1@(pr0)	vr29 = sel vmsk1 vr2, vr15;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 8;"
        "pseudo@0	@pseudo imm_1 = 0;"
        "V1@(pr0)	vr28 = shl.u32 vr28, r44;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 8;"
        "pseudo@0	@pseudo imm_1 = 0;"
        "V1@(pr0)	vr29 = shl.u32 vr29, r44;"
        "}"
        "{"
        "V0@(pr0)	vr1 = mov.u32 r46;"
        "}"
        "{"
        "V0@(pr0)	vr1 = sel vmsk0 vr28, vr29;"
        "}"
        "{"
        "V0@(pr0)	vr30 = or.u32 vr1, vr30;"
        "}"
        "{"
        "V0@(pr0)	vr1 = mov.u32 r46;"
        "}"
        "{"
        "V0@(pr0)	vr28 = mov.u32 r46;"
        "V1@(pr0)	vr29 = mov.u32 r46;"
        "}"
        "{"
        "V0@(pr0)	vmsk1 = eq.s32 vr31, r46;"
        "}"
        "{"
        "V0@(pr0)	vr28 = sel vmsk1 vr2, vr16;"
        "V1@(pr0)	vr29 = sel vmsk1 vr2, vr7;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 16;"
        "pseudo@0	@pseudo imm_1 = 0;"
        "V1@(pr0)	vr28 = shl.u32 vr28, r44;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 16;"
        "pseudo@0	@pseudo imm_1 = 0;"
        "V1@(pr0)	vr29 = shl.u32 vr29, r44;"
        "}"
        "{"
        "V0@(pr0)	vr1 = mov.u32 r46;"
        "}"
        "{"
        "V0@(pr0)	vr1 = sel vmsk0 vr28, vr29;"
        "}"
        "{"
        "V0@(pr0)	vr30 = or.u32 vr1, vr30;"
        "}"
        "{"
        "V0@(pr0)	vr0 = mov.u32 r46;"
        "V1@(pr0)	vr1 = mov.u32 r46;"
        "}"
        "{"
        "V0@(pr0)	vr3 = mov.u32 r46;"
        "V1@(pr0)	vr31 = mov.u32 r46;"
        "}"
        "{"
        "V0@(pr0)	vr28 = mov.u32 r46;"
        "V1@(pr0)	vr29 = mov.u32 r46;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 112;"
        "pseudo@0	@pseudo imm_1 = 0;"
        "V0@(pr0)	vr31 = and.u32 vr12, r44;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 4;"
        "pseudo@0	@pseudo imm_1 = 0;"
        "V1@(pr0)	vr31 = shr.u32 vr31, r44;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 4;"
        "pseudo@0	@pseudo imm_1 = 0;"
        "V0@(pr0)	vmsk0 = gteq.s32 vr31, r44;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 4;"
        "pseudo@0	@pseudo imm_1 = 0;"
        "V0@(pr0)	vr3 = sub.s32 vr31, r44;"
        "V1@(pr0)	vr31 = sel vmsk0 vr31, vr3;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 3;"
        "pseudo@0	@pseudo imm_1 = 0;"
        "V0@(pr0)	vmsk1 = eq.s32 vr31, r44;"
        "}"
        "{"
        "V0@(pr0)	vr28 = sel vmsk1 vr2, vr4;"
        "V1@(pr0)	vr29 = sel vmsk1 vr2, vr5;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 16;"
        "pseudo@0	@pseudo imm_1 = 0;"
        "V1@(pr0)	vr28 = shr.u32 vr28, r44;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 16;"
        "pseudo@0	@pseudo imm_1 = 0;"
        "V1@(pr0)	vr29 = shr.u32 vr29, r44;"
        "}"
        "{"
        "V0@(pr0)	vr1 = mov.u32 r46;"
        "}"
        "{"
        "V0@(pr0)	vr1 = sel vmsk0 vr28, vr29;"
        "}"
        "{"
        "V0@(pr0)	vr30 = or.u32 vr1, vr30;"
        "}"
        "{"
        "V0@(pr0)	vr1 = mov.u32 r46;"
        "}"
        "{"
        "V0@(pr0)	vr28 = mov.u32 r46;"
        "V1@(pr0)	vr29 = mov.u32 r46;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 2;"
        "pseudo@0	@pseudo imm_1 = 0;"
        "V0@(pr0)	vmsk1 = eq.s32 vr31, r44;"
        "}"
        "{"
        "V0@(pr0)	vr28 = sel vmsk1 vr2, vr6;"
        "V1@(pr0)	vr29 = sel vmsk1 vr2, vr13;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 8;"
        "pseudo@0	@pseudo imm_1 = 0;"
        "V1@(pr0)	vr28 = shr.u32 vr28, r44;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 8;"
        "pseudo@0	@pseudo imm_1 = 0;"
        "V1@(pr0)	vr29 = shr.u32 vr29, r44;"
        "}"
        "{"
        "V0@(pr0)	vr1 = mov.u32 r46;"
        "}"
        "{"
        "V0@(pr0)	vr1 = sel vmsk0 vr28, vr29;"
        "}"
        "{"
        "V0@(pr0)	vr30 = or.u32 vr1, vr30;"
        "}"
        "{"
        "V0@(pr0)	vr1 = mov.u32 r46;"
        "}"
        "{"
        "V0@(pr0)	vr28 = mov.u32 r46;"
        "V1@(pr0)	vr29 = mov.u32 r46;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 1;"
        "pseudo@0	@pseudo imm_1 = 0;"
        "V0@(pr0)	vmsk1 = eq.s32 vr31, r44;"
        "}"
        "{"
        "V0@(pr0)	vr28 = sel vmsk1 vr2, vr14;"
        "V1@(pr0)	vr29 = sel vmsk1 vr2, vr15;"
        "}"
        "{"
        "V0@(pr0)	vr1 = mov.u32 r46;"
        "}"
        "{"
        "V0@(pr0)	vr1 = sel vmsk0 vr28, vr29;"
        "}"
        "{"
        "V0@(pr0)	vr30 = or.u32 vr1, vr30;"
        "}"
        "{"
        "V0@(pr0)	vr1 = mov.u32 r46;"
        "}"
        "{"
        "V0@(pr0)	vr28 = mov.u32 r46;"
        "V1@(pr0)	vr29 = mov.u32 r46;"
        "}"
        "{"
        "V0@(pr0)	vmsk1 = eq.s32 vr31, r46;"
        "}"
        "{"
        "V0@(pr0)	vr28 = sel vmsk1 vr2, vr16;"
        "V1@(pr0)	vr29 = sel vmsk1 vr2, vr7;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 8;"
        "pseudo@0	@pseudo imm_1 = 0;"
        "V1@(pr0)	vr28 = shl.u32 vr28, r44;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 8;"
        "pseudo@0	@pseudo imm_1 = 0;"
        "V1@(pr0)	vr29 = shl.u32 vr29, r44;"
        "}"
        "{"
        "V0@(pr0)	vr1 = mov.u32 r46;"
        "}"
        "{"
        "V0@(pr0)	vr1 = sel vmsk0 vr28, vr29;"
        "}"
        "{"
        "V0@(pr0)	vr30 = or.u32 vr1, vr30;"
        "}"
        "{"
        "V0@(pr0)	vr0 = mov.u32 r46;"
        "V1@(pr0)	vr1 = mov.u32 r46;"
        "}"
        "{"
        "V0@(pr0)	vr3 = mov.u32 r46;"
        "V1@(pr0)	vr31 = mov.u32 r46;"
        "}"
        "{"
        "V0@(pr0)	vr28 = mov.u32 r46;"
        "V1@(pr0)	vr29 = mov.u32 r46;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 7;"
        "pseudo@0	@pseudo imm_1 = 0;"
        "V0@(pr0)	vr31 = and.u32 vr12, r44;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 4;"
        "pseudo@0	@pseudo imm_1 = 0;"
        "V0@(pr0)	vmsk0 = gteq.s32 vr31, r44;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 4;"
        "pseudo@0	@pseudo imm_1 = 0;"
        "V0@(pr0)	vr3 = sub.s32 vr31, r44;"
        "V1@(pr0)	vr31 = sel vmsk0 vr31, vr3;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 3;"
        "pseudo@0	@pseudo imm_1 = 0;"
        "V0@(pr0)	vmsk1 = eq.s32 vr31, r44;"
        "}"
        "{"
        "V0@(pr0)	vr28 = sel vmsk1 vr2, vr4;"
        "V1@(pr0)	vr29 = sel vmsk1 vr2, vr5;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 24;"
        "pseudo@0	@pseudo imm_1 = 0;"
        "V1@(pr0)	vr28 = shr.u32 vr28, r44;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 24;"
        "pseudo@0	@pseudo imm_1 = 0;"
        "V1@(pr0)	vr29 = shr.u32 vr29, r44;"
        "}"
        "{"
        "V0@(pr0)	vr1 = mov.u32 r46;"
        "}"
        "{"
        "V0@(pr0)	vr1 = sel vmsk0 vr28, vr29;"
        "}"
        "{"
        "V0@(pr0)	vr30 = or.u32 vr1, vr30;"
        "}"
        "{"
        "V0@(pr0)	vr1 = mov.u32 r46;"
        "}"
        "{"
        "V0@(pr0)	vr28 = mov.u32 r46;"
        "V1@(pr0)	vr29 = mov.u32 r46;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 2;"
        "pseudo@0	@pseudo imm_1 = 0;"
        "V0@(pr0)	vmsk1 = eq.s32 vr31, r44;"
        "}"
        "{"
        "V0@(pr0)	vr28 = sel vmsk1 vr2, vr6;"
        "V1@(pr0)	vr29 = sel vmsk1 vr2, vr13;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 16;"
        "pseudo@0	@pseudo imm_1 = 0;"
        "V1@(pr0)	vr28 = shr.u32 vr28, r44;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 16;"
        "pseudo@0	@pseudo imm_1 = 0;"
        "V1@(pr0)	vr29 = shr.u32 vr29, r44;"
        "}"
        "{"
        "V0@(pr0)	vr1 = mov.u32 r46;"
        "}"
        "{"
        "V0@(pr0)	vr1 = sel vmsk0 vr28, vr29;"
        "}"
        "{"
        "V0@(pr0)	vr30 = or.u32 vr1, vr30;"
        "}"
        "{"
        "V0@(pr0)	vr1 = mov.u32 r46;"
        "}"
        "{"
        "V0@(pr0)	vr28 = mov.u32 r46;"
        "V1@(pr0)	vr29 = mov.u32 r46;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 1;"
        "pseudo@0	@pseudo imm_1 = 0;"
        "V0@(pr0)	vmsk1 = eq.s32 vr31, r44;"
        "}"
        "{"
        "V0@(pr0)	vr28 = sel vmsk1 vr2, vr14;"
        "V1@(pr0)	vr29 = sel vmsk1 vr2, vr15;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 8;"
        "pseudo@0	@pseudo imm_1 = 0;"
        "V1@(pr0)	vr28 = shr.u32 vr28, r44;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 8;"
        "pseudo@0	@pseudo imm_1 = 0;"
        "V1@(pr0)	vr29 = shr.u32 vr29, r44;"
        "}"
        "{"
        "V0@(pr0)	vr1 = mov.u32 r46;"
        "}"
        "{"
        "V0@(pr0)	vr1 = sel vmsk0 vr28, vr29;"
        "}"
        "{"
        "V0@(pr0)	vr30 = or.u32 vr1, vr30;"
        "}"
        "{"
        "V0@(pr0)	vr1 = mov.u32 r46;"
        "}"
        "{"
        "V0@(pr0)	vr28 = mov.u32 r46;"
        "V1@(pr0)	vr29 = mov.u32 r46;"
        "}"
        "{"
        "V0@(pr0)	vmsk1 = eq.s32 vr31, r46;"
        "}"
        "{"
        "V0@(pr0)	vr28 = sel vmsk1 vr2, vr16;"
        "V1@(pr0)	vr29 = sel vmsk1 vr2, vr7;"
        "}"
        "{"
        "V0@(pr0)	vr1 = mov.u32 r46;"
        "V1@(pr0)	vr1 = sel vmsk0 vr28, vr29;"
        "}"
        "{"
        "V0@(pr0)	%[res0] = or.u32 vr1, vr30;"
        "}"
        : [res0] "=x" (result0)
        : [input0] "x" (a),  [input1] "x" (b),  [input2] "x" (c)
        :"vr4", "vr30", "vr10", "vr6", "vr12", "vr7", "vr15", "vr31", "vr5", "vr1", "vr0", "vr28", "vr13", "vr29", "vr2", "vr16", "vr11", "vr14", "vr3", "vmsk0", "vmsk1"
        );
    return result0;
}

#endif // _BYTE_PERM_H_
