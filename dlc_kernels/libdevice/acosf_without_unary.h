#pragma once
#include "../../dlc-intrinsics.h"
#include "../../typehint.h"

#ifndef _ACOSF_WITHOUT_UNARY_H_X86_
#define _ACOSF_WITHOUT_UNARY_H_X86_

inline float8_128 __dlc_acosf_without_unary(float8_128 a)
{
    float8_128 result0;
    asm (
        "{V0@(pr0)  vr10 = mov.u32 %[input0];}"
        "{"
        "pseudo@0	@pseudo imm_0 = 65535;"
        "pseudo@0	@pseudo imm_1 = 32767;"
        "V0@(pr0)	vr13 = mov.u32 r49;"
        "V1@(pr0)	vr17 = and.u32 vr10, r44;"
        "}"
        "{"
        "V0@(pr0)	vr11 = or.u32 vr10, r47;"
        "}"
        "{"
        "V0@(pr0)	vr12 = mul.f32 vr10, vr10;"
        "V1@(pr0)	vr11 = add.f32 vr13, vr11;"
        "}"
        "{"
        "V0@(pr0)	vr11 = mul.f32 vr11, r50;"
        "V1@(pr0)	vmsk2 = ls.f32 vr17, r50;"
        "}"
        "{"
        "V0@(pr0)	vmsk0 = eq.f32 vr17, r49;"
        "V1@(pr0)	vmsk1 = gt.f32 vr17, r49;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_1 = 8960;"
        "V0@(pr0)	vr12 = sel vmsk2 vr11, vr12;"
        "V1@(pr0)	vmsk4 = lseq.s32 vr17, r37;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 61192;"
        "pseudo@0	@pseudo imm_1 = 14353;"
        "pseudo@0	@pseudo imm_2 = 32516;"
        "pseudo@0	@pseudo imm_3 = 14927;"
        "V0@(pr0)	vr13 = mul.f32 vr12, r44;"
        "V1@(pr0)	vr14 = add.f32 vr13, r45;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_2 = 4422;"
        "pseudo@0	@pseudo imm_3 = 48420;"
        "V0@(pr0)	vr13 = mul.f32 vr12, vr14;"
        "V1@(pr0)	vr14 = add.f32 vr13, r45;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_2 = 2728;"
        "pseudo@0	@pseudo imm_3 = 15950;"
        "V0@(pr0)	vr13 = mul.f32 vr12, vr14;"
        "V1@(pr0)	vr14 = add.f32 vr13, r45;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_2 = 45200;"
        "pseudo@0	@pseudo imm_3 = 48806;"
        "V0@(pr0)	vr13 = mul.f32 vr12, vr14;"
        "V1@(pr0)	vr14 = add.f32 vr13, r45;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_2 = 43691;"
        "pseudo@0	@pseudo imm_3 = 15914;"
        "V0@(pr0)	vr13 = mul.f32 vr12, vr14;"
        "V1@(pr0)	vr14 = add.f32 vr13, r45;"
        "}"
        "{"
        "V0@(pr0)	vr11 = mul.f32 vr12, vr14;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 50734;"
        "pseudo@0	@pseudo imm_1 = 15773;"
        "pseudo@0	@pseudo imm_2 = 13153;"
        "pseudo@0	@pseudo imm_3 = 48944;"
        "V0@(pr0)	vr15 = mul.f32 vr12, r44;"
        "V1@(pr0)	vr14 = add.f32 vr15, r45;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_2 = 22317;"
        "pseudo@0	@pseudo imm_3 = 16385;"
        "V0@(pr0)	vr15 = mul.f32 vr12, vr14;"
        "V1@(pr0)	vr14 = add.f32 vr15, r45;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_2 = 53561;"
        "pseudo@0	@pseudo imm_3 = 49177;"
        "V0@(pr0)	vr15 = mul.f32 vr12, vr14;"
        "V1@(pr0)	vr14 = add.f32 vr15, r45;"
        "}"
        "{"
        "V0@(pr0)	vr15 = mul.f32 vr12, vr14;"
        "V1@(pr0)	vr15 = add.f32 vr15, r49;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 65535;"
        "pseudo@0	@pseudo imm_1 = 32767;"
        "pseudo@0	@pseudo imm_2 = 32640;"
        "V0@(pr0)	vr0 = and.u32 vr15, r44;"
        "V1@(pr0)	vmsk6 = eq.s32 vr0, r38;"
        "}"
        "{"
        "V0@(pr0)	vr1 = mul.f32 vr0, r50;"
        "V1@(pr0)	vr2 = mov.u32 vr0;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 23007;"
        "pseudo@0	@pseudo imm_1 = 24375;"
        "V0@(pr0)	vr3 = mov.u32 r44;"
        "V1@(pr0)	vr2 = shr.u32 vr2, r48;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 16320;"
        "V0@(pr0)	vr2 = sub.s32 vr3, vr2;"
        "V1@(pr0)	vr4 = mov.u32 r36;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 32768;"
        "V0@(pr0)	vr3 = mul.f32 vr2, vr2;"
        "V1@(pr0)	vr6 = and.u32 vr15, r36;"
        "}"
        "{"
        "V0@(pr0)	vr5 = mul.f32 vr1, vr3;"
        "V1@(pr0)	vr5 = sub.f32 vr4, vr5;"
        "}"
        "{"
        "V0@(pr0)	vr5 = mul.f32 vr5, vr2;"
        "V1@(pr0)	vr2 = mov.u32 vr5;"
        "}"
        "{"
        "V0@(pr0)	vr3 = mul.f32 vr2, vr2;"
        "V1@(pr0)	vmsk5 = eq.f32 vr15, r46;"
        "}"
        "{"
        "V0@(pr0)	vr5 = mul.f32 vr1, vr3;"
        "V1@(pr0)	vr5 = sub.f32 vr4, vr5;"
        "}"
        "{"
        "V0@(pr0)	vr5 = mul.f32 vr5, vr2;"
        "V1@(pr0)	vr2 = mov.u32 vr5;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 32640;"
        "V0@(pr0)	vr3 = mul.f32 vr2, vr2;"
        "V1@(pr0)	vr7 = or.u32 vr6, r36;"
        "}"
        "{"
        "V0@(pr0)	vr5 = mul.f32 vr1, vr3;"
        "V1@(pr0)	vr5 = sub.f32 vr4, vr5;"
        "}"
        "{"
        "V0@(pr0)	vr5 = mul.f32 vr5, vr2;"
        "V1@(pr0)	vr2 = or.u32 vr6, r46;"
        "}"
        "{"
        "V0@(pr0)	vr1 = mul.f32 vr5, vr5;"
        "V1@(pr0)	vr1 = or.u32 vr6, vr1;"
        "}"
        "{"
        "V0@(pr0)	vr15 = sel vmsk5 vr1, vr7;"
        "V1@(pr0)	vr15 = sel vmsk6 vr15, vr2;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 8552;"
        "pseudo@0	@pseudo imm_1 = 13218;"
        "V0@(pr0)	vr11 = mul.f32 vr15, vr11;"
        "V1@(pr0)	vr16 = mov.u32 r44;"
        "}"
        "{"
        "V0@(pr0)	vr13 = mul.f32 vr10, vr11;"
        "V1@(pr0)	vmsk3 = ls.f32 vr10, r46;"
        "}"
        "{"
        "V1@(pr0)	vr16 = sub.f32 vr16, vr13;"
        "}"
        "{"
        "V1@(pr0)	vr16 = sub.f32 vr10, vr16;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 4058;"
        "pseudo@0	@pseudo imm_1 = 16329;"
        "V0@(pr0)	vr13 = mov.u32 r44;"
        "V1@(pr0)	vr16 = sub.f32 vr13, vr16;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 65535;"
        "pseudo@0	@pseudo imm_1 = 32767;"
        "pseudo@0	@pseudo imm_2 = 32640;"
        "V0@(pr0)	vr0 = and.u32 vr12, r44;"
        "V1@(pr0)	vmsk6 = eq.s32 vr0, r38;"
        "}"
        "{"
        "V0@(pr0)	vr1 = mul.f32 vr0, r50;"
        "V1@(pr0)	vr2 = mov.u32 vr0;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 23007;"
        "pseudo@0	@pseudo imm_1 = 24375;"
        "V0@(pr0)	vr3 = mov.u32 r44;"
        "V1@(pr0)	vr2 = shr.u32 vr2, r48;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 16320;"
        "V0@(pr0)	vr2 = sub.s32 vr3, vr2;"
        "V1@(pr0)	vr4 = mov.u32 r36;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 32768;"
        "V0@(pr0)	vr3 = mul.f32 vr2, vr2;"
        "V1@(pr0)	vr6 = and.u32 vr12, r36;"
        "}"
        "{"
        "V0@(pr0)	vr5 = mul.f32 vr1, vr3;"
        "V1@(pr0)	vr5 = sub.f32 vr4, vr5;"
        "}"
        "{"
        "V0@(pr0)	vr5 = mul.f32 vr5, vr2;"
        "V1@(pr0)	vr2 = mov.u32 vr5;"
        "}"
        "{"
        "V0@(pr0)	vr3 = mul.f32 vr2, vr2;"
        "V1@(pr0)	vmsk5 = eq.f32 vr12, r46;"
        "}"
        "{"
        "V0@(pr0)	vr5 = mul.f32 vr1, vr3;"
        "V1@(pr0)	vr5 = sub.f32 vr4, vr5;"
        "}"
        "{"
        "V0@(pr0)	vr5 = mul.f32 vr5, vr2;"
        "V1@(pr0)	vr2 = mov.u32 vr5;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 32640;"
        "V0@(pr0)	vr3 = mul.f32 vr2, vr2;"
        "V1@(pr0)	vr7 = or.u32 vr6, r36;"
        "}"
        "{"
        "V0@(pr0)	vr5 = mul.f32 vr1, vr3;"
        "V1@(pr0)	vr5 = sub.f32 vr4, vr5;"
        "}"
        "{"
        "V0@(pr0)	vr5 = mul.f32 vr5, vr2;"
        "V1@(pr0)	vr2 = or.u32 vr6, r46;"
        "}"
        "{"
        "V0@(pr0)	vr1 = mul.f32 vr5, vr5;"
        "V1@(pr0)	vr1 = or.u32 vr6, vr1;"
        "}"
        "{"
        "V0@(pr0)	vr15 = sel vmsk5 vr1, vr7;"
        "V1@(pr0)	vr15 = sel vmsk6 vr15, vr2;"
        "}"
        "{"
        "V0@(pr0)	vr1 = mul.f32 vr15, r50;"
        "V1@(pr0)	vr2 = mov.u32 vr15;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 23007;"
        "pseudo@0	@pseudo imm_1 = 24375;"
        "V0@(pr0)	vr3 = mov.u32 r44;"
        "V1@(pr0)	vr2 = shr.u32 vr2, r48;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 16320;"
        "V0@(pr0)	vr2 = sub.s32 vr3, vr2;"
        "V1@(pr0)	vr4 = mov.u32 r36;"
        "}"
        "{"
        "V0@(pr0)	vr3 = mul.f32 vr2, vr2;"
        "V1@(pr0)	vmsk5 = lseq.f32 vr15, r46;"
        "}"
        "{"
        "V0@(pr0)	vr5 = mul.f32 vr1, vr3;"
        "V1@(pr0)	vr5 = sub.f32 vr4, vr5;"
        "}"
        "{"
        "V0@(pr0)	vr5 = mul.f32 vr5, vr2;"
        "V1@(pr0)	vr2 = mov.u32 vr5;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_2 = 0;"
        "pseudo@0	@pseudo imm_3 = 32640;"
        "V0@(pr0)	vr3 = mul.f32 vr2, vr2;"
        "V1@(pr0)	vmsk6 = eq.s32 vr15, r45;"
        "}"
        "{"
        "V0@(pr0)	vr5 = mul.f32 vr1, vr3;"
        "V1@(pr0)	vr5 = sub.f32 vr4, vr5;"
        "}"
        "{"
        "V0@(pr0)	vr5 = mul.f32 vr5, vr2;"
        "V1@(pr0)	vr2 = mov.u32 vr5;"
        "}"
        "{"
        "V0@(pr0)	vr3 = mul.f32 vr2, vr2;"
        "V1@(pr0)	vmsk7 = eq.f32 vr15, r46;"
        "}"
        "{"
        "V0@(pr0)	vr5 = mul.f32 vr1, vr3;"
        "V1@(pr0)	vr5 = sub.f32 vr4, vr5;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 0;"
        "pseudo@0	@pseudo imm_1 = 32768;"
        "pseudo@0	@pseudo imm_2 = 0;"
        "pseudo@0	@pseudo imm_3 = 32640;"
        "V0@(pr0)	vr1 = and.u32 vr15, r44;"
        "V1@(pr0)	vr3 = or.u32 vr1, r45;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 0;"
        "pseudo@0	@pseudo imm_1 = 32704;"
        "V0@(pr0)	vr15 = mul.f32 vr5, vr2;"
        "V1@(pr0)	vr15 = sel vmsk5 vr15, r44;"
        "}"
        "{"
        "V0@(pr0)	vr15 = sel vmsk6 vr15, r46;"
        "V1@(pr0)	vr15 = sel vmsk7 vr15, vr3;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 8552;"
        "pseudo@0	@pseudo imm_1 = 13218;"
        "V0@(pr0)	vr13 = mul.f32 vr15, vr11;"
        "V1@(pr0)	vr13 = sub.f32 vr13, r44;"
        "}"
        "{"
        "V1@(pr0)	vr13 = add.f32 vr13, vr15;"
        "}"
        "{"
        "V0@(pr0)	vr13 = mul.f32 vr13, r51;"
        "}"
        "{"
        "V0@(pr0)	vr14 = mov.u32 r52;"
        "V1@(pr0)	vr17 = sub.f32 vr14, vr13;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 61440;"
        "pseudo@0	@pseudo imm_1 = 65535;"
        "V0@(pr0)	vr14 = and.u32 vr15, r44;"
        "}"
        "{"
        "V1@(pr0)	vr13 = add.f32 vr14, vr15;"
        "}"
        "{"
        "V0@(pr0)	vr10 = mul.f32 vr14, vr14;"
        "}"
        "{"
        "V1@(pr0)	vr10 = sub.f32 vr12, vr10;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 65535;"
        "pseudo@0	@pseudo imm_1 = 32767;"
        "pseudo@0	@pseudo imm_2 = 32640;"
        "V0@(pr0)	vr0 = and.u32 vr13, r44;"
        "V1@(pr0)	vmsk6 = eq.s32 vr0, r38;"
        "}"
        "{"
        "V0@(pr0)	vr1 = mul.f32 vr0, r50;"
        "V1@(pr0)	vr2 = mov.u32 vr0;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 23007;"
        "pseudo@0	@pseudo imm_1 = 24375;"
        "V0@(pr0)	vr3 = mov.u32 r44;"
        "V1@(pr0)	vr2 = shr.u32 vr2, r48;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 16320;"
        "V0@(pr0)	vr2 = sub.s32 vr3, vr2;"
        "V1@(pr0)	vr4 = mov.u32 r36;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 32768;"
        "V0@(pr0)	vr3 = mul.f32 vr2, vr2;"
        "V1@(pr0)	vr6 = and.u32 vr13, r36;"
        "}"
        "{"
        "V0@(pr0)	vr5 = mul.f32 vr1, vr3;"
        "V1@(pr0)	vr5 = sub.f32 vr4, vr5;"
        "}"
        "{"
        "V0@(pr0)	vr5 = mul.f32 vr5, vr2;"
        "V1@(pr0)	vr2 = mov.u32 vr5;"
        "}"
        "{"
        "V0@(pr0)	vr3 = mul.f32 vr2, vr2;"
        "V1@(pr0)	vmsk5 = eq.f32 vr13, r46;"
        "}"
        "{"
        "V0@(pr0)	vr5 = mul.f32 vr1, vr3;"
        "V1@(pr0)	vr5 = sub.f32 vr4, vr5;"
        "}"
        "{"
        "V0@(pr0)	vr5 = mul.f32 vr5, vr2;"
        "V1@(pr0)	vr2 = mov.u32 vr5;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 32640;"
        "V0@(pr0)	vr3 = mul.f32 vr2, vr2;"
        "V1@(pr0)	vr7 = or.u32 vr6, r36;"
        "}"
        "{"
        "V0@(pr0)	vr5 = mul.f32 vr1, vr3;"
        "V1@(pr0)	vr5 = sub.f32 vr4, vr5;"
        "}"
        "{"
        "V0@(pr0)	vr5 = mul.f32 vr5, vr2;"
        "V1@(pr0)	vr2 = or.u32 vr6, r46;"
        "}"
        "{"
        "V0@(pr0)	vr1 = mul.f32 vr5, vr5;"
        "V1@(pr0)	vr1 = or.u32 vr6, vr1;"
        "}"
        "{"
        "V0@(pr0)	vr13 = sel vmsk5 vr1, vr7;"
        "V1@(pr0)	vr13 = sel vmsk6 vr13, vr2;"
        "}"
        "{"
        "V0@(pr0)	vr13 = mul.f32 vr13, vr10;"
        "}"
        "{"
        "V0@(pr0)	vr11 = mul.f32 vr11, vr15;"
        "V1@(pr0)	vr13 = add.f32 vr11, vr13;"
        "}"
        "{"
        "V1@(pr0)	vr11 = add.f32 vr14, vr13;"
        "}"
        "{"
        "V0@(pr0)	vr13 = mul.f32 vr11, r51;"
        "}"
        "{"
        "V0@(pr0)	vr10 = sel vmsk3 vr13, vr17;"
        "V1@(pr0)	vr10 = sel vmsk2 vr10, vr16;"
        "}"
        "{"
        "V0@(pr0)	vr11 = mov.u32 r52;"
        "}"
        "{"
        "V0@(pr0)	vr12 = mul.f32 vr11, r50;"
        "}"
        "{"
        "V0@(pr0)	vr10 = sel vmsk4 vr10, vr12;"
        "V1@(pr0)	vr11 = sel vmsk3 vr11, r46;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_2 = 0;"
        "pseudo@0	@pseudo imm_3 = 32704;"
        "V0@(pr0)	vr10 = sel vmsk0 vr10, vr11;"
        "V1@(pr0)	%[res0] = sel vmsk1 vr10, r45;"
        "}"
        : [res0] "=x" (result0)
        : [input0] "x" (a)
        :"vr2", "vr1", "vr17", "vr4", "vr5", "vr16", "vr0", "vr11", "vr14", "vr15", "vr3", "vr7", "vr13", "vr10", "vr6", "vr12", "vmsk3", "vmsk0", "vmsk5", "vmsk4", "vmsk7", "vmsk1", "vmsk2", "vmsk6"
        );
    return result0;
}

#endif // _ACOSF_WITHOUT_UNARY_H_
