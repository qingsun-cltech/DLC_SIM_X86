#pragma once
#include "../../dlc-intrinsics.h"
#include "../../typehint.h"

#ifndef _REMAINDERF_H_X86_
#define _REMAINDERF_H_X86_

inline float8_128 __dlc_remainderf(float8_128 a, float8_128 b)
{
    float8_128 result0;
    asm (
        "{V0@(pr0)  vr10 = mov.u32 %[input0];}"
        "{V0@(pr0)  vr11 = mov.u32 %[input1];}"
        "{"
        "V0@(pr0)	vmsk0 = eq.s32 vr10, r46;"
        "V1@(pr0)	vmsk1 = eq.s32 vr10, r47;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 65535;"
        "pseudo@0	@pseudo imm_1 = 32767;"
        "V0@(pr0)	vr1 = and.u32 vr10, r44;"
        "V1@(pr0)	vr31 = and.u32 vr11, r44;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_1 = 32640;"
        "V0@(pr0)	vmsk7 = gt.s32 vr1, r37;"
        "}"
        "{"
        "V0@(pr0)	vr1 = mov.u32 vr11;"
        "V1@(pr0)	vr5 = mov.u32 vr10;"
        "}"
        "{"
        "V0@(pr0)	(urf) = rcp.f32 vr1;"
        "}"
        "{"
        "MTR@(pr0)	vr1 = pop urf;"
        "}"
        "{"
        "V0@(pr0)	vr2 = mul.f32 vr10, vr1;"
        "}"
        "{"
        "V0@(pr0)	vr28 = mov.u32 vr2;"
        "pseudo@0	@pseudo imm_2 = 65535;"
        "pseudo@0	@pseudo imm_3 = 32767;"
        "V1@(pr0)	vr0 = cvtftoint.s32 vr2, r45;"
        "}"
        "{"
        "V1@(pr0)	vmsk2 = gteq.f32 vr28, r46;"
        "}"
        "{"
        "V0@(pr0)	vr12 = cvtftoint.s32 vr28, r46;"
        "V1@(pr0)	vr13 = cvtftoint.s32 vr28, r56;"
        "}"
        "{"
        "V1@(pr0)	vr14 = sel vmsk2 vr12, vr13;"
        "}"
        "{"
        "V0@(pr0)	vr14 = cvtinttof.f32 vr14;"
        "V1@(pr0)	vr15 = sub.f32 vr28, vr14;"
        "}"
        "{"
        "V0@(pr0)	vmsk3 = eq.f32 vr15, r50;"
        "V1@(pr0)	vmsk2 = eq.f32 vr15, r58;"
        "}"
        "{"
        "V0@(pr0)	vmsk5 = vor.f32 vmsk3, vmsk2;"
        "}"
        "{"
        "V0@(pr0)	vr16 = and.u32 vr12, r48;"
        "V1@(pr0)	vmsk3 = eq.s32 vr16, r46;"
        "}"
        "{"
        "V1@(pr0)	vr17 = sel vmsk3 vr13, vr12;"
        "}"
        "{"
        "V0@(pr0)	vr3 = sel vmsk5 vr0, vr17;"
        "}"
        "{"
        "V0@(pr0)	vr4 = cvtinttof.f32 vr3;"
        "}"
        "{"
        "V0@(pr0)	vr6 = mul.f32 vr4, vr11;"
        "}"
        "{"
        "V1@(pr0)	vr10 = sub.f32 vr5, vr6;"
        "}"
        "{"
        "V0@(pr0)	vr10 = sel vmsk0 vr10, r46;"
        "V1@(pr0)	vr10 = sel vmsk1 vr10, r47;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 32640;"
        "pseudo@0	@pseudo imm_1 = 65408;"
        "V0@(pr0)	vmsk3 = eq.f32 vr10, r36;"
        "V1@(pr0)	vmsk4 = eq.f32 vr10, r37;"
        "}"
        "{"
        "V0@(pr0)	vmsk2 = eq.f32 vr11, r46;"
        "pseudo@0	@pseudo imm_0 = 32704;"
        "V0@(pr0)	vr10 = sel vmsk2 vr10, r36;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 32704;"
        "V0@(pr0)	vr10 = sel vmsk3 vr10, r36;"
        "V1@(pr0)	vr10 = sel vmsk4 vr10, r36;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_0 = 32640;"
        "pseudo@0	@pseudo imm_1 = 65408;"
        "V0@(pr0)	vmsk0 = eq.f32 vr11, r36;"
        "V1@(pr0)	vmsk1 = eq.f32 vr11, r37;"
        "}"
        "{"
        "V0@(pr0)	vr10 = sel vmsk0 vr10, vr5;"
        "V1@(pr0)	vr10 = sel vmsk1 vr10, vr5;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_1 = 32640;"
        "V0@(pr0)	vmsk0 = gt.s32 vr2, r37;"
        "}"
        "{"
        "pseudo@0	@pseudo imm_1 = 32704;"
        "V0@(pr0)	vr10 = sel vmsk0 vr10, r37;"
        "V1@(pr0)	%[res0] = sel vmsk7 vr10, r37;"
        "}"
        : [res0] "=x" (result0)
        : [input0] "x" (a),  [input1] "x" (b)
        :"vr2", "vr1", "vr5", "vr17", "vr4", "vr16", "vr0", "vr11", "vr14", "vr15", "vr3", "vr28", "vr13", "vr31", "vr10", "vr6", "vr12", "vmsk3", "vmsk0", "vmsk5", "vmsk4", "vmsk7", "vmsk1", "vmsk2"
        );
    return result0;
}

#endif // _REMAINDERF_H_
